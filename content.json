{"meta":{"title":"Hexo","subtitle":"","description":"","author":"Happysnaker","url":"http://example.com","root":"/"},"pages":[{"title":"分类","date":"2020-04-20T16:00:00.000Z","updated":"2023-02-10T05:03:32.303Z","comments":false,"path":"categories/index.html","permalink":"http://example.com/categories/index.html","excerpt":"","text":""},{"title":"留言板","date":"2020-04-21T12:17:58.000Z","updated":"2023-02-10T05:13:29.425Z","comments":true,"path":"conmment/index.html","permalink":"http://example.com/conmment/index.html","excerpt":"","text":"有什么想说的? 有什么想问的?"},{"title":"donate","date":"2020-02-13T15:13:05.000Z","updated":"2023-02-10T05:35:24.157Z","comments":false,"path":"donate/index.html","permalink":"http://example.com/donate/index.html","excerpt":"","text":""},{"title":"about","date":"2020-02-12T14:14:36.000Z","updated":"2023-02-10T05:06:07.987Z","comments":false,"path":"about/index.html","permalink":"http://example.com/about/index.html","excerpt":"","text":""},{"title":"tags","date":"2020-02-13T12:24:16.000Z","updated":"2023-02-10T05:04:39.283Z","comments":false,"path":"tags/index.html","permalink":"http://example.com/tags/index.html","excerpt":"","text":""},{"title":"links","date":"2020-02-13T15:11:06.000Z","updated":"2023-02-10T05:18:01.266Z","comments":true,"path":"links/index.html","permalink":"http://example.com/links/index.html","excerpt":"","text":""}],"posts":[{"title":"AQS 知识总结","slug":"AQS 知识总结","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.962Z","comments":true,"path":"post/bc53.html","link":"","permalink":"http://example.com/post/bc53.html","excerpt":"","text":"AQS 知识总结AQS，全称 Abstract Queue Synchronizer，中文名称“同步阻塞队列”，在java.util.concurrent.locks包下面，是一个抽象的可以实现阻塞线程、排队控制、唤醒线程等操作的同步器基础框架类，AQS 可以实现排它锁、共享锁、条件锁、计数器等相关功能。 AQS 维护着一个同步队列，队列节点其实就是一个工作线程，每个节点都维护着其前驱节点与后继节点，节点中的 waitStatus 字段标识着节点是否被取消或是正在等待一个条件等。 如果用一句话来总结 AQS 的功能，那就是 AQS 必须要保证整个队列入队和出队操作的原子性，同时要保证入队的线程在休眠后必须能够被唤醒。 在 AQS 的实现中，任何节点获取到资源时都会被设置成头节点，头节点的所有后继节点都是需要陷入休眠的节点，所以头节点必须要唤醒后继节点。后继节点是由其前驱节点唤醒的，所以 AQS 的管理中，一个节点如果需要陷入休眠，那么它必须将自己链接到一个能够唤醒它的前驱节点，通俗点讲，就是找个“好爹”，而每个节点在释放锁时，也要忠实的履行职责，唤醒后继节点。 AQS 是一个抽象的可以实现阻塞线程、排队控制、唤醒线程等操作的同步器基础框架类，现在再来理解这句话，阻塞线程、排队控制、唤醒线程，AQS 并没有实现获取锁的核心逻辑，获取锁的真正逻辑是用户实现的，AQS 只是帮我们管理线程，没得到锁的线程进行休眠，并且要保证休眠的线程能够被唤醒，可以说这就是整个 AQS 要做的事情。 static final class Node &amp;#123; // 标志线程已被中断 static final int CANCELLED = 1; // 标志节点在释放时，必须唤醒后继节点 static final int SIGNAL = -1; // 标志节点正在等待一个条件，用以实现条件队列 static final int CONDITION = -2; // 指示下一个 acquireShared 应该无条件地传播，即下一个节点 waitStatus 应该为 SIGNAL static final int PROPAGATE = -3; // waitStatus 为上述 4 种值，同时可能为 0，代表无意义 volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; // 为 null 代表独占模式，否则代表共享模式 Node nextWaiter; &amp;#125; 独占模式原理AQS 队列与其他队列并无两样，也是个先进先出的队列，因此新的节点入队时会被放置在队尾，如果节点获取锁（也称资源）失败，节点将会陷入休眠，在休眠时节点会为自己找一个“好爹”以负责唤醒自己（节点会修改前驱节点的 ws &#x3D; signal）。 释放锁时，如果有必要，节点必须唤醒后继节点，让后续节点醒过来继续尝试获取锁。 在一开始时，AQS 的 head 是一个伪头节点(假定已经初始化)，直到某个节点成功获取锁才会被设置成头节点。 获取资源分析acquire 方法是获取锁的入口方法： public final void acquire(int arg) &amp;#123; // 如果尝试获取锁不成功，那么进入 acquireQueued 堵塞，不停的尝试获取锁，如果 acquireQueued 返回 true，则线程自我中断，线程销毁 // 如果尝试获取锁成功，则不必堵塞或中断，线程继续运行；或者 acquireQueued 返回 false 同样如此 // 目标: tryAcquire(arg) 返回 true，或 acquireQueued 返回 false，否则线程将中断 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &amp;#125; tryAcquire 方法是我们自己实现的核心方法，acquire 方法会至少调用一次 tryAcquire 方法，这也意味着新加入的节点可能在第一次 tryAcquire 就成功了，那么这个新节点将不会入队而是直接运行，新节点直接抢占运行，而那些在等待队列中的线程却没得到运行，发生不公平的现象，AQS 提供了 hasQueuedPredecessors() 方法以判断当前线程是否是等待时间最久的线程，以实现公平的锁。 如果所有线程一次 tryAcquire 就成功了，那么没有排队的线程，AQS 也就没有什么事情可以做了。 如果第一次 tryAcquire 失败，节点会通过 addWaiter 方法被加入至队列尾部，然后执行 acquireQueued 方法，该方法是不停堵塞并尝试获取锁的核心方法： final boolean acquireQueued(final Node node, int arg) &amp;#123; boolean interrupted = false; try &amp;#123; // 无线循环，直到 获取锁 或 休眠成功 for (; ; ) &amp;#123; // 获取上一个节点，如果上一个节点就是队头，并且当前节点成功获取到锁，则设置当前节点为头 final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &amp;#123; setHead(node); // 由于是独占模式，当前节点获取锁成功，那么上一个节点一定释放了锁，可以光荣退休 p.next = null; // 返回 false，这将导致线程开始工作 return interrupted; &amp;#125; // 获取锁失败，休眠等待唤醒 // 否则查看自己是否能够休眠，如果能够休眠则进行休眠 if (shouldParkAfterFailedAcquire(p, node)) interrupted |= parkAndCheckInterrupt(); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; cancelAcquire(node); if (interrupted) selfInterrupt(); throw t; &amp;#125; &amp;#125; shouldParkAfterFailedAcquire(p, node) 是节点是否能够陷入休眠的核心方法： private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &amp;#123; int ws = pred.waitStatus; // 如果前一个节点会通知自己，那么自己可以放心地睡 if (ws == Node.SIGNAL) // ws == 1 return true; if (ws > 0) &amp;#123; // 如果前节点死掉了，则重新链接到一个新的存活节点（找一个“好爹”） do &amp;#123; node.prev = pred = pred.prev; &amp;#125; while (pred.waitStatus > 0); pred.next = node; &amp;#125; else &amp;#123; // 否则前驱节点必须要承担起唤醒后续节点的重任 pred.compareAndSetWaitStatus(ws, Node.SIGNAL); &amp;#125; // 否则，自己不能休眠，没有节点会唤醒自己，必须要在 acquireQueued 方法内不停尝试 获取锁 以及 休眠 return false; &amp;#125; 可以发现在 shouldParkAfterFailedAcquire(p, node) 方法中，节点只有在前节点保证会唤醒自己的情况下才会陷入休眠，如果前节点死了，节点会遍历直至找到一个正常的节点链接上去；如果前节点正常，但是 ws !&#x3D; Node.SIGNAL，那么 AQS 会将前节点的 ws 设置为 Node.SIGNAL，然后继续重试。 释放资源分析public final boolean release(int arg) &amp;#123; if (tryRelease(arg)) &amp;#123; Node h = head; // 在独占模式下，必须要唤醒后继节点 // h 是可能为 null 的，这说明队列为空，那么也没有队列可以唤醒了 // h.waitStatus 也是可能为 0 的，获取锁时，如果线程第二次就成功了，那么将不会陷入休眠，也不会设置自身状态，而直接成为队头，这种情况下，h.waitStatus == 0，这说明没有后续节点找到自己当“爹” if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &amp;#125; return false; &amp;#125; unparkSuccessor 是唤醒线程的核心方法，当线程被唤醒时，线程从 acquireQueued 醒过来，会继续进入循环尝试获取锁。 这就是 AQS 管理独占模式队列的逻辑：能不管就不管，如果没办法获取锁，AQS 不得不管了，那么就保证你陷入休眠时有人唤醒，保证某些“承担大任”的节点出队时要唤醒后继节点。 共享模式原理共享模式允许多个节点共享资源，这也意味着队列中可能会有多个正在获取资源的节点，共享模式中节点释放资源并不会把节点移出队列，因为它们可能还会释放部分资源。 共享模式中陷入休眠的逻辑与独占模式并无两样，但共享模式下在尝试获取资源时，如果发现还有资源可用，共享模式下会唤醒头节点的后继节点，让后继节点继续尝试获取资源。 当节点获取到资源时，仍然会把节点设置为头节点，头节点必须要唤醒后继节点。 当节点释放资源时，共享模式中可能会有非头节点释放资源，这种情况下也必须要唤醒头节点的后继节点。 获取资源分析public final void acquireShared(int arg) &amp;#123; // 如果为 -1 表示失败了，则进入同步队列堵塞获取锁 // 如果成功了，不用入队 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &amp;#125; tryAcquireShared(arg) 是具体获取资源的方法，这个方法的返回值为： ret &#x3D; -1：获取资源失败。 ret &#x3D; 0：获取资源成功，但没有其他资源可用。 ret &#x3D; 1：获取资源成功，并且还有资源可用。 来看 doAcquireShared 方法： private void doAcquireShared(int arg) &amp;#123; // 标记为共享节点添加到队列 final Node node = addWaiter(Node.SHARED); boolean interrupted = false; try &amp;#123; for (; ; ) &amp;#123; final Node p = node.predecessor(); if (p == head) &amp;#123; int r = tryAcquireShared(arg); /** * r = -1: 失败 * r = 0：成功，但没有其他资源了，不允许其他共享者进入了 * r = 1：成功，还有资源，允许其他共享者进入 */ if (r >= 0) &amp;#123; // 这是我们第一次见这个函数 setHeadAndPropagate(node, r); p.next = null; // help GC // 注意，这里返回了，因此不会堵塞 return; &amp;#125; &amp;#125; // 堵塞等待唤醒 if (shouldParkAfterFailedAcquire(p, node)) interrupted |= parkAndCheckInterrupt(); &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; cancelAcquire(node); throw t; &amp;#125; finally &amp;#123; if (interrupted) selfInterrupt(); &amp;#125; &amp;#125; 可以发送与独占模式还是比较相似的，只有 setHead 变成了 setHeadAndPropagate ，来看看这个函数： private void setHeadAndPropagate(Node node, int r) &amp;#123; // 注意！！！这里 h 是旧头部 Node h = head; // 设置 node 为新头部 setHead(node); // r > 0，说明还有资源可用，所以尝试唤醒休眠线程，这个很好理解 // h.waitStatus 是旧头部的状态，h.waitStatus 不可能为 SIGNAL，因为当为 SIGNAL 时，后继线程应该正在休眠；一旦 h 唤醒后继节点后，h 自身也会通过 CAS 将 ws 设置为别的状态，总之，不可能为 SIGNAL // h.waitStatus 只可能为 PROPAGATE，为啥为 PROPAGATE 也要唤醒节点？我们后面再讲 if (r > 0 || h.waitStatus &lt; 0) &amp;#123; Node s = node.next; if (s != null &amp;&amp; !s.isShared()) &amp;#123; return; &amp;#125; // 因为还有资源可用，所以尝试唤醒头节点的后继节点 doReleaseShared(); &amp;#125; &amp;#125; 当资源可用时或者旧头部的状态为 PROPAGATE 时，此时需要继续唤醒后继节点，这就是这个方法的逻辑。 释放资源分析public final boolean releaseShared(int arg) &amp;#123; if (tryReleaseShared(arg)) &amp;#123; doReleaseShared(); return true; &amp;#125; return false; &amp;#125; 在释放资源时，一旦释放成功，则必会进入 doReleaseShared() 方法： private void doReleaseShared() &amp;#123; for (; ; ) &amp;#123; // 找到当前头部节点，尝试唤醒后继节点 Node h = head; if (h != null &amp;&amp; h != tail) &amp;#123; int ws = h.waitStatus; // 如果需要唤醒后继节点的话，那么尝试将自身状态设置为 0，并唤醒后继节点 if (ws == Node.SIGNAL) &amp;#123; if (!h.compareAndSetWaitStatus(Node.SIGNAL, 0)) continue; unparkSuccessor(h); &amp;#125; // 否则就将自己状态设置为 Node.PROPAGATE else if (ws == 0 &amp;&amp; !h.compareAndSetWaitStatus(0, Node.PROPAGATE)) continue; // loop on failed CAS &amp;#125; if (h == head) // loop if head changed break; &amp;#125; &amp;#125; doReleaseShared() 方法会尝试释放头节点的后继节点，而只要 tryReleaseShared 成功，就一定会执行 doReleaseShared() 方法，也就是说任何一个节点释放资源时，都会保证去尝试唤醒一个正在休眠的节点。 到这里，共享模式已经可以实现了，那 Node.PROPAGATE 字段有何意义呢？ Node.PROPAGATE 意义Node.PROPAGATE 字段的出现是为了解决一个 Bug JDK-6801020 本节摘抄至 AQS源码深入分析之共享模式-你知道为什么AQS中要有PROPAGATE这个状态吗？_雕爷的架构之路-CSDN博客_aqs propagate 来看看离现在非常久远的Java 5u22中的该处代码是如何实现的： private void setHeadAndPropagate(Node node, int propagate) &amp;#123; setHead(node); if (propagate > 0 &amp;&amp; node.waitStatus != 0) &amp;#123; Node s = node.next; if (s == null || s.isShared()) unparkSuccessor(node); &amp;#125; &amp;#125; public final boolean releaseShared(int arg) &amp;#123; if (tryReleaseShared(arg)) &amp;#123; Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; &amp;#125; return false; &amp;#125; 可以看到，早期版本的实现相比于现在的实现来说简单了很多，总结起来最主要的区别有以下几个： 在setHeadAndPropagate方法中，早期版本对节点waitStatus状态的判断只是!&#x3D;0，而现在改为了&lt;0；早期版本的releaseShared方法中的执行逻辑和独占锁下的release方法是一样的，而现在将具体的唤醒逻辑写在了doReleaseShared方法里面，和setHeadAndPropagate方法共同调用。而可能出现bug的测试代码如下： import java.util.concurrent.Semaphore; public class TestSemaphore &amp;#123; private static Semaphore sem = new Semaphore(0); private static class Thread1 extends Thread &amp;#123; @Override public void run() &amp;#123; sem.acquireUninterruptibly(); &amp;#125; &amp;#125; private static class Thread2 extends Thread &amp;#123; @Override public void run() &amp;#123; sem.release(); &amp;#125; &amp;#125; public static void main(String[] args) throws InterruptedException &amp;#123; for (int i = 0; i &lt; 10000000; i++) &amp;#123; Thread t1 = new Thread1(); Thread t2 = new Thread1(); Thread t3 = new Thread2(); Thread t4 = new Thread2(); t1.start(); t2.start(); t3.start(); t4.start(); t1.join(); t2.join(); t3.join(); t4.join(); System.out.println(i); &amp;#125; &amp;#125; &amp;#125; 其实上面所做的操作无非就是创建了四个线程：t1和t2用于获取信号量，而t3和t4用于释放信号量，其中的10000000次for循环是为了放大出现bug的几率，join操作是为了阻塞主线程。现在就可以说出出现bug的现象了：也就是这里可能会出现线程被hang住的情况发生。 可以想象这样一种场景：假如说当前CLH队列中有一个空节点和两个被阻塞的节点（t1和t2想要获取信号量但获取不到被阻塞在CLH队列中（state初始为0））：head-&gt;t1-&gt;t2（tail）。 时刻1：t3调用release-&gt;releaseShared-&gt;tryReleaseShared，将state+1变为1，同时发现此时的head节点不为null并且waitStatus为-1，于是继续调用unparkSuccessor方法，在该方法中会将head的waitStatus改为0； 时刻2：t1被上面t3调用的unparkSuccessor方法所唤醒，调用了tryAcquireShared，将state-1又变为了0。注意，此时还没有调用接下来的setHeadAndPropagate方法； 时刻3：t4调用release-&gt;releaseShared-&gt;tryReleaseShared，将state+1变为1，同时发现此时的head节点虽然不为null，但是waitStatus为0，所以就不会执行unparkSuccessor方法； 时刻4：t1执行setHeadAndPropagate-&gt;setHead，将头节点置为自己。但在此时propagate也就是剩余的state已经为0了（propagate是在时刻2时通过传参的方式传进来的，那个时候-1后剩余的state是0），所以也不会执行unparkSuccessor方法。 至此可以发现一轮循环走完后，CLH队列中的t2线程永远不会被唤醒，主线程也就永远处在阻塞中，这里也就出现了bug。那么来看一下现在的AQS代码在引入了PROPAGATE状态后，在面对同样的场景下是如何解决这个bug的： 时刻1：t3调用release-&gt;releaseShared-&gt;tryReleaseShared，将state+1变为1，继续调用doReleaseShared方法，将head的waitStatus改为0，同时调用unparkSuccessor方法； 时刻2：t1被上面t3调用的unparkSuccessor方法所唤醒，调用了tryAcquireShared，将state-1又变为了0。注意，此时还没有调用接下来的setHeadAndPropagate方法； 时刻3：t4调用release-&gt;releaseShared-&gt;tryReleaseShared，将state+1变为1，同时继续调用doReleaseShared方法，此时会将head的waitStatus改为PROPAGATE； 时刻4：t1执行setHeadAndPropagate-&gt;setHead，将新的head节点置为自己。虽然此时propagate依旧是0，但是“h.waitStatus &lt; 0”这个条件是满足的（h现在是PROPAGATE状态），同时下一个节点也就是t2也是共享节点，所以会执行doReleaseShared方法，将新的head节点（t1）的waitStatus改为0，同时调用unparkSuccessor方法，此时也就会唤醒t2了。 至此就可以看出，在引入了PROPAGATE状态后，可以有效避免在高并发场景下可能出现的、线程没有被成功唤醒的情况出现。 条件队列原理条件队列由 AQS 内部类 ConditionObject 维护，关于条件变量介绍与使用可参考我的其他博客：**线程间同步方式**。 条件变量是一组等待唤醒的逻辑，在 AQS的实现中，等待的逻辑其实就是将线程加入由 ConditionObject 维护的条件队列中，由于 ConditionObject 内部并没有保证同步，所以等待时必须保证持有锁，AQS 保证线程在进入休眠时会释放锁。 唤醒的逻辑也很清晰，在 AQS 中，唤醒线程其实就是将由 ConditionObject 维护的条件队列中的头节点移至 AQS 中的同步等待队列中，唤醒该节点，然后节点就会进入 acquireQueued 方法，与独占模式中争抢资源的逻辑一致。 等待public final void await() throws InterruptedException &amp;#123; // 将节点添加至 条件队列 Node node = addConditionWaiter(); // 尝试释放自己持有的锁，如果未持有锁会抛出异常 int savedState = fullyRelease(node); int interruptMode = 0; // 如果不在同步等待队列的话（即还没被唤醒，如果被唤醒了会被移到等待队列中） while (!isOnSyncQueue(node)) &amp;#123; // 没有信号唤醒，那就休眠等待 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &amp;#125; // 被唤醒，以被添加到等待队列 // 进入 acquireQueued，与独占模式逻辑相同，不停 争抢锁 或 休眠 if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &amp;#125; 唤醒private void doSignal(Node first) &amp;#123; do &amp;#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; // 将队列中的头节点(等待时间最长的)作为参数，调用 transferForSignal &amp;#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &amp;#125; final boolean transferForSignal(Node node) &amp;#123; // 如果无法设置，那么线程肯定被取消了，因为等待中的队列 ws 只可能是 CONDITION if (!node.compareAndSetWaitStatus(Node.CONDITION, 0)) return false; // 将节点加入同步等待队列，这个返回的是前一个节点 Node p = enq(node); int ws = p.waitStatus; // 将前一个节点设置为 SIGNAL，如果设置成功，自己可以放心休眠 if (ws > 0 || !p.compareAndSetWaitStatus(ws, Node.SIGNAL)) LockSupport.unpark(node.thread); return true; &amp;#125; 实践 —— 代码实现可重入锁实现public class MyReentrantLock &amp;#123; private AbstractQueuedSynchronizer sync; /** * 实现不公平、可重入锁的 AQS */ private class UnFairSync extends AbstractQueuedSynchronizer &amp;#123; @Override protected boolean tryAcquire(int arg) &amp;#123; int state = getState(); // 如果资源可用，或持有锁的是当前线程，则尝试封锁资源 if (state == 0 || getExclusiveOwnerThread() == Thread.currentThread()) &amp;#123; return compareAndSetState(0, arg); &amp;#125; return false; &amp;#125; @Override protected boolean tryRelease(int arg) &amp;#123; int state = getState(); return compareAndSetState(state, state - arg); &amp;#125; &amp;#125; /** * 实现公平、可重入锁的 AQS */ private class FairSync extends AbstractQueuedSynchronizer &amp;#123; @Override protected boolean tryAcquire(int arg) &amp;#123; // 如果当前线程不是等待队列中的第一个线程，则不让其站有锁 // 这是公平的锁，只有等待队列中等待时间最长的能够拥有锁 if (getFirstQueuedThread() != Thread.currentThread()) &amp;#123; return false; &amp;#125; int state = getState(); // 如果资源可用，或持有锁的是当前线程，则尝试封锁资源 if (state == 0 || getExclusiveOwnerThread() == Thread.currentThread()) &amp;#123; return compareAndSetState(0, arg); &amp;#125; return false; &amp;#125; @Override protected boolean tryRelease(int arg) &amp;#123; int state = getState(); return compareAndSetState(state, state - arg); &amp;#125; &amp;#125; public MyReentrantLock(boolean fair) &amp;#123; this.sync = fair ? new FairSync() : new UnFairSync(); &amp;#125; public MyReentrantLock() &amp;#123; this(false); //默认不公平锁 &amp;#125; public void lock() &amp;#123; sync.acquire(1); &amp;#125; public void unLock() &amp;#123; sync.release(1); &amp;#125; &amp;#125; 信号量实现public class MySemaphore &amp;#123; AbstractQueuedSynchronizer sync; public MySemaphore(int totalResource) &amp;#123; sync = new Sync(totalResource); &amp;#125; private class Sync extends AbstractQueuedSynchronizer &amp;#123; public Sync(int s) &amp;#123; setState(s); &amp;#125; @Override protected int tryAcquireShared(int arg) &amp;#123; int state = getState(); System.out.println(\"state = \" + state); // 如果资源够的话，则获取资源 if (state >= arg &amp;&amp; compareAndSetState(state, state - arg)) &amp;#123; // 如果获取资源之后还有资源的话，返回 1，否则返回 0 return state - arg > 0 ? 1 : 0; &amp;#125; // 获取资源失败 return -1; &amp;#125; @Override protected boolean tryReleaseShared(int arg) &amp;#123; int state = getState(); return compareAndSetState(state, state + arg); &amp;#125; &amp;#125; public void acquire(int resource) &amp;#123; sync.acquireShared(resource); &amp;#125; public void release(int resource) &amp;#123; sync.releaseShared(resource); &amp;#125; &amp;#125; 计数器实现public class MyCountDownLatch &amp;#123; private AbstractQueuedSynchronizer sync; private class Sync extends AbstractQueuedSynchronizer &amp;#123; public Sync(int n) &amp;#123; // 初始化任务数 setState(n); &amp;#125; @Override protected int tryAcquireShared(int arg) &amp;#123; int state = getState(); // 等于 0 时代表任务已全部完成，返回 1，允许等待的线程 await // 大于 0 时，说明还有任务，允许其他线程领取任务，await 的需要继续等待 // 不可能小于 0 return state == 0 ? 1 : -1; &amp;#125; @Override protected boolean tryReleaseShared(int arg) &amp;#123; int state = getState(); if (state > 0) &amp;#123; // 尝试将任务数减少 1 return compareAndSetState(state, state - 1); &amp;#125; return false; &amp;#125; &amp;#125; public MyCountDownLatch(int n) &amp;#123; sync = new Sync(n); &amp;#125; public void countDown() &amp;#123; sync.releaseShared(1); &amp;#125; public void await() &amp;#123; sync.acquireShared(1); &amp;#125; &amp;#125; 测试代码public class Main &amp;#123; public static void main(String[] args) throws InterruptedException &amp;#123; test1();// 测试可重入锁 test2();// 测试信号量 test3();// 计数器 &amp;#125; synchronized static void countDown(MyCountDownLatch cdl, int id) &amp;#123; cdl.countDown(); System.out.println(\"线程\" + id + \" 完成一个任务\"); &amp;#125; static void test3() &amp;#123; int N = 10; MyCountDownLatch cdl = new MyCountDownLatch(N); System.out.println(\"总任务数：\" + N); for (int i = 0; i &lt; N; i++) &amp;#123; final int id = i; new Thread(()-> &amp;#123; countDown(cdl, id); &amp;#125;).start(); &amp;#125; cdl.await(); System.out.println(\"任务全部完成，继续运行！\"); &amp;#125; static void test2() throws InterruptedException &amp;#123; MySemaphore sem = new MySemaphore(5); for (int i = 1; i &lt;= 10; i++) &amp;#123; int id = i; new Thread(() -> &amp;#123; sem.acquire(1); System.out.println(\"线程\" + id + \"获取 1 个资源\"); &amp;#125;).start(); &amp;#125; // 等待资源全部被获取 Thread.sleep(100); // 释放 3 个资源 System.out.println(\"\\n主线程释放 3 个资源\\n\"); sem.release(3); // 等待资源全部被获取 Thread.sleep(100); // 释放 3 个资源 System.out.println(\"\\n主线程释放 2 个资源\\n\"); sem.release(2); &amp;#125; static void test1() throws InterruptedException &amp;#123; MyReentrantLock lock = new MyReentrantLock(); for (int i = 1; i &lt;= 100; i++) &amp;#123; int id = i; new Thread(() -> &amp;#123; lock.lock(); System.out.println(\"线程\" + id + \" 持有锁\"); System.out.println(\"线程\" + id + \" 释放锁\"); System.out.println(); lock.unLock(); &amp;#125;).start(); &amp;#125; &amp;#125; &amp;#125;","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"Docker网络模型原理","slug":"Docker网络模型原理","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:34:52.921Z","comments":true,"path":"post/93f4.html","link":"","permalink":"http://example.com/post/93f4.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 Docker网络模型bridge模式bridge模式是docker默认的网络模式，也是使用最频繁的一个模式，我们主要理解该模式。 容器向外发送信息 在docker启动时，如果不显式添加参数，则默认使用该模式，启动时docker会创建一个虚拟网卡，被命名为docker0，docker0一端管辖着docker容器网络，docker容器网络一般以内部地址172(被占用则改用其他内部地址)开头，一端连接宿主机物理网卡，起着桥接的作用，这也是该模式名称的由来。此后，每创建一个容器，docker就会创建一个虚拟网络设备接口veth-pair(上图中的eth0&lt;-&gt;veth)，一个接口用于由docker0向容器发送消息，另一个接口用于由容器向外发送数据。 在docker0与宿主机物理接口中eth0，还存在一个ip forward(ip转发)规则，所有由docker0网络发往外部的数据，其源地址都会被映射为物理机的源地址，当数据包到达真实物理网卡时，就好像是由宿主机发出的数据包一样，然后，eth0物理网卡用自己的MAC地址将数据包封装成帧，进行链路传输，这就是整个发送的流程。 现在开始进行验证，注意docker需要运行在Linux机器上，windows下powershell部分命令无法执行。 在Linux宿主机中键入ip addr命令查看网口，存在如下信息： docker0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default link/ether 02:42:8c:85:1a:f3 brd ff:ff:ff:ff:ff:ff inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0 valid_lft forever preferred_lft forever inet6 fe80::42:8cff:fe85:1af3/64 scope link valid_lft forever preferred_lft forever 发现确实存在docker0接口，其ip为172.17.0.1，并且采用CIDR方式进行路由，子网掩码为255.255.0.0。 创建一个容器bbox1并进入，键入ifconfig查看接口信息： eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:02 inet addr:172.17.0.2 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:27 errors:0 dropped:0 overruns:0 frame:0 TX packets:7 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:2043 (1.9 KiB) TX bytes:516 (516.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 发现确实存在etho接口(lo是回环接口)，并且bbox1的ip地址为172.17.0.2，键入route -n查看容器的路由转发规则： Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.17.0.1 0.0.0.0 UG 0 0 0 eth0 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth0 发现容器的默认网关是172.17.0.1，即docker0，0.0.0.0这个地址代表默认地址，即如果在路由表中不存在地址，则默认其为0.0.0.0，docker0收到数据包后，就像普通数据包一样试图发往物理网卡，在Linux中，数据包发往物理网卡转发之前会先交由内核路由，内核路由会判断是否需要进行NAT转换，经过相应处理之后再进行网卡路由选择转发。 此处内核充当NAT路由，为软件路由，为网卡前的一层抽象，对主机内进程是透明的 回到宿主机中(另外开一个终端)，在宿主机命令行键入iptables -t nat -vnL命令查看NAT转换规则，发现有如下信息： Chain POSTROUTING (policy ACCEPT 21 packets, 1479 bytes) pkts bytes target prot opt in out source destination 3 202 MASQUERADE all -- * !docker0 172.17.0.0/16 0.0.0.0/0 发现由172.17.0.0&#x2F;16发往0.0.0.0&#x2F;0的包会被内核应用MASQUERADE规则，MASQUERADE规则会将该ip分组的源地址伪装成真实的物理机地址，这样一个虚拟的不存在的容器地址就变成了真实的、存在的物理机地址，因此可以与外界进行通信。 172.17.0.0&#x2F;16 代表 所有 源地址 &amp; 255.255.0.0(16个1) &#x3D; 172.17.0.0 的地址，这里就是容器内网地址 同理，0.0.0.0&#x2F;0 意味着任意地址 之前有个学弟问我，为什么其他服务器能回应由容器内发出的ping，当数据包发送到物理机上，又是怎么到达容器内的呢？ 这里涉及到docker的二层封装知识，当docker0收到容器内发来的数据包时，会将收到的数据包作为一个整体当作数据，重新进行TCP&#x2F;IP封装，其中TCP端口号为容器端口号，要知道，容器不过是主机上的一个进程，其端口号是唯一的，这样当主机收到数据包时直接交由TCP层，TCP层根据端口号直接将数据交付容器，此时容器就好像刚刚收到一个完整的数据包一样。 外部向容器发送信息要知道，外部主机只知道宿主机的ip，容器对其是完全不可见的，因此必须映射物理机的地址到容器上。 在上面的例子中，外部主机得知了容器的具体端口号，因此可以将数据交由容器，但这只是特殊的情况，外部机仍然无法访问具体的容器内的服务，例如：容器内的8080端口开放tomcat服务。 这种情况下，需要开启端口映射，例如将容器内的 8080 端口映射到主机的 80 端口，这样外部机访问主机的 80 端口即可访问容器的的 8080 端口，启动时可通过参数 -p [主机端口][容器端口]开启次映射，当配置映射时，docker会自动配置Linux内核的SNAT规则与转发表，对所有目的地址为 [主机IP][配置的主机端口]转换为[容器IP][配置的主机端口]，并转发与docker0接口，docker0接口进行查表，交由具体的容器。 自定义网络规则创建之前，查看当前网络，可以发现docker安装时创建了bridge、host、none三个网络。 [root@docker1 ~]# docker network ls NETWORK ID NAME DRIVER SCOPE c1bb643c9c5a bridge bridge local 59364623cee2 host host local fb704391fb47 none null local 键入docker network create --driver=bridge --subnet=172.08.21.0/24 --gateway=172.08.21.1 my-net以bridge模式创建自定义网络，此时指定网段172.08.21.0&#x2F;24，指定网关172.08.21.1，此时发现多了my-net网络： PS C:\\Users\\happysnakers> docker network ls NETWORK ID NAME DRIVER SCOPE 4f40a1f35b48 bridge bridge local 388c0fa8a67d host host local 92462d1ae4e8 my-net bridge local 306db96b7739 none null local 利用busybox镜像创建bbox1容器，docker run -it --rm --network=my-net --name bbox1 --ip=172.08.21.65 busybox，注意指定的ip必须与之前定义网络时指定的网段相符合。 新开终端，利用busybox镜像创建bbox2容器，docker run -it --rm --name bbox2 busybox，此处利用默认的docker0配置。 打印bbox1中的网络配置: / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:08:15:41 inet addr:172.8.21.65 Bcast:172.8.21.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:14 errors:0 dropped:0 overruns:0 frame:0 TX packets:5 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:1076 (1.0 KiB) TX bytes:378 (378.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) ip 确实为我们指定的ip地址，在bbox2中尝试ping 172.8.21.65，发现ping不通。 此时网络图如上，看来一切原因都在内核路由中，回到主机中，键入route -n 查看主机的路由: Kernel IP routing table Destination Gateway Genmask Iface 0.0.0.0 192.168.0.1 0.0.0.0 enp0s3 172.17.0.0 0.0.0.0 255.255.0.0 docker0 172.8.21.0 0.0.0.0 255.255.255.0 br-757bb8fb1878 192.168.0.0 0.0.0.0 255.255.255.0 enp0s3 从路由中看出各网段是未封闭的，应当是可以通信的，但我们之前说过，路由转发前会动过SNAT转换，问题应该是出现在NAT转换过程中了，键入iptables -t filter -vnL命令查看过滤表： Chain DOCKER-ISOLATION-STAGE-1 (1 references) pkts bytes target prot opt in out source destination 0 0 DOCKER-ISOLATION-STAGE-2 all -- br-757bb8fb1878 !br-757bb8fb1878 0.0.0.0/0 0.0.0.0/0 33 6167 DOCKER-ISOLATION-STAGE-2 all -- docker0 !docker0 0.0.0.0/0 0.0.0.0/0 76 9290 RETURN all -- * * 0.0.0.0/0 0.0.0.0/0 可以看到向docker0和br-757bb8fb1878(my-net)接口的发出任意包都会被应用DOCKER-ISOLATION-STAGE-2规则，事实上在DOCKER-ISOLATION-STAGE-2之前还有一个DOCKER-ISOLATION-STAGE-1规则，DOCKER-ISOLATION-STAGE-1规则过滤任何从docker容器内发出的包，将该包交由DOCKER-ISOLATION-STAGE-2链处理，DOCKER-ISOLATION-STAGE-2过滤任意发往docker容器的包，而对不发往docker容器的包返回给正常链处理(RETURN规则)，这样经DOCKER-ISOLATION-STAGE-1和DOCKER-ISOLATION-STAGE-2过滤后的包即是由不同brigde中的容器之间的数据包了。 执行docker network connect my-net bbox2命令将bbox2容器连接到my-net网络(bbox1所属网络)，在bbox2中尝试ping 172.8.21.65，发现能够ping通，网络确实互联。 键入route -n和ifconfig查看bbox2的路由转发规则与接口： / # route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 172.17.0.1 0.0.0.0 UG 0 0 0 eth0 172.8.21.0 0.0.0.0 255.255.255.0 U 0 0 0 eth1 172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 eth0 / # ifconfig eth0 Link encap:Ethernet HWaddr 02:42:AC:11:00:03 inet addr:172.17.0.3 Bcast:172.17.255.255 Mask:255.255.0.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:11 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:866 (866.0 B) TX bytes:0 (0.0 B) eth1 Link encap:Ethernet HWaddr 02:42:AC:08:15:02 inet addr:172.8.21.2 Bcast:172.8.21.255 Mask:255.255.255.0 UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:16 errors:0 dropped:0 overruns:0 frame:0 TX packets:5 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:1216 (1.1 KiB) TX bytes:378 (378.0 B) lo Link encap:Local Loopback inet addr:127.0.0.1 Mask:255.0.0.0 UP LOOPBACK RUNNING MTU:65536 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:1000 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 发现发往172.8.21.0&#x2F;24的数据包会被发往eth1接口，并且发现eth1接口的目的地址inet addr确实为我们所配置网络的网关，成功互联，此时网络图大概如下所示： host模式host模式即主机模式，这时候一个容器就是正常的主机的一个进程，容器网络就是主机网络，容器和宿主机共享同一个网络命名空间，换言之，容器的IP地址即为宿主机的IP地址。所以容器可以和宿主机一样，使用宿主机的任意网卡，实现和外界的通信。其网络模型可以参照下图： 采用这种模式容器的确是可以访问外部主机，原理就是主机上的一个进程访问外网，这种模式缺点是很明显的，容器内不再虚拟化端口，容器内所有的端口会会占用主机端口，各个容器之间会竞争端口，十分不安全。 none模式在这种模式下，容器有独立的网络栈，但不包含任何网络配置，只具有lo这个loopback网卡用于进程通信。也就是说，none模式为容器做了最少的网络设置，但是俗话说得好“少即是多”，在没有网络配置的情况下，通过第三方工具或者手工的方式，开发这任意定制容器的网络，提供了最高的灵活性。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"ConcurrentHashMap 学习总结","slug":"ConcurrentHashMap 学习总结","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.962Z","comments":true,"path":"post/cea5.html","link":"","permalink":"http://example.com/post/cea5.html","excerpt":"","text":"ConcurrentHashMap 本文基于 jdk11，前置知识：[Java HashMap 详解](.&#x2F;HashMap 学习总结.md) 插入时逻辑在 jdk1.7 以前，ConcurrentHashMap 采用分段锁，将一个大的 HashMap 数组分为多个小的段 Segment，每个段也是一个 HashMap 数组，插入时首先计算 key 所属的段，然后对整个段上锁，再执行插入。通过细化敏感资源的思想，ConcurrentHashMap 大大提高了效率，而在 jdk1.8 之后，这种思想更是明显。 在 jdk1.8 后，ConcurrentHashMap 放弃了分段的做法，通过对数组下标上锁，更细一步的缩小了锁的范围。 这是如何做到的呢？在 ConcurrentHashMap 中，一个元素要插入（或者删除）到下标 i 的位置，它首先必须要获得 tab[i] 上持有的锁，tab[i] 其实就是一个 Node，如果这是一个链表，tab[i] 的含义是链表的头节点，由于插入采用的是尾插法，因此头节点的位置是不会改变的；如果这是一颗树，由于插入时树的根节点是可能会被调整的，因此 ConcurrentHashMap 用 TreeBin 类（继承 Node）封装了树的根节点，树的根节点可能会变，但 TreeBin 是不会变的，换句话说，就是给整棵树套了层皮。 jdk1.8 后，锁是利用 synchronized 实现的，经过几次优化后，synchronized 的性能已经相当不错了。 final V putVal(K key, V value, boolean onlyIfAbsent) &amp;#123; int hash = spread(key.hashCode()); for (Node&lt;K,V>[] tab = table;;) &amp;#123; Node&lt;K,V> f; int n, i, fh; K fk; V fv; // 如果头节点为空，那么利用 CAS 尝试设置头节点 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &amp;#123; if (casTabAt(tab, i, null, new Node&lt;K,V>(hash, key, value))) break; // no lock when adding to empty bin &amp;#125; else &amp;#123; V oldVal = null; // P // 否则对头节点上锁 synchronized (f) &amp;#123; // 上锁之后在此检查，因为在上锁的那一刻是存在并发冲突的，例如在 P 点 if (tabAt(tab, i) == f) &amp;#123; if (fh >= 0) &amp;#123; // 哈希值大于 0，意味着是链表 binCount = 1; for (Node&lt;K,V> e = f;; ++binCount) &amp;#123; // 同 hashmap 一样的逻辑 &amp;#125; &amp;#125; else if (f instanceof TreeBin) &amp;#123; // 树的操作 Node&lt;K,V> p; binCount = 2; (p = ((TreeBin&lt;K,V>)f).putTreeVal(hash, key,value)); &amp;#125; &amp;#125; &amp;#125; if (binCount >= TREEIFY_THRESHOLD) treeifyBin(tab, i); // 同 HashMap 一样的逻辑，树化 break; &amp;#125; &amp;#125; addCount(1L, binCount); return null; &amp;#125; 总结来看，jdk1.8 中 ConcurrentHashMap 是通过 synchronized 对链表头节点或 TreeBin（树的根节点的包装类）上锁，一旦一个线程持有锁后，由于链表头节点是不会改变的，而树根节点通过包装后也是不变的，所以其他线程的插入、删除必须要等待获取链表头节点上的锁，这保证了线程并发安全性。 jdk1.8 后虽然删除了分段锁，但仍然是一个将锁细化的思想，这次将锁细化到了数组中的每一个下标，细化程度应该是更甚于 jdk1.7 的，因此效率也是高于 jdk.17 的。我们从中也可以学习到一点思想，例如下单时我们不必锁住整个方法，可以只对商品 ID 上锁。 大小增加逻辑ConcurrentHashMap 是如何安全的增加或减少大小的？我们直到单纯的 size++ 和 size– 是不安全的，因为 Java 是基于栈解释而不是基于寄存器的，size++ 首先会把 size 和 1 入栈，然后再取出这两个变量进行相加，这至少需要 3 条命令，并不是一条原语，因此这不是并发安全的。 按理来说，应该可以采用 Atomic 类进行自增和自减，这的确可以，但是 Atomic 底层也是利用 CAS 不断自旋，ConcurrentHashMap 采用了效率更高的一种方式，ConcurrentHashMap 仍然采用细分的思想，创建了 CounterCell 数组，如果线程对 BASECOUNT 自增或自减失败，线程就会转而操作 CounterCell 数组，将 CounterCell 中的值增减或减小，如果这还失败，那么会尝试对 CounterCell 扩容，直到到达一个阈值，然后继续循环。 至于选择 CounterCell 数组中的哪一个 CounterCell，这仍然是通过哈希计算出下标，CounterCell 数组的大小也是 2 的幂，如果冲突频繁，也会尝试扩容，所允许的最大大小为 CPU 核心数，这是有原因的，当线程数超过 CPU 核心数后，并行效率其实还不如串行。 说白了，其实就是减少冲突，既然另一个线程在操作这个变量，那么我就去操作其他变量，计算 size 的时候再重新加起来就好了，下面是计算大小的方法： final long sumCount() &amp;#123; CounterCell[] cs = counterCells; long sum = baseCount; if (cs != null) &amp;#123; for (CounterCell c : cs) if (c != null) sum += c.value; &amp;#125; return sum; &amp;#125; 这种方法还是非常巧妙的，将需要竞争的资源分散开来，以减小冲突，需要时再重新聚合起来，果然看源码还是能学到很多牛逼的思想。 for (;;) &amp;#123; CounterCell[] cs; CounterCell c; int n; long v; if ((cs = counterCells) != null &amp;&amp; (n = cs.length) > 0) &amp;#123; c = cs[(n - 1) &amp; h]; // 尝试修改值 if (U.compareAndSetLong(c, CELLVALUE, v = c.value, v + x)) break; // 如果 cs 数组的大小大于等于 CPU 核心数了，停止扩容 else if (counterCells != cs || n >= NCPU) // else if (cellsBusy == 0 &amp;&amp; U.compareAndSetInt(this, CELLSBUSY, 0, 1)) &amp;#123; try &amp;#123; // 扩容 if (counterCells == cs) // Expand table unless stale counterCells = Arrays.copyOf(cs, n &lt;&lt; 1); &amp;#125; finally &amp;#123; cellsBusy = 0; &amp;#125; collide = false; continue; // Retry with expanded table &amp;#125; h = ThreadLocalRandom.advanceProbe(h); &amp;#125; // 尝试设置 BASECOUNT else if (U.compareAndSetLong(this, BASECOUNT, v = baseCount, v + x)) break; // Fall back on using base &amp;#125; 初始化逻辑在 jdk1.7 之前，如果过多线程同时开始初始化，可能会导致 CPU飙升，而在 jdk.18 后，缓解了这个问题： private final Node&lt;K,V>[] initTable() &amp;#123; Node&lt;K,V>[] tab; int sc; while ((tab = table) == null || tab.length == 0) &amp;#123; if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin else if (U.compareAndSetInt(this, SIZECTL, sc, -1)) &amp;#123; try &amp;#123; if ((tab = table) == null || tab.length == 0) &amp;#123; int n = (sc > 0) ? sc : DEFAULT_CAPACITY; Node&lt;K,V>[] nt = (Node&lt;K,V>[])new Node&lt;?,?>[n]; table = tab = nt; sc = n - (n >>> 2); // sc = n - 1/4 n = 0.75n &amp;#125; &amp;#125; finally &amp;#123; sizeCtl = sc; &amp;#125; break; &amp;#125; &amp;#125; return tab; &amp;#125; 可以发现，如果 sc 标志 &#x3D; -1 时，标识正在初始化，jdk1.7 之前会无线自旋，而在当前版本，添加了 Thread.yield() 方法，表示线程愿意降低自己执行的优先度，通过这种方法来缓解 CPU 飙升的问题。 还可以发现，一旦初始化完成后，sc 会被设置为 0.75N，这是扩容时的阈值，扩容因子默认为 0.75，并且不允许用户修改。 扩容时逻辑ConcurrentHashMap 允许多线程同时进行扩容，在插入时，你会看到如下代码： else if ((fh = f.hash) == MOVED) tab = helpTransfer(tab, f); 一旦 tab[i].hash 为 -1 时，标识此下标正在发生扩容，那么线程将会尝试帮助扩容： final Node&lt;K,V>[] helpTransfer(Node&lt;K,V>[] tab, Node&lt;K,V> f) &amp;#123; Node&lt;K,V>[] nextTab; int sc; nextTab = ((ForwardingNode&lt;K,V>)f).nextTable; // 获取新表 if (tab != null &amp;&amp; (f instanceof ForwardingNode)) &amp;#123; int rs = resizeStamp(tab.length); // 获取扩容的唯一标识符 while (nextTab == nextTable &amp;&amp; table == tab &amp;&amp; (sc = sizeCtl) &lt; 0) &amp;#123; // 如果标识符不相等，标识扩容已完成或已经开始下一轮扩容了 // sc == rs + MAX_RESIZERS 是个特殊的运算，用于控制帮忙线程最大数量 if ((sc >>> RESIZE_STAMP_SHIFT) != rs || sc == rs + MAX_RESIZERS) break; // 尝试将 sc + 1 表示线程增加，成功则开始扩容 if (U.compareAndSetInt(this, SIZECTL, sc, sc + 1)) &amp;#123; transfer(tab, nextTab); break; &amp;#125; &amp;#125; return nextTab; &amp;#125; return table; &amp;#125; 上面代码中的 rs 的值是由当前数组大小唯一标识的，例如标识是从 16 扩容到 32，还是由 32 扩容到 64，并且只有 16 位有效，而 sc 的值是由最先开始扩容的线程设置的，sc 的高 16 位被设置成 rs，不仅如此，rs &lt;&lt; RESIZE_STAMP_SHIFT 一定是负的，这意味着扩容时 sc 一定是负的： if (U.compareAndSetInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); //RESIZE_STAMP_SHIFT =16 这意味着，如果 (sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) !&#x3D; rs，说明扩容已经完成或已经进入下一轮扩容，信息已过时，应该退出重新循环，这里都是为了保障并发安全。 可以看到每个线程进入帮忙扩容时，都会自增 sc 的值，而 sc 的值最初为 rs &lt;&lt; 16 + 2，这意味着 sc 的低 16 位标识当前正在参与扩容的线程数 +1（初始时只有一个线程但 +2 了，多了一个），ConcurrentHashMap 通过这种方式可以控制参与帮忙调整线程的最大数量。 转移的逻辑与 HashMap 是类似的，但由于允许多线程共同扩容，ConcurrentHashMap 必须要是并发安全的。 在 HashMap 中我们有一个很巧妙的结论，下标 i 的元素扩容后要么在 i 处，要么在 i + n 处，这意味两个不同下标之间的元素是不可能有任何冲突的，因此，只要保证不同线程选取不同下标进行扩容就可以了。在 ConcurrentHashMap 中，这通过 volatile 变量 transferIndex 来实现，transferIndex 标识线程开始选取的下标，线程会尝试选取 stride（步长）个下标，那么线程必须要利用 CAS 修改 transferIndex 来标识下一个线程开始的位置，如果 CAS 失败了，线程需要重新尝试，因为 volatile 只保证了可见性而并没有保证原子性。 在对下标 i 进行扩容时，线程必须要锁住 tab[i]，锁住的逻辑与插入时类似，这是由于在扩容时，可能还会与插入、查找、删除等操作存在并发冲突，因此必须上锁。但换个角度，如果 tab[i] 还没有线程对其扩容（但是扩容操作已经开始，只是还没轮到 i），此时其他的操作是不会被堵塞的。 sizeCtlsizeCtl，即 sc 作为大小控制量，在 ConcurrentHashMap 中至关重要，通过上面的分析，来总结一下这个变量不同值对应的不同含义。 sizeCtl &#x3D; 0：这标识 tab 还未初始化，需要初始化。 sizeCtl &#x3D; -1：这标识 tab 正在初始化，等待的线程需降低自己的执行的优先级，防止 CPU 飙升。 sizeCtl &lt; 0 &amp;&amp; sizeCtl !&#x3D; -1：标识正在扩容，sc 高16位标识扩容标识戳，数组大小不同，则标识戳也不同；低16位表示正在扩容的线程数 + 1。 sizeCtl &gt; 0：这代表扩容的阈值，ConcurrentHashMap 中，扩容因子固定为 0.75。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"Git 原理与实践","slug":"Git 原理与实践","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.974Z","comments":true,"path":"post/a79.html","link":"","permalink":"http://example.com/post/a79.html","excerpt":"","text":"Git 原理与实践演变历史 本地版本控制在早期的时候，项目版本控制都是在本地通过复制文件以及文件命名进行控制的，例如将不同版本的项目命名为 v1.0、v2.0 等。 早期较为成熟的版本控制工具如 RCS 就是利用这种方式，当然 RCS 并不是保存整个文件，而是增量更新，只有初代版本会保存所有内容，后续版本将以增加更新的形式保存，例如 “某文件某偏移增加或删除了XXX内容”。 当然，本地版本控制的弊端非常明显，协同合作非常困难，因此演变出了集中式的版本控制。 集中式版本控制SVN 是集中式版本控制的代言人，曾经流行过一段时间，SVN 将所有的版本变更以增量更新（补丁）的方式保存在远程服务器，允许开发人员从服务器拉去或提交。 但是集中式版本控制是中心化的，可靠性依赖于远程服务器，并且不支持复杂的分支操作， 于是 Git 孕育而生。 分布式版本控制Git 允许本地暂存变更，所以说 Git 的每个仓库都能记录版本历史，开发人员无须联网也能进行版本控制，解决了 SVN 只有一个服务器保存版本的问题，是当下主流的版本控制工具。 Git 不同于之前的工具，Git 每次更新都是会保存全部的文件而非增量更新，因此 Git 通常不支持 Commit 大文件。 Git 原理版本控制原理Git 版本管理主要是通过 .git&#x2F;Objects&#x2F; 路径下的文件进行管理，假设这里只简单的考虑 Commit，该路径下主要会存储三大重要信息： commit 信息：保存用户的 commit 记录，包括 commit message、author、committer、parent 以及最重要的 tree ID，tree ID 是指向 tree 的文件。 tree 信息：用户 commit 可能涉及到多个文件的修改，一个 tree 文件中将保存多个 blog ID，blog 是指具体发生修改的文件。 blog 信息：blog 即是指具体发生改动的内容文件，Git 会全量保存文件内容。 接着我们在本地进行实践，首先初始化 Git 仓库，然后创建 Readme 文件，在 Readme 文件中随便写点内容，提交到本地仓库中： git init vim Readme.md # 然后自己写点内容 git add . # 添加当前目录变更 git commit -m \"create readme\" 执行完上述步骤后，我们打印 .git 目录下文件： 这里可以发现 objects 目录下多出了三个文件，先通过 git log 命令查看下更新的日志： [root]# git log commit 854ebf0cbe82f7c6b06c35dfb48d5af2149d4643 Author: happysnaker &lt;xxx@qq.com> Date: Sat May 21 15:26:44 2022 +0800 create readme 发现 commit 信息文件 ID 是 854ebf0cbe82f7c6b06c35dfb48d5af2149d4643，通过 git cat-file 命令查看文件： [root]# git cat-file -p 854ebf0cbe82f7c6b06c35dfb48d5af2149d4643 tree 58c31878a99ff474aba5a0ad3cc751285003acc7 author happysnaker &lt;xxx@qq.com> 1653118004 +0800 committer happysnaker &lt;xxx@qq.com> 1653118004 +0800 create readme 这包含了我们了我们的提交信息，其中还包含了 tree 信息文件，同样查看一下 tree 文件： [root]# git cat-file -p 58c31878a99ff474aba5a0ad3cc751285003acc7 100644 blob 557db03de997c86a4a028e1ebd3a1ceb225be238 Readme.md tree 信息包含了 blog 文件信息，这就是我们修改的文件，当然 tree 文件内可以包含多个修改的文件，查看 blog 文件： [root]# git cat-file -p 557db03de997c86a4a028e1ebd3a1ceb225be238 Hello World 他就是我们文件的全量内容，这就是 git 的版本控制原理，现在我们尝试对 readme 文件进行更改并且提交： [root]# vim Readme.md [root]# git add . [root]# git commit -m \"update readme\" 继续查看一些文件树： 发现这里又多了三个文件，这反应出Git 每次提交都会新建 commit、tree 和 blog 文件，通过 git log 查看 commit 文件信息： [root]# git log commit 3c8de40439f7917b188e7c3271409794ec635ef3 Author: happysnaker &lt;1637318597@qq.com> Date: Sat May 21 15:40:09 2022 +0800 update readme commit 854ebf0cbe82f7c6b06c35dfb48d5af2149d4643 Author: happysnaker &lt;1637318597@qq.com> Date: Sat May 21 15:26:44 2022 +0800 create readme 这里最新的 commit 文件是 3c8de40439f7917b188e7c3271409794ec635ef3，查看这个文件内容： [root]# git cat-file -p 3c8de40439f7917b188e7c3271409794ec635ef3 tree ce81273cc3c46c1e7543355e01010685aab9412d parent 854ebf0cbe82f7c6b06c35dfb48d5af2149d4643 author happysnaker &lt;1637318597@qq.com> 1653118809 +0800 committer happysnaker &lt;1637318597@qq.com> 1653118809 +0800 update readme 这与我们之前所说的是一模一样的，唯一的不同是这里多了个 parent 字段，它刚好指向我们上一个 commit 版本。 所以说，Git 其实就是通过 commit、tree 和 blog 文件来进行版本控制，Git 将进行全量保存而非增量更新，Git 只需只需记录下每次 commit 所产生的 commit 文件，进行版本切换的时候，直接找到 commit 文件，并找到对应的 blog 文件，将工作区文件替换成 blog 文件便可完成版本控制。 分支控制原理那 Git 的分支切换呢？Git 是如何进行分支控制的？一个分支是如何不对另一个分支产生影响的呢？ 其实这很简单，在上面我们已经讲了 commit 相关原理，每一次 commit 都会产生一个 commit 文件，那这样我们可以将每个 commit 看作是一个节点，分支的移动变更其实就是在节点中不停的切换，那对应到 Git 的实现中呢，其实就是在分支文件中保存不同的 commit 文件 ID。 这里可以去 Git 可视化网站体验一下：Learn Git Branching 如果仔细观察 .git 目录，你就会发现目录下 HEAD 是指向当前工作区的版本，而分支则在 refs&#x2F;heads 路径下。 我们通过实践来感受，在上面的基础上，建立 dev 分支，并且更改 Readme 内容后并提交： [root@VM-16-3-centos GitStudy]# git checkout -b dev Switched to a new branch 'dev' [root@VM-16-3-centos GitStudy]# vim Readme.md [root@VM-16-3-centos GitStudy]# git add . [root@VM-16-3-centos GitStudy]# git commit -m \"dev update\" 先查看一下 log： [root@VM-16-3-centos GitStudy]# git log commit 2f4e8231544311974d9ddd5db47ec3cc6dcc462f Author: happysnaker &lt;1637318597@qq.com> Date: Sat May 21 15:59:32 2022 +0800 dev update commit 3c8de40439f7917b188e7c3271409794ec635ef3 Author: happysnaker &lt;1637318597@qq.com> Date: Sat May 21 15:40:09 2022 +0800 update readme commit 854ebf0cbe82f7c6b06c35dfb48d5af2149d4643 Author: happysnaker &lt;1637318597@qq.com> Date: Sat May 21 15:26:44 2022 +0800 create readme 这次在 dev 分支的提交 ID 是 2f4e8231544311974d9ddd5db47ec3cc6dcc462f，现在我们打印 .git 路径树： 首先来看看这次最新提交的 commit 文件内容： [root]# git cat-file -p 2f4e8231544311974d9ddd5db47ec3cc6dcc462f tree 1f16b25244adda7d4590841975baabda6a41c328 parent 3c8de40439f7917b188e7c3271409794ec635ef3 author happysnaker &lt;1637318597@qq.com> 1653119972 +0800 committer happysnaker &lt;1637318597@qq.com> 1653119972 +0800 dev update 然后我们打印一下 HEAD 文件、refs&#x2F;heads&#x2F;dev 和 refs&#x2F;heads&#x2F;master 文件看看里面的内容到底是什么： [root@VM-16-3-centos GitStudy]# git cat-file -p HEAD tree 1f16b25244adda7d4590841975baabda6a41c328 parent 3c8de40439f7917b188e7c3271409794ec635ef3 author happysnaker &lt;1637318597@qq.com> 1653119972 +0800 committer happysnaker &lt;1637318597@qq.com> 1653119972 +0800 dev update 发现 HEAD 文件和本次 commit 文件是一致的，这很正常，HEAD 是你当前的工作版本，因此 HEAD 与当前提交是一致的，来看看分支文件： [root@VM-16-3-centos GitStudy]# git cat-file -p master tree ce81273cc3c46c1e7543355e01010685aab9412d parent 854ebf0cbe82f7c6b06c35dfb48d5af2149d4643 author happysnaker &lt;1637318597@qq.com> 1653118809 +0800 committer happysnaker &lt;1637318597@qq.com> 1653118809 +0800 update readme [root@VM-16-3-centos GitStudy]# git cat-file -p dev tree 1f16b25244adda7d4590841975baabda6a41c328 parent 3c8de40439f7917b188e7c3271409794ec635ef3 author happysnaker &lt;1637318597@qq.com> 1653119972 +0800 committer happysnaker &lt;1637318597@qq.com> 1653119972 +0800 dev update 你发现了吗？master 分支仍然是指向上一次的版本更改，这其实就是 Git 版本管理的原理，Git 维护当前所处的分支，并且会实时更新 HEAD 文件和 ref&#x2F;heads 目录下当前分支的内容，而其他分支文件内容不会更改，所以其他分支是察觉不到本次更改的，当分支切换时，HEAD 也将切换到对应分支，实现了隔离管理。 试着切回 master 分支，并查看 HEAD： [root@VM-16-3-centos GitStudy]# git checkout master Switched to branch 'master' [root@VM-16-3-centos GitStudy]# git cat-file -p HEAD tree ce81273cc3c46c1e7543355e01010685aab9412d parent 854ebf0cbe82f7c6b06c35dfb48d5af2149d4643 author happysnaker &lt;1637318597@qq.com> 1653118809 +0800 committer happysnaker &lt;1637318597@qq.com> 1653118809 +0800 update readme 发现 HEAD 也切换到了之前 master 的版本，在这种状态下，我们当然是感知不到 dev 分支所做的更改，因为当前 commit 指向的 blog 文件还是之前的版本。 那合并分支呢？合并分支的原理其实也很简单，例如在 master 分支下执行git merge dev命令，这将选取两者分支中最新的一次提交，并将当前所处的分支快速推进到最新的提交版本。 [root@VM-16-3-centos GitStudy]# git merge dev Updating 3c8de40..2f4e823 Fast-forward Readme.md | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) [root@VM-16-3-centos GitStudy]# git cat-file -p master tree 1f16b25244adda7d4590841975baabda6a41c328 parent 3c8de40439f7917b188e7c3271409794ec635ef3 author happysnaker &lt;1637318597@qq.com> 1653119972 +0800 committer happysnaker &lt;1637318597@qq.com> 1653119972 +0800 dev update 看，合并后，master 分支被推进到最新的版本了！本地提交是不会产生冲突的，但 push 到远程时，发现远程分支版本已经不是上一次 clone 时的版本了，那么便会产生冲突，因此在 push 之前我们通常需要 git pull 拉取最新的更改并合并之后再做提交，在这一步时，如果远程分支与你恰好修改了同一个文件，这会产生冲突，Git 会提示你并将冲突文件展现出来，这包含双方的修改，你可以自行选择删除或修改一些内容。解决冲突后，分支已经合并，现在可以正常 push 了。 标签管理标签管理原理非常简单，每个标签文件(refs&#x2F;tag 目录下)其实就是保存着一个稳定版本的 commit 文件，标签通常不会被修改。 常用语句 git remote add orgin &#x67;&#x69;&#116;&#x40;&#x67;&#105;&#116;&#x68;&#117;&#x62;&#46;&#x63;&#111;&#109;:username&#x2F;repo.git，通过 ssh 建立远程仓库。 git push -u origin master，提交到远程仓库的 master 分支。 git merge xxx，将当前分支与 xxx 分支合并，并将当前分支推进到最新的分支。 git pull，等价于 git fetch + git merge，可以通过 –rebase 参数使分支树更加整洁。 git rebase xxx，同 merge，rebase 将会使分支树更加整洁，通过 -i 参数可交互式的调整分支版本。 git commit –amend，修改 commit 的信息。 git reset，将 HEAD 推进到对应版本，例如 git reset HEAD^，这将推进到 HEAD 的上一个版本，注意，一旦 HEAD 和你当前分支的 commit 分离，此时 Git 不允许你提交。 git cat-file -p filename，查看 git 目录下文件内容。 git log，打印 commit 日志。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"HTTPS","slug":"HTTPS","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.976Z","comments":true,"path":"post/d3cd.html","link":"","permalink":"http://example.com/post/d3cd.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记 HTTPS什么是 HTTPSHTTPS （全称：Hyper Text Transfer Protocol over SecureSocket Layer），是以安全为目标的 HTTP 通道，在HTTP的基础上通过传输加密和身份认证保证了传输过程的安全性。 HTTPS 中，使用传输层安全性(TLS)或安全套接字层(SSL)对通信协议进行加密，即 HTTP + SSL(TLS) &#x3D; HTTPS。 阅读本文之前，希望你已经掌握了计算机网络方面的安全知识，可参考我的博客计算机网络中的安全。 TLS 是 SSL3.0 的改进版本，它们之间的主要差别是加密的算法不同，从思想上看，它们的语义是相同的。由于 TLS 是基于 SSL 发展过来的，在下文中我们仅采用 SSL 以指代 SSL&#x2F;TLS。 SSL 握手SSL 握手阶段是整个 SSL 协议最复杂也是最核心的阶段，SSL 在握手阶段中协商算法与密匙，就像我们在计算机网络中的安全所说的，握手阶段采用的是非对称密码体制，而一旦算法与密匙协商完成，通信则使用对称密码体制。 在这一步中，SSL 利用非对称密码加密体制以协商供通信使用的对称密码体制加密的算法和密匙 和 用于报文完整性加密(MAC)的算法和密匙，此外为了防止重放攻击，SSL 采用生成随机数的方式去应对，具体的握手步骤如下： 客户明文发送它支持的密码算法的列表，连同一个客户的随机不重数。 从客户发来的列表中，服务器选择一种公匙算法(例如RSA)、一种对称算法(例如AES、DES) 和一种MAC算法(例如SHA-3)。服务器把它的算法选择和证书以及一个服务器的不重数发送(明文)给客户端，服务器还会签名还报文，此时算法协商完毕。 服务器可以要求客户端发送它的证书。 服务器生成一个前主密匙（Pre-Master Secret，PMS，预主密匙），发送给客户端。 客户端验证该证书，提取服务器公匙，生成一个前主密匙（Pre-Master Secret，PMS，预主密匙），用服务器的公匙加密 PMS，然后发送给服务器。 如果服务器要求客户端发送证书，这一步还必须发送证书。 使用 SSL 标准定义密匙导出函数，客户端与服务器同时利用双方的不重数从各自收到的 PMS 中导出相同的主密匙（Master Secret，MS）。从 MS 中导出双方需要的对称密匙以及MAC密匙，到此密匙协商完毕。 客户端利用 MAC 密匙发送所有握手报文的一个 MAC（报文摘要）。 服务器利用 MAC 密匙发送所有握手报文的一个 MAC（报文摘要）。 注意，根据上述步骤，这里有 4 个密匙，EA、MA、EB 和 MB，分别是发送方和接收方的会话密匙和 MAC 密匙，双方共享四个密匙，例如 A 利用 EA、MA 发送加密消息给 B，B 利用 EA、MA 解密；而 B 利用 EB 和 MB 发送加密消息给 A，A 利用 EB 和 MB 解密。 双方发送利用各自的密匙发送消息，使得整个会话安全更为健壮，即使有一方的密文被破解，另一方的密文仍然无法破解。 在下文中，我们可能会抽象的将这 4 个密匙当作两个密匙，E 和 M。 分析： 不重数是有必要的，利用不重数可以防止重放攻击，如果黑客原封不动的重放报文，那么服务器将会拒绝此次连接，因为不重数重复。你可能会有疑问：黑客不可以更改不重数吗？正是考虑到了这一点，所以主密匙的生成需要利用到不重数，如果不重数不同，生成的密匙肯定是不同的，密匙不同，黑客自然无法之前破解双方通信的内容了。 数字签名也是有必要的，这是为了防止黑客劫持该证书报文，而伪装成服务器与客户端通信(黑客会更改不重数)。 最后的报文摘要也是必要的，这是为了防止黑客篡改报文，例如黑客劫持步骤 1 中的报文，删掉其中比较强的算法，迫使服务器与客户端选择较弱的算法通信。 密匙交换 ECDH算法 我们假定双方只需要两个密匙，一个密匙用于对称密码加密，定义为 E，一个密匙用于 MAC 加密，定义为 M，而不是前面说的 4 个。 前主密匙怎么生成的？主密匙又是怎么生成的？如何重主密匙中导出双方需要的密匙？ 我们先回答第三个问题：切分主密匙即可，换句话说，主密匙就是就是 E 和 M 的合并字符串，E 与 M 的长度在协商算法时就已经确认了，例如 E &#x3D; 101，M &#x3D; 011，则主密匙可能是 101011，切分时按照长度切割即可。 现在我们来讨论如何生成 PMS 以及如何从 PMS 中解析出 MS，ECDH 算法已经成为了当下主流的实现，因此我们主要介绍一下 ECDH 算法。 我们定义：$$S_A \\ 是客户端生成的一个私匙 \\S_B \\ 是服务器生成的一个私匙 \\P \\ 是一个大质数, \\ G \\ 是一个整数, \\ P、G是公开的$$假设 PMSA是客户端生成发送给服务器的前主密匙，PMSB是服务器生成发送给客户端的前主密匙，那么其计算公式为：$$PMS_A &#x3D; G^{S_A} mod \\ P \\PMS_B &#x3D; G^{S_B} mod \\ P \\$$那么经过交换后，客户端握有 PMSB，而服务器拥有 PMSA，现在它们分别对收到的 PSM 进行如下运算：$$客户端：(PMS_B)^{S_A} \\ mod \\ P &#x3D; (G^{S_B} mod \\ P)^ \\ mod \\ P &#x3D; K_1 \\服务器：(PMS_A)^{S_B} \\ mod \\ P &#x3D; (G^{S_A} mod \\ P)^ \\ mod \\ P &#x3D; K_2$$在计算机网络中的安全安全中我们证明过一个结论：$$(m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; (m^e \\ mod \\ n)^d \\ mod \\ n$$因此可以得：$$K_1 &#x3D; K_2 &#x3D; K$$即，双方根据收到的 PSM 经过运算后会得到一致的数据，这个 K 就是我们要的主密匙 MS，从主密匙中就可以切分出我们具体需要的密匙了！而**密匙 SA、SB的生成依赖于各自的随机数(不等于随机数)**，P、G 是 SSL 标准规定的，这样我们就彻底揭开了密匙交换过程的面纱。 在 SSL 握手的第 4 步中，注意到服务器发送给客户端 PSMB 是没有加密的，这意味着服务器的 SB 是暴露在外的，然而即使黑客得知了 SB 也无能为例，因为在生成 MS 的计算中，是同时需要 SA、SB 的，而 SA 是加密的，因为客户发送的 PSMA 会用服务器的公匙加密，只有服务器自己能够解密，然后得出 SA，黑客无法获取 SA ，故我们可以保证整个密匙交换过程是安全的！ 数据传输运输层仍然是使用 TCP 传输，这就可能会遭受 重排序攻击，因此 SSL 设计了 SSL 记录以防止该攻击（同时也用于关闭连接），SSL 记录位于应用层与传输层之间，应用层的数据需要被处理成 SSL 记录才会交给 TCP 层。 类型。该字段指示这是 SSL 握手报文，还是通信报文，或是 SSL 连接关闭报文。 版本。指示 SSL 报文协议，例如 TLS。 长度。指示 SSL 记录的长度，以便 SSL 处理程序从 TCP 字节流中提取出 SSL 记录（解决粘包问题）。 数据。要发送的应用程序的数据。 MAC。对整个 SSL 记录的摘要，注意，这个摘要还包含了序号。 SSL 采用序号解决重排序攻击，SSL 记录除 数据 和 MAC 外都是明文发送的（但它们都可以通过 MAC 验证，所以无须担心这些明文被修改），序号没有一个显示的字段指示，而是被保存在 MAC 中，这样更安全。双方遵守 SSL 标准以获取&#x2F;添加序号，例如可以选择 MAC 中的前 4 字节作为序号。发送方每次发送数据都会递增 SSL 序号，初始时它为 0，序号被加密在 MAC 中，通过这种方式以防止重排序攻击。 中止连接通过 SSL 记录中的类型以发出中止连接，无须担心黑客更改类型或仿造发出中止报文，因为加密的 MAC 对它进行了鉴别。服务器应答后客户端即可发出 TCP FIN。 SSL 握手抓包实践随便搜一个 HTTPS 的网站，例如：curl https://www.baidu.com，得到数据包如下： 10.252.251.95 是我自己的 IP，14.215.177.38 是服务器 IP Cilent Hello 包 Server Hello 包 Certificate 包 Server Key Exchange Server Hello Done 包这个没啥说的，就是结束 Server Hello。 Cilent Key Exchange, Change Cipher Spec, Encrypted HandShack Message 包 看名字也能猜出个大概，客户密匙交换、更改密码规范以及对整个客户端握手的MAC报文摘要，更改密码规范我们没说，这是 TLS 引入的新规范，即要求通信双方每隔一段时间后就更换新的密匙，以加强安全，本文会略过对该规范的讲解。 Server Encrypted HandShack Message剩下的就是服务器生成的握手报文摘要了，整个握手环节到此结束。 请比对一下我们之前说的步骤，看看是否吻合，结果应该是一致的，只是某些报文合并成一个报文了或者一些报文拆分成多个报文。 总结通过理论分析和实践抓包，相信理解 HTTPS 应该没有任何困难了，我们已经彻底揭开 HTTPS 神秘的面纱。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"HashMap 学习总结","slug":"HashMap 学习总结","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.976Z","comments":true,"path":"post/eb23.html","link":"","permalink":"http://example.com/post/eb23.html","excerpt":"","text":"HashMap 基于 jdk11 构造函数HashMap 支持传入一个初始容量以及扩容因子作为构造参数，有意思的是 HashMap 并不会以我们传入的初始容量作为大小，而是会将第一个大于等于初始容量的 2 的幂作为 Map 的大小，HashMap 的大小永远都是 2 的幂，这有许多好处： 令 N 为 2 的幂，那么 $H \\ % \\ N \\iff H \\ &amp; \\ (N-1) $，位运算比求余运算快得多。 令 N 为 2 的幂，当 $H \\ % \\ N&#x3D;k$ 时，有 $ H \\ % \\ 2N &#x3D; k \\ 或 \\ H \\ % \\ 2N &#x3D; k + N$，也就是说当 Map 扩容时，元素扩容后的位置要么就在原下标，要么就在原下标+N的位置，两个不同下标的元素扩容时绝不会发生冲突，这十分方便。 扩容因子其实就是扩容的阈值，当Map实际元素个数达到 $设定容量 \\times 扩容因子$ 时，将会触发扩容操作，默认的扩容因子是 0.75，这个值是官方推荐的，不至于过大导致扩容难以被触发，如果一直不扩容，那么 Map 中发生哈希冲突的可能性就会越大；也不至于过小导致扩容频繁发生。 插入时逻辑HashMap 中，元素的哈希值是这样产生的： static final int hash(Object key) &amp;#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); &amp;#125; Map 中计算哈希值时，让 key 的 hashCode 与其本身的高 16 位进行亦或得出，这样做的原因是由于在计算索引采用的公式为 $hash &amp; (N-1)$，当 N 较小时，例如 N &#x3D; 8，此时与 N - 1 操作将仅仅采用 hash 的低三位作为下标，而没有利用到 hash 的高位，基于这个原因，HashMap 在设计 hash 时，让哈希的高位在低位上也能有所体现，这样做可以有效减少冲突。 在 jdk1.8 后，当链表长度超过阈值时，就会转换成红黑树，这个阈值在 HashMap 中是 8（第九个元素到来时）： for (int binCount = 0; ; ++binCount) &amp;#123; // 遍历到尾部，没找到，新建节点插入 if ((e = p.next) == null) &amp;#123; p.next = newNode(hash, key, value, null); // TREEIFY_THRESHOLD = 8，大于等于 8 个节点就树化 if (binCount >= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); break; &amp;#125; // 如果找到了就退出，直接更新 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &amp;#125; 在树化的方法中，例如将原来的链表的 Node 转换成 TreeNode，有意思的是 HashMap 中 TreeNode 是继承至 Node 的，因此 next 指向依然是不变的，并且在 TreeNode 中，还增加了一个 prev 字段，这意味着一颗红黑树中还存在一个双向链表。 管不得 Map 这么耗内存。 final void treeifyBin(Node&lt;K,V>[] tab, int hash) &amp;#123; int n, index; Node&lt;K,V> e; if (tab == null || (n = tab.length) &lt; MIN_TREEIFY_CAPACITY) resize(); else if ((e = tab[index = (n - 1) &amp; hash]) != null) &amp;#123; // 获取tab[i] TreeNode&lt;K,V> hd = null, tl = null; do &amp;#123; // 将每个节点转换成 TreeNode TreeNode&lt;K,V> p = replacementTreeNode(e, null); if (tl == null) hd = p; else &amp;#123; p.prev = tl; // 链上前一个节点 tl.next = p; &amp;#125; tl = p; &amp;#125; while ((e = e.next) != null); if ((tab[index] = hd) != null) hd.treeify(tab); // 遍历元素插入红黑树 &amp;#125; &amp;#125; 注意到 tab.length &lt; MIN_TREEIFY_CAPACITY 判断，当哈希表的大小小于 64 时，此时不会树化而是优先扩容，扩容也能有效缓解哈希冲突的情况。 因此树化的条件是：链表元素大于 8 个，并且哈希表大小大于等于 64 可以发现 HashMap 在插入链表时采用的是尾插法，而如果已经转换成树了，HashMap 也有对应的分支： else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V>)p).putTreeVal(this, tab, hash, key, value); 现在，就是红黑树插入的逻辑了。 红黑树的插入回顾一下红黑树的知识点： 根节点一定是黑的 红色节点的孩子一定是黑的 从一个节点到任意一个叶子节点不同路径上的黑色节点数目都是一样的 如果采用自底向上的插入方法，我们首先要定位待插入的位置，然后向上平衡。 为了保证第三点要素，新插入的节点必须是红色的，然后考虑所有的情况： 父节点为空：此时自身为根节点，变为黑色插入。 父节点为黑色：自身为红色节点，不会破坏红黑树的性质，直接插入。 父节点为红色（这意味着祖父节点必定是黑色的）： 叔叔节点为空或者为黑色：此时需要旋转，并且父节点和祖父节点都需要变色。 叔叔节点为红色：将叔叔节点和父节点变为黑色，祖父节点变为红色，颜色翻转，由于祖父节点变为红色，因此祖父节点可能不平衡，对祖父节点继续向上循环。 瞅瞅 HashMap 中的源码，首先是查找，查找就是简单的二叉查找树的查找，一个问题是对于 Object 的 key，要如何去比较大小呢？在树化的逻辑中，任何元素都是不同的，也就是说一定具有可比性，HashMap 的做法是： 首先比较哈希值。 哈希值相等的话，如果类型实现了 Comparable 的接口话，调用 Comparable 比较。 如果还相等，比较它们的类名（字符串比较）。 如果还想等，则调用 System.identityHashCode 方法比较它们地址大小。这不可能相等，此方法类似于 C 语言的取址符，不同对象的地址一定是不同的！ 一旦找到对应的位置后，则开始向上平衡： static &lt;K,V> TreeNode&lt;K,V> balanceInsertion(TreeNode&lt;K,V> root, TreeNode&lt;K,V> x) &amp;#123; // 待插入节点默认红色 x.red = true; for (TreeNode&lt;K,V> xp, xpp, xppl, xppr;;) &amp;#123; // 父节点空，自己作为根，直接返回 if ((xp = x.parent) == null) &amp;#123; x.red = false; return x; &amp;#125; // 父节点黑色，直接返回 else if (!xp.red) return root; xppl = xpp.left; // 那么父节点为红色 // 父节点作为左节点，需要一次 L型旋转(右旋) if (xp == (xppl)) &amp;#123; // 父节点是左，叔叔节点就是右了 // 如果叔叔节点是红的，那么颜色翻转，x = 祖父节点，继续循环 if ((xppr = xpp.right) != null &amp;&amp; xppr.red) &amp;#123; xppr.red = false; xp.red = false; xpp.red = true; x = xpp; &amp;#125; // 否则要旋转 else &amp;#123; // 如果 x 在右边，那么就是 LR 型，需要先进行一个 R型旋转（左旋） if (x == xp.right) &amp;#123; root = rotateLeft(root, x = xp); xpp = (xp = x.parent) == null ? null : xp.parent; &amp;#125; // 然后来一次 L 型旋转，父节点和祖父节点变色，这里作了健壮性判断 if (xp != null) &amp;#123; xp.red = false; if (xpp != null) &amp;#123; xpp.red = true; root = rotateRight(root, xpp); &amp;#125; &amp;#125; &amp;#125; &amp;#125; else &amp;#123; // 这里就是 R 型了，一样分析 &amp;#125; &amp;#125; &amp;#125; 扩容时逻辑当数组实际大小达到一个阈值时，将触发扩容： if (++size > threshold) resize(); threshold 其实就是设定的大小乘以扩容因子： newThr = oldThr &lt;&lt; 1; if (newThr == 0) &amp;#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &amp;#125; threshold = newThr; 上面这段代码逻辑是在 resize 函数中的，也就是说 threshold 其实等于新数组大小乘扩容因子，而新数组大小为原来的两倍。 扩容时其实就是新建一个两倍与旧数组大小的新数组，然后将旧数组中的元素全部拷贝进新数组。前面讲过，由于如果元素原来的下标为 i，那么在新数组中该元素的下标要么为 i，要么为 i + n，这意味着，原先一个桶中的一系列元素可以可以分为两组，一组在 i 中，一组在 i + n 中： for (int j = 0; j &lt; oldCap; ++j) &amp;#123; Node&lt;K,V> e; if ((e = oldTab[j]) != null) &amp;#123; oldTab[j] = null; else if (e instanceof TreeNode) // 执行树的逻辑 ((TreeNode&lt;K,V>)e).split(this, newTab, j, oldCap); else &amp;#123; // preserve order Node&lt;K,V> loHead = null, loTail = null; Node&lt;K,V> hiHead = null, hiTail = null; Node&lt;K,V> next; do &amp;#123; // 将元素分为两组，一组 low，一组 hi &amp;#125; while ((e = next) != null); if (loTail != null) &amp;#123; loTail.next = null; newTab[j] = loHead; // low 链表放在 j 处 &amp;#125; if (hiTail != null) &amp;#123; hiTail.next = null; newTab[j + oldCap] = hiHead; // hi 链表放在 j + n 处 &amp;#125; &amp;#125; &amp;#125; &amp;#125; 在 jdk1.7 中，扩容时是一个一个元素使用头插法扩容的，在多线程情况下可能会产生死锁，jdk1.8 中是先得出两个链表，然后直接接入，从而解决这个 BUG。 对树扩容的逻辑是类似的，因为之前说过，一个树中蕴含着一个链表，因此逻辑也是类似的，不过树中有一些额外的逻辑： if (lc &lt;= UNTREEIFY_THRESHOLD) tab[index] = loHead.untreeify(map); // UNTREEIFY_THRESHOLD = 6 一旦数目小于等于 6 个，树就会退化成链表。 删除时逻辑查找时逻辑就不赘述了，删除时主要看看树退化的条件： if (root == null || (movable &amp;&amp; (root.right == null || (rl = root.left) == null || rl.left == null))) &amp;#123; tab[index] = first.untreeify(map); // too small return; &amp;#125; 移除树元素退化时并不是以 6 个为基准退化，这与上诉不同，最少时，可以为 4 个。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"JIT 即时编译及优化技术","slug":"JIT 即时编译及优化技术","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.976Z","comments":true,"path":"post/467a.html","link":"","permalink":"http://example.com/post/467a.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 JIT 即时编译及优化技术前言我相信很多人都知道 Java 是一门解释性语言，不同与 C&#x2F;C++，Javac编译器将 .java 文件编译成 .class 文件，然后由 JVM 运行时读取 .class 指令，一条一条的解释指令，将 .class 指令逐条的翻译成机器码运行，这有有点也有缺点，让我们来具体探讨一下此方面的点点滴滴。 即时编译编译与解释是不同的概念，上面我们说解释是将字节码在运行时逐条地翻译成机器码执行，而编译是提前一次性地翻译成机器码，这样就无需运行时去慢慢的解释了，虽然增加了编译的时间，但运行效率却大大提高了。 而且，编译后的机器代码是完全可以复用的，通俗点讲，经过编译后的机器码是多次运行的，而只需编译一次；而对于解释型语言来说，无论运行多少次重复代码，都需要一条一条的去解释执行。这就是JVM编译优化的思考方向：提前编译热点代码。 为了提高热点代码的执行效率，在运行时，虚拟机将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，完成这个任务的编译器称为即时编译器（Just In Time Compiler），简称 JIT 编译器。 热点代码探测什么会成为热点代码？ 被多次调用的方法。一个方法被调用得多了，方法体内代码执行的次数自然就多，成为“热点代码”是理所当然的。 被多次执行的循环体。一个方法只被调用过一次或少量的几次，但是方法体内部存在循环次数较多的循环体，这样循环体的代码也被重复执行多次，因此这些代码也应该认为是“热点代码”。 如何检测热点代码？ 基于采样的热点探测：采用这种方法的虚拟机会周期性地检查各个线程的栈顶如果发现某个（或某些）方法经常出现在栈顶，那这个方法就是“热点方法” 优点：实现简单高效，容易获取方法调用关系（将调用堆栈展开即可） 缺点：不精确，容易因为因为受到线程阻塞或别的外界因素的影响而扰乱热点探测 基于计数器的热点探测：采用这种方法的虚拟机会为每个方法（甚至是代码块）建立计数器，统计方法的执行次数，如果次数超过一定的阈值就认为它是“热点方法” 优点：统计结果精确严谨 缺点：实现麻烦，需要为每个方法建立并维护计数器，不能直接获取到方法的调用关系 大多数虚拟机往往采用第二种方法，既然有两种代码(方法和循环体)可能会成为热点代码，那么也会存在两种计数器： 方法调用计数器：这个计数器用于统计方法被调用的次数。默认阈值在 Client 模式下是 1500 次，在 Server 模式下是 10000 次。 回边计数器：统计一个方法中循环体代码执行的次数。具体的，在遇到控制流向后跳转的指令会被记为回边。 解释一下控制流向后跳转的指令会被记为回边这句话，这里的向后指的是时间向后，考虑下面循环代码： flag = xxx; while (flag) &amp;#123; do...somthing &amp;#125; 事实上这种循环代码如果编译后大概是这个样子: flag = xxx; do: do...somthing if (flag) &amp;#123; goto do; &amp;#125; 可以看到循环体编译后会存在一个 goto 控制流跳转，回边检测就是检测类似的控制流。 当计数器超过阈值时，如果已经存在编译的版本，则直接运行编译的版本；否则，JVM就会提交一个 OSR 编译请求，请求即时编译器编译热点代码，然后将计数器的值降低至阈值之下，等待编译完成。 编译优化技术我们都知道C语言中可以通过开启 -o1 -o2等参数开启编译优化，编译优化会消耗较长的时间，但优化后的代码质量高，运行效率高，Java官方也一直在不停的提高即时编译器的优化效果。 Java中存在两种即时编译器，即C1、C2编译器，C1是客户端下的编译器，此类编译器通常不会进行过多的优化，只是正常的编译代码，编译速度快，但运行效率一般；C2是服务器下默认的编译器，此类编译器往往会进行大量的优化操作，编译速度缓慢，但编译后运行效率高。 语言无关的经典优化技术之一：公共子表达式消除如果一个表达式 E 已经计算过了，并且从先前的计算到现在 E 中所有变量的值都没有发生变化，那么 E 的这次出现就成为了公共子表达式。对于这种表达式，没必要花时间再对它进行计算，只需要直接使用前面计算过的表达式结果代替 E 就可以了。 例子：int d = (c * b) * 12 + a + (a + b * c) 可能会被替换为： int d = E * 12 + a + (a + E)，此时 b * c 只会被计算一次。 语言相关的经典优化技术之一：数组范围检查消除Java语言是相对安全的语言，这是因为 Java 语言作为很多隐式的判断，例如在访问数组时 JVM 会先进行判断，判断下标是否合法；又例如进行除法前，Java 会先判断除数是否为0……如果不合法，Java会友善的抛出异常提醒程序员，而程序员可以捕捉这次异常。但对于 C&#x2F;C++ 开发者就没那么幸运了，一旦发生异常，C&#x2F;C++并不会进行这些检查，如果数组真的越界了，那么就非法操作了其他内存的数据，程序却不会停止，除非访问了操作系统禁止访问的段，这是相当糟糕的。 但 Java 多了许多的隐式判断，这也导致了“Java天生就慢人一等”，一个优化技术是，如果在编译器就确保操作是合法的，则可以去掉这些隐式的判断。 例如: int[] a = new int[3]; a[2] = 1; 像上面这种代码编译器就能确定是合法的，则可直接去掉判断这一类字节码不编译。 最重要的优化技术之一：方法内联方法内联是编译优化技术之母，即将方法体原封不动的“复制”到发起调用的方法之中，从而避免真实的方法调用，为其他优化技术打下基础。例如： static void foo(Object o) &amp;#123; if (o != null) &amp;#123; do.... &amp;#125; &amp;#125; //测试的代码 static void test() &amp;#123; Object o = null; foo(o); &amp;#125; //内联的 test 代码 static void test() &amp;#123; Object o = null; if (o != null) &amp;#123; do.... &amp;#125; &amp;#125; //通过方法内联后，编译器可以消除无用代码，即不会执行 test() 代码 但是Java中的方法内联是非常困难的，原因在于Java中几乎所有的方法都是虚方法，可能在父类或者子类中有不同的实现，Java中只有对构造器、静态方法可能会展开内联。C 语言中不存在虚方法，因此 C 语言可以达到极高的优化效率。 但在 JIT 技术越来越成熟的今天，JIT 可以在运行时确定甚至是预测虚方法，然后利用 JIT 即时编译进行方法内联，由于 JIT 是 JVM 运行时编译，即使预测出错也可以 “变量回归（归零）”，重新开始运行，这是纯编译器无法做到的。 函数内联的有点很明显：避免过程调用（参数保存等工作，内核态切换），将过程间分析转为过程内分析。 函数内联也是有缺点的：会使函数变得庞大，原本几行的函数内联后可能变得几百行，占用内存（递归函数将无限大），并且存放 CPU 指令缓存时可能会导致更多的不命中。 最前沿的优化技术之一：逃逸分析Java语言所有对象都在堆上分配，这引起不少人的诟病，有时候我们仅仅只是想简单的使用一个对象中的一个变量或者一个方法，却不得不去 Java 堆中分配，但要知道 Java 垃圾回收是需要耗费大量时间的，甚至是 “STW” 级别的，如果一个对象在方法栈帧中不会逃逸，即不会被其他方法或其他线程访问，那么该对象被认为是不共享的，可以在栈上进行分配，减轻垃圾回收的压力。 如果能证明一个对象不会逃逸到方法或线程之外，也就是别的方法或线程无法通过任何途径访问到这个对象，则可以为这个变量进行一些高效的优化： 栈上分配：将不会逃逸的局部对象分配到栈上，那对象就会随着方法的结束而自动销毁，减少垃圾收集系统的压力。 同步消除：如果该变量不会发生线程逃逸，也就是无法被其他线程访问，那么对这个变量的读写就不存在竞争，可以将同步措施消除掉。 标量替换：标量是指无法在分解的数据类型，比如原始数据类型以及reference类型。而聚合量就是可继续分解的，比如 Java 中的对象。标量替换如果一个对象不会被外部访问，并且对象可以被拆散的话，真正执行时可能不创建这个对象，而是直接创建它的若干个被这个方法使用到的成员变量来代替。这种方式不仅可以让对象的成员变量在栈上分配和读写，还可以为后后续进一步的优化手段创建条件。 例如P p = new P(); int x = p.x; return x;这段代码，如果确定p不会逃逸，那么可能会直接进行标量替换，JVM不会分配P对象，而是直接分配 x 字段基本类型。 逃逸分析的论文很早就有了，尽管如此，逃逸分析仍然是项复杂的技术，例如下面代码： class Test &amp;#123; private Strint str; public String getStr()&amp;#123;return str;&amp;#125; public void test() &amp;#123; String s = new Str(); str = s; System.out.println(str); &amp;#125; &amp;#125; 可以看到即使 test() 方法内 s 对象看起来好像未发送逃逸，但 s 将自己赋值给了可能发送逃逸的 str，因此 s 仍然有可能会发生逃逸。 Java中使用相对简单的逃逸分析，一旦对象存在发送逃逸的可能性，JVM均认为该对象逃逸，则避免优化。 要怎么判断呢，一个简单的算法是，变量 P： P 是否传递给其他函数 P 是否传递给全局变量 P 是否传递给已经逃逸的对象 如果是，则认为逃逸，否则认为非逃逸。 如果存在函数内联，逃逸的概率将大大降低。 为什么不直接编译所有字节码看了这么多你可能会想，既然编译这么牛逼，为什么JVM不直接把所有字节码一次性全部编译呢？这有如下几点原因，要知道，解释器并非一无是处。 全部编译编译时间长，用户等待时间长，通常客户端模式下不太可取。 解释器是逐条翻译的，这意味着解释器可以可以很好的根据当前记录的信息进行分支预测、虚方法调用预测、循环可能会执行多少次。即使当代处理器也具有分支预测的功能，但和解释器这类动态预测比起来确实天差地别。 正如刚刚所说，解释器可以对虚方法调用进行预测，如果可以预测到虚方法，那么提前编译时就可以进行方法的内联，极大的提高编译优化效果。即使错误的预测了，也可以回归解释器解释，纯编译器可不能如此的任性。 相信未来的很长一段时间解释器和编译器仍然是Java后端编译的共同技术。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"JVM 调优","slug":"JVM 调优","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.978Z","comments":true,"path":"post/175f.html","link":"","permalink":"http://example.com/post/175f.html","excerpt":"","text":"JVM 调优异常排查CPU 占用过高引起 CPU 过高的原因大多数是由于长循环，例如在并发过高的情况下，利用 CAS 操作将导致大量空旋，导致 CPU 占用过高。 解决的方法是： 通过top 命令查看 CPU 占用最高的进程。 通过 top -Hp [pid] 查看此进程中 CPU 占用最高的线程。 通过 jstack [pid] | grep [xid] -A 30 命令查看对应线程信息，注意 xid 是第二步中线程 ID 的 16 进制。 现在，可以定位到对应代码片段进行 review 排除错误，通过对 jstack 信息的查看，很显然我们是在 Main 函数中输出出现了问题，事实上也是如此，这段测试代码就是在一个 while 循环中不停的输出。 除了输出对应线程信息之外，还可以通过 jstack -l pid &gt; xxx.txt 命令将对应 Java 进程的所有线程信息输出到 xxx.txt 中，然后可以通过在线网站进行分析，例如 Smart Java thread dump analyzer - thread dump analysis in seconds (fastthread.io) ，这个网站不仅能得出线程信息，还能得出是否发生死锁、是否占用 CPU 等。 OOM 排查这类错误通常需要排查 dump 文件，生成 dump 文件可以使用 jmap + pid 手动生成，但使用最多的还是让 Jvm 检查 OOM ERROR 自动转储 dump 文件，这需要添加如下 jvm 参数： -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=oom.hprof oom.hprof 是存储 dump 信息的文件，为了更快出现 OOM，我们将堆的大小设置的小一点，添加参数 -Xmx50m 设置堆最大大小为 50mb 以便更快出现 OOM。 public static void main(String[] args) throws Exception &amp;#123; List&lt;Object> list = new ArrayList&lt;>(); for (;;) &amp;#123; list.add(new HashMap&lt;>()); &amp;#125; &amp;#125; 测试代码很简单，不停创建 HashMap 对象即可，运行代码： 现在 dump 文件已经被转储，接下来得分析 dump 文件。 说实话，除非时间比较充足，否则自己去读懂 dump 文件是没有太大必要的，可以利用现有的工具进行分析，例如 jdk 自带的 Visual VM 工具，但我更喜欢在页面更加美观、操作更方便的在线网站上分析，例如 World-class heap Dump analysis - Java, Android memory dump analyzer (heaphero.io)。 将 dump 文件提交并分析，很快就能得出是哪里出错了： 调优实战调优参数一下列出几个重要的 JVM 参数（圈起来，要背的）： -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=oom.hprof 表示开启 dump 文件自动转储，触发的条件是 OnOutOfMemoryError，存储的位置为 oom.hprof。 -XX:+PrintGCDetails 或者 -Xlog:gc* 表示打印出 GC 日志，有专门的工具对日志进行分析。 -Xms1024m 设置堆的初始大小，相当于懒加载，通常设置成等于 -Xmx。 -Xmx1024m 设置堆的最大大小，当增大此参数时，可有效防止 OOM 的发生，同时因为堆的总大小增大，GC 发生的频繁程度下降，但由于内存增大，一次 GC 的停顿时间增多。 -Xmn1024m 设置年轻代的初始大小，当减小新生代时，由于 GC 主要发生在新生代，新生代空间减小，GC 发生次数更频繁，虽然 GC 频繁，影响 JVM 性能，但都是新生代的 GC，停顿时间还是比较短的。由于新生代空间减小，可能会导致新生代提前进入老年代（条件是分代年龄和达到空间阈值），这就使得老年代可能会提前触发 GC。 -Xss128k 设置线程栈空间的大小，当程序有明显递归行为时，可适当增加比例。 -XX:SurvivorRatio=8 Eden 和 S 区的比例，大多数情况下只会调小此参数，如果程序不符合 “大多数对象都是朝生夕灭” 的分代假说的话，可能 S 区将无法存放存活的对象，于是将不得不借用老年代的空间，这就导致一部分新生代被移动至老年代区间中，这是违背初衷的，这将会更频繁的触发 FULL GC，这个时候需要调小此参数，但是但此参数越来越小时，E 区变得更小，新生代 GC 也会更加频繁，影响 JVM 性能。 -XX:MaxTenuringThreshold=10 设置晋升老年代的年龄条件，如果程序中对象大多数都是存活很久的对象，可以调小此参数，让对象更快的进入老年代，不然对象将持续占用新生代的空间，变相减少新生代的空间，导致 GC 频繁。 速记规则： 还有一些使用不同垃圾收集器的参数这个不需要背，它们的参数都符合 -XX:+Use[GC_Name] 命名规范，例如：-XX:+UseConcMarkSweepGC 表示使用 CMS 老年代垃圾收集器。 调优实战我们使用最古老的串行化 Serial 垃圾收集器，对 JVM 添加如下参数：-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=oom.hprof -Xmx50m -Xlog:gc* -XX:+UseSerialGC。 测试程序如下： public static void main(String[] args) throws Exception &amp;#123; class Test &amp;#123; String val; public Test(String _val) &amp;#123; this.val = _val; &amp;#125; &amp;#125; List&lt;Object> oldList = new ArrayList&lt;>(); for (int i = 0; i &lt; 1e6; i++) &amp;#123; for (int j = 0; j &lt; 10; j++) &amp;#123; Test young = new Test(\"y-i == \" + i); &amp;#125; Test old = new Test(\"o-i == \" + i); oldList.add(old); if (i > 1e5) &amp;#123; // 移除老年代，让他们被 GC 回收 oldList.remove(0); &amp;#125; &amp;#125; &amp;#125; 在这个例子很简单，不停创建新生代和老年代，当老年代存活的够久时，移除它们，同时为了保证 “大多数对象都是新生代” 的假说，我们按照 10 : 1 的比例创造它们。 在上面这个例子中，新生代内存 : 老年代内存 &#x3D; 15 ：33.8，在这个条件下触发了 33 次 FULL GC，程序运行时能感受到明显的卡顿，现在我们考虑降低 FULL GC 次数。 想要降低 FULL GC，一般得从两个方面入手： 调大新生代的大小，当新生代过小时，更多的新生代对象由于空间不够进入老年代，导致老年代压力过大，触发 FULL GC，因此调大新生代大小是一个解决方案。 调大老年代的大小，这很显然，当老年代大小变大时，FULL GC 频率自然会下降，但一次会需要更多的时间。 调整进入老年代的年龄限制。一方面，如果这个年龄限制过小，将会导致很多新生代进入老年代；另一方面，当限制过大时，本身为老年代的对象可能不得不存留在新生代中，导致新生代空间压力过大，这又回到了条件一。事实上，多数垃圾收集器都会动态的选择年龄限制。 你可能会觉得条件 1 和条件 2 不是冲突的嘛，的确是冲突的，这个例子告诉我们，没有一个绝对正确的决定，改变任意一个参数可能使程序变得更好，也可能使程序变的更坏，这完全取决于程序的性质，因此，像 G1 这种根据历史回收的数据启发式决定回收哪些垃圾的垃圾收集器也许是更好的选择。 回过头来分析，FULL GC 触发频繁，我们可以肯定老年代空间是不够的，但是，这究竟是由于 新生代空间小导致新生代对象进入老年代空间 还是 老年代对象本身过多 导致的，如果是前一种，我们必须调大新生代空间，而如果是后一种，我们把必须调小新生代空间以增大老年代空间，这完全取决于具体的应用程序。 仔细分析代码，程序中新生代是严格意义上的 “朝生夕灭”，young 对象被创建之后在下一个循环中就被抛弃了，因此考虑不太可能是新生代空间小导致的问题，因为存活的新生代对象非常少，GC 总是能清理掉哪些已死的对象。 因此考虑是第二种原因，尝试一下调小新生代大小：-Xmn10m： 完美的决策，竟然没有一次 FULL GC 的发生！由于新生代空间减小，Minor GC 发生次数增多是必然的，但由于没有 FULL GC 发生，总时间是第一次的一半不到。 来试试调大新生代大小：-Xmn20m： 这导致 FULL GC 增多了！FULL GC 次数增多 15 次，总的 FULL GC 时间相较于第一次增加 130ms 了，停顿的时间增加了，但执行的越频繁，平均停顿时间会相对少一点，这里平均停顿时间比第一次少了 1ms 左右。 我们试着调大一下最大堆大小：-Xmx75m： 这非常优秀，看来调大堆大小是个不错的选择，当然，毕竟“钞能力”嘛，但是不是内存越大越好呢？ 我们来试试：-Xmx512m： 的确，总时间变小了，但你发现了吗，这次实验一次 GC 的平均时间是最多的，如果这是 FULL GC，这意味着一次停顿的时间是最大的，这是一个弊端。 这真是矛盾啊，例如你想降低一次 FULL GC 的停顿时间，增加 FULL GC 的执行次数可以有效的降低时间，毕竟时间等于路程除以速度，于是你想让 FULL GC 执行的更频繁些： 减少老年代空间大小似乎达到这个目的，毕竟空间小了，GC 必然要频繁点。 但是减少老年代空间的同时又增大了新生代的空间，一旦新生代空间增大，对象可能在新生代就被回收了，FULL GC 触发次数会变少，当然这是我们乐于接受的结果；但另一方面，一旦新生代空间增大，触发 Minor GC 的次数就少了，别忘了，FULL GC 的触发某些情况下是依赖于 Minor GC 的，当 Minor GC 的次数少了，FULL GC 次数自然也少了。 JVM 调优就是如此矛盾，没有一个绝对的最优解，必须要根据你的程序选择恰当的参数。 索性对于一些明显极端的参数我们可以进行调整，例如堆空间或新生代过小，官方也推出了 G1 这种启发式的垃圾回收器来帮我们管理。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"Java垃圾回收机制与垃圾收集器","slug":"Java垃圾回收机制与垃圾收集器","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.978Z","comments":true,"path":"post/82fa.html","link":"","permalink":"http://example.com/post/82fa.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 Java垃圾回收机制与垃圾收集器前言 首先来思考一个问题： 哪些内存需要回收？ 首先对于栈空间里的内存是无须回收的，因为这一部分内存会随着退出作用域而自动释放，事实上，主要回收的内存是方法区中废弃的常量和不再使用类元数据与堆中未被引用的对象，这一部分内存我们定义为“垃圾”。对于方法区中内存的回收是在回收堆内存时由虚拟机顺带回收的。 接下来，让我们一起来学习JVM是如何回收垃圾的，在此之前，约定在无特殊声明的情况下，默认的虚拟机为当前主流的HotSpot。 判定对象是否存活(标记)只有当一个对象不再被使用后，JVM才可以将其回收，那么如何判定一个对象是否存活呢? 引用计数法引用计数法是一个非常经典的方法，其原理也很简单，即为每一个对象维护一个引用计数，每当该对象被引用时，则自增引用计数，当局部变量修改引用时或局部变量被销毁，递减相应对象的引用计数，当一个对象的引用计数为0时，则代表该对象无引用，判定其为死亡状态。 引用计数的优点在于其实现简单，判定效率也高，例如C++中的智能指针或Python中的垃圾回收都采用了这种方法，但Java几乎所有的主流虚拟机都没有采用这个简单的方法，这是因为引用计数无法保证完全正确，例如经典的循环引用问题。 若此时局部变量放弃对对象的引用，这两个堆对象仍然无法被回收，因为它们之间存在互相引用： public class Test &amp;#123; Object instance = null; public static void main(String[] args) &amp;#123; var a = new Test(); var b = new Test(); a.instance = b; b.instance = a; /*即时移除对对象的引用，引用计数方法仍然无法回收对象*/ a = null; b = null; &amp;#125; &amp;#125; 可达性分析算法思想该算法通过一系列被称为“GC Roots”的根对象作为起点集合，依次扫描这些节点，根据引用关系向下搜索，搜索过程走过的路径称为引用链，如果某一个对象从任何一个GC Roots开始到该对象都不可达时，则判定该对象是不可能再被使用的。 例如上图中 Object 5 和 Object 6 就是已死的对象，通过可达性分析算法则可以避免对象循环引用的问题，例如即时对象5和对象6互相引用，由于与GC Roots之间没有引用链，它们仍然会被回收。 固定可作为GC Roots的对象包括以下几种： 本地栈中具有引用的对象：例如 Object A = new Object();，这里的变量A就是一个GC ROOTS，可以看一看前面引用计数的图，这里的A就是一个栈变量，但其指向了一个堆变量，当退出作用域时，下一次扫描将不会检测到该引用链，具体看下面的OopMap内容。 具有引用的静态类型对象：例如public static Object obj = new Object() ;，这里的obj也会被作为GC ROOTS。 方法区中具有常量引用的对象：例如private String str = &quot;Hello World!&quot;; ，此时str引用了常量池中的对象，str会被作为GC ROOTS以判定常量池中对象是否废弃。 在本地方法栈中JNI引用的对象：该对象可能是一个C或C++指针，不属于Java本地代码，这类对象如果引用了Java堆中对象同样也会被作为GC ROOTS。 Java虚拟机内部的引用：例如基本数据类型引用了对于的class对象。 如果总结来看，除了堆中对象不会作为GC ROOTS，几乎所有引用了堆对象或常量池的对象都会被作为GC ROOTS，但这也不是绝对的，即使是堆中对象也是可能会作为根对象的，这在后面将跨代引用时会提到。 算法步骤可达性分析主要采用三色标记法，按照对象是否被访问分成三种颜色： 白色：表示尚未遍历该对象，如果结束时对象仍为白色，则表示对象不可达。 灰色：表示已经遍历该对象，但还没有遍历该对象的引用，下一次遇到该对象时会继续遍历该对象的引用。 黑色：已经遍历该对象，并且所有引用都扫描过了，下一次遇到该对象时会直接跳过。 整个算法用代码表示大概就像下面这样(自己模拟的，非官方)： class AccessibilityAnalysis &amp;#123; /* key 为对象， value 为对象的引用集合*/ private Map&lt;Object, List&lt;Object>> objMap = null; /* key 为对象， value 为对象的颜色, 0-白色 1-灰色 2-黑色*/ private Map&lt;Object, Integer> colors = null; /*保存结果的集合*/ private Set&lt;Object> result = null; public AccessibilityAnalysis(Map&lt;Object, List&lt;Object>> objMap, Map&lt;Object, Integer> colors) &amp;#123; this.objMap = objMap; this.colors = colors; this.result = new HashSet&lt;>(); for (Object obj : objMap.keySet()) &amp;#123; this.colors.put(obj, 0); &amp;#125; &amp;#125; public Set start() &amp;#123; for (Object obj : objMap.keySet()) &amp;#123; /*对每个根节点开始算法*/ dfs(obj, colors); &amp;#125; for (var it : colors.entrySet()) &amp;#123; //这里标记可达的，也可以标记不可达，排除掉GC ROOTS本身 if (it.getValue() == 2 &amp;&amp; !objMap.containsKey(it.getKey())) &amp;#123; result.add(it.getKey()); &amp;#125; &amp;#125; return result; &amp;#125; public void dfs(Object obj, Map&lt;Object, Integer> colors) &amp;#123; int color = colors.get(obj); /*黑色或灰色表示已搜索过，略过*/ if (color == 2 || color == 1) &amp;#123; return; &amp;#125; /*开始搜索，设置为灰色*/ colors.put(obj, 1); for (Object nextObj : objMap.get(obj)) &amp;#123; dfs(nextObj, colors); &amp;#125; /*搜索完毕，设置为黑色*/ colors.put(obj, 2); return; &amp;#125; &amp;#125; 上述代码是在单线程模式下运行的，在全部节点遍历完之后再获取结果，事实上只需要两种颜色即可；但JVM允许并发标记，此时每个线程遍历完之后就会尝试标记，必须要将灰色节点信息传递给其他线程，以免其他线程直接标记该节点。 对象复活一个对象即使被标记成“死亡”状态也不是一定会被回收的，这涉及JVM回收垃圾的具体步骤。 要真正回收一个垃圾，至少要经历两次标记过程，第一次则运行三色标记法对对象进行标记，随后JVM会进行一次筛选，判定该对象是否有必要执行finalize方法，判定的依据是该对象是否重写方法并且没有执行过该方法，如果没有必要执行，则直接进行回收；如果确实需要执行，该对象会被放置在F-Queue队列中，由JVM创建一条低优先级的线程去执行，稍后JVM会对队列中的对象进行小规模的标记，JVM统计在finalize中的GC ROOTS而避免重新遍历所有GC ROOTS，如果对象在finalize方法中重新关联了一条引用链，那么该对象将会逃脱第二次标记，从而复活。 要注意JVM并不等待finalize成功执行后才去标记，而是等待一小段时间后直接开始标记，而不管方法是否被执行，JVM不能接受一个“垃圾”还疯狂的占用程序运行资源。此外，根据上述判定依据，一个对象不能重复复活，因为finalize方法只会被执行一次。 public class Test &amp;#123; private static Test test = null; public void say() &amp;#123; System.out.println(\"我还活着\"); &amp;#125; @Override protected void finalize() throws Throwable &amp;#123; test = this; &amp;#125; public static void main(String[] args) throws InterruptedException &amp;#123; test = new Test(); test = null; System.gc(); /*finalize优先级很低，等待finalize执行*/ Thread.sleep(200); if (test == null) &amp;#123; System.out.println(\"kill\"); &amp;#125; else &amp;#123; test.say(); &amp;#125; test = null; System.gc(); Thread.sleep(200); /*不允许第二次逃脱*/ if (test == null) &amp;#123; System.out.println(\"kill\"); &amp;#125; else &amp;#123; test.say(); &amp;#125; &amp;#125; &amp;#125; /* sout: 我还活着 kill */ 不过，finalize方法已经被废弃了，这会影响程序性能，try - finally 是更好的选择。 引用概念的完善垃圾收集过程十分依赖于引用链，但在之前，一个对象只有“被引用”和“未被引用”两种状态，对于一些“食之无味，弃之可惜”的对象却无能为力，这与我们生活中的某些现象很类似，例如你还有一些作业要写，你想把主要的任务完成，但对于一些次要的任务，你期望如果有时间就写，没时间就算了，这是一种动态的抉择，而不是处于一定写或一定不写的状态。Java中某些时候也需要这种对象，我们期望还有空间可用时就保留它，否则就清楚它，为此，Java完善了引用的概念： 强引用，绝大多数的引用都是强引用，例如“var obj &#x3D; new Object();”这类引用关系，强引用只要存在，垃圾收集器就永远不会收集该对象。 软引用，软引用即我们上面所描述的一种关系，表示对象有用但非必须，如果JVM还有空间则不会清除对象，一旦JVM空间不足则会回收这部分内存。可以通过把引用赋值给SoftReference来将其转换为软引用，例如“SoftReference sr &#x3D; new SoftReference(obj);”，此时obj便成为了软引用，后续可以通过sr.get()获得对象。 弱引用，这是比软引用更弱的引用，被弱引用关联的对象只能只能存活到下一次GC开始，下一次GC开始时，无论如何都会自动回收掉该内存。类似于软引用，Java提供了WeakReference类来实现弱引用。 虚引用，也称“幽灵引用”，一个对象持有虚引用时，就好比没有任何引用一样，随时都可能被回收，持有虚引用的唯一目的就是在该对象被GC时收到一个系统通知，虚引用可以通过PhantomReference类来实现。 垃圾回收算法上述判定对象存活的过程被称为标记过程，当我们标记一个对象后，接下来就要开始真正的垃圾回收过程了。 不过在这之前，要说说经典的分代假说理论，毕竟，所有的垃圾回收算法都是基于这些理论的： 弱分代假说（Weak Generational Hypothesis）：绝大多数对象都是朝生夕灭的。 强分代假说（Strong Generational Hypothesis）：熬过越多次垃圾收集过程的对象就越难以消亡。 跨代引用假说（Intergenerational Reference Hypothesis）：跨代引用相对于同代引用来说仅占极少数。 正是由于这些假说，JVM将Java对象分为新生代(young)和老年代(old)，所有对象初始都作为新生代(下面对提到某些大对象除外)，当新生代熬过一定次数的垃圾收集后就会进入老年代，新生代与老年代被放置在不同的区域，根据不同年代采用不同的算法收集垃圾。 标记 - 清除法该算法分为标记和清除两个部分，首先标记所有不可达的对象，然后直接将这些对象清除，要注意这里的清除并不是真的置空，而是取消分配状态，然后将空闲块信息保存至空闲链表中，等到下次再分配。 清除的操作类似于操作系统中的空闲空间分配与回收，读者可自行了解空闲空间分配算法。 标记清除算法的优点是实现简单，但缺点也是很明显的，根据分代假说，绝大多数对象都是朝生夕灭的，这意味着需要更多的时间去标记与清除这些对象，而且，如上图所示，回收后很容易会导致外部碎片，这可能导致下一次分配难以进行。 标记 - 清除法既可以清理新生代也可以用以清理老年代，但由于其种种缺点，标记清除法事实上已经很少被单独使用了。 标记 - 复制法标记 - 复制法解决了标记清除法的缺点，它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块，当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。 如果内存中多数对象都是存活的，这种算法将会产生大量的内存间复制的开销，但对于多数对象都是可回收的情况，算法需要复制的就是占少数的存活对象，而且每次都是针对整个半区进行内存回收，分配内存时也就不用考虑有空间碎片的复杂情况，只要移动堆顶指针，按顺序分配即可。这样实现简单，运行高效，几乎完美解决了标记 - 清除法带来的缺点。 其缺陷也显而易见，这种复制回收算法的代价是将可用内存缩小为了原来的一半，浪费了大量的空间。为解决该问题，IBM公司曾仔细研究过对象存活的比例，发现大部分时候，仅有2%的对象存活下来，由于标记复制法复制的是存活对象，因此完全没有必要按照1：1的比例来分配空间，为此有一种更优雅的标记复制法称为“Appel式回收法”，该算法将新生代区按照 8 : 1 : 1的比例分割。 具体的，将新生代分为一块 Eden 区和 两块 Survivor 区，Eden 区与 Survivor 区大小比例为 8 : 1，当我们分配空间时，只是用 Eden 区和其中一块 Survivor 区，而保留另一块幸存者区作为复制空间，当发起垃圾回收时，将作为分配空间的 Eden 区和其中一块 Survivor 区中的存活对象复制到另一块 Survivor 区中，然后一次性清除 Eden 区和其中一块 Survivor 区(含不可达对象的区)，现在，该 Survivor 又被作为复制区域，等待下一次回收… 在并发复制过程中，对内存的分配会暂时放置在存活区中，这就保证了复制阶段不会出现错误。 但要注意，并不是所有的程序都能保证存活对象能全部装进 Survivor 区，当这种情况发生时，必须要借助老年代的空间以作为担保，标记复制法必须要额外空间担保，因此，标记复制法通常只用于回收新生代。如无特殊说明，后续标记复制法说的都是“Appel式回收法”。 这里还有一个问题，就是对于大对象如何解决？对于较大对象的复制是非常缓慢的，可能会导致较长时间的停顿，给予用户不好的体验，对于这种问题，通常大部分JVM规定超过一定大小的对象将直接进入老年代。 标记 - 整理法老年代由于没有额外的空间担保，并且存活对象过大，复制效率低，无法使用标记复制算法，通常使用标记整理法。 由于没有额外的空间，因此只能在老年代内部实现，为了避免像标记清除法那样产生大量的外部碎片，标记整理法通过将标记存活的对象向空间一侧移动，然后一次性情况存活对象边界指针以外的区域。 由于JVM是基于页实现的，因此标记整理算法的实现是相对简单的，存活对象可以直接覆盖点死亡对象页，虽然实现简单，但由于涉及到大量内存或磁盘读写，并且由于老年代的特殊性(存活对象较多)，这会异常缓慢(我们不能移动死亡对象去整理，因为那样的话存活对象直接仍然有大量的碎片)，在整理的过程中，由于涉及到整个老年代的空间读写，JVM无法支持分配对象，因此必须要暂停所有线程(ZGC打破了牢笼)，由于暂停时间长，这种暂停被设计者形象的描述为“Stop The World”。 由于整理大对象需要较多时间，实际中也通常采用标记清除 + 标记整理法结合使用。 标记整理法有优点也有缺点。何时使用取决于具体的环境。 具体细节JVM主动发起的几乎都是新生代的垃圾回收，而只有当空间不足时才会发起一次老年代的回收或者是 如何确定GC Roots？难道虚拟机要遍历全部的栈空间以及方法区去确定GC ROOTS吗，这样做效率未免太低了些，HotSpot虚拟机采用一组数据结构OopMap(Ordinary Object Pointer，普通对象指针)，OopMap是运行时生成的，对于对象之间的引用，虚拟机在类加载后就会把对象内所有数据计算出来，如果是引用类型，则保存在OopMap中；而对于栈到堆的引用，虚拟机在即时编译阶段(处于运行期)会扫描所有栈帧之间的数据，并把引用保存到OopMap之中(只会在安全点记录这一刻的栈帧信息)，然后，JVM便可以直接扫描OopMap以确定GC ROOTS，所以，OopMap为JVM提供了准确式的垃圾收集。 来思考一下生成OopMap是否可以与用户线程并发运行，答案是可以，但实际成本过高，导致主流虚拟机几乎都是暂停用户线程生成OopMap以开始垃圾收集。要清楚即时编译器会扫描会扫描所有栈帧中的所有数据，考虑并发的情形，当程序进入一个方法时，即时编译器开始收集当前栈帧的所有信息，当信息被收集完成，此时程序恰好退出方法区，这意味着栈帧信息发生了变化，该方法出栈，这导致即时编译器收集到的全是无用、甚至是错误的信息，不仅增加空间成本，还要额外去处理这些无用的、错误的信息，这使得成本代价过于昂贵。 因此，在开始垃圾收集之前，必须要“STW”即暂停用户线程以确定GC ROOTS，这就引入了另一个问题，即何时暂停或者说在程序代码的哪个位置暂停？ 安全点和安全区域我们在确定 GCROOTS 时已经说明了暂停执行的必要性，由于暂停的原因之一是为了保证垃圾收集的安全性，因此称程序暂停的位置为安全点。有了安全点的设定，现在可以添加一条新的规则：程序必须要执行到安全点的位置才可以发起垃圾收集，而不能随意发起。这条规则隐含了一条信息，即在分配内存代码处必须要设置安全点以防内存不够发起垃圾回收。 那么除了在发起内存分配时设置安全点，其他地方该如何设置安全点呢？既不能让程序执行太长时间，这可能会导致内存占用率飙升，也不能频繁的执行，否则会影响性能。 安全点的选定基本上是以程序“是否具有让程序长时间执行的特征”为标准进行选定的——因为每条指令执行的时间都非常短暂，程序不太可能因为指令流长度太长这个原因而过长时间运行，“长时间执行”的最明显特征就是指令序列复用，例如方法调用、循环跳转、异常跳转等，所以具有这些功能的指令才会产生Safepoint。， 这是书上的原文，可能比较难理解，翻译一下就是为了避免线程长时间无法进入安全点，故而在长时间代码片段前后设置安全点。 例如一个超大的循环，一半会在循环回跳（重新进入循环或者说一次循环的末尾）时设定安全点，避免线程因为长时间无法到达安全点而导致停顿时间过长。 安全点一般都是由前端编译器生成的，前端编译器会插入关于安全点的字节码，在进入JVM之前，安全点就已经固定了。 一般会在如下几个位置选择安全点： 循环的末尾 方法临返回前 调用方法之后 抛异常的位置 再来看OpenJDK官方对安全点的定义： 安全点是在程序执行期间的所有GC Root已知并且所有堆对象的内容一致的点。 从全局的角度来看，所有线程必须在GC运行之前在安全点阻塞。 从本地的角度来看，安全点是一个显着的点，它位于执行线程可能阻止GC的代码块中。 大多数调用点都能当做安全点。 总的来说，安全点就是指，当线程运行到这类位置时，堆对象状态是确定一致的，引用关系不会轻易发生变化，JVM可以安全地进行操作，如GC，偏向锁解除等。 现在问题是，由于GC发生时需要暂停线程(不只是单线程收集器，即使是多线程收集器某个阶段也需要暂停线程)，那么如何在 GC 发生时，使所有线程都跑到最近的 Safe Point 上再停下来？ 主要有两种方式： 抢断式中断：在 GC 发生时，首先中断所有线程，如果发现线程未执行到 Safe Point，就恢复线程让其运行到 Safe Point 上，这种方式是由JVM主动控制的。 主动式中断：在 GC 发生时，JVM不直接操作线程中断，而是简单地设置一个标志，让各个线程执行时主动轮询这个标志，发现中断标志为真时就自己中断挂起，然后通知JVM自己到达安全点，一旦所有线程都准备好了，JVM就可以开始垃圾收集了。中断标志被设置在安全点处，因此当线程运行到安全点时，便会挂起自己。 安全区域又是什么？ Safe Point 是对正在执行的线程设定的。如果一个线程处于 Sleep 或中断状态，它就不能响应 JVM 的中断请求，再运行到 Safe Point 上。因此 JVM 引入了 Safe Region。Safe Region 是指在一段代码片段中，引用关系不会发生变化。在这个区域内的任意地方开始 GC 都是安全的。线程在进入 Safe Region 的时候先标记自己已进入了 Safe Region，等到被唤醒时准备离开 Safe Region 时，先检查能否离开，如果 GC 完成了或未开始，那么线程可以离开，否则它必须等待直到收到安全离开的信号为止。 这意味着，休眠或中断代码附近必须被标志为安全区域，安全区域可以是一条代码(指令)，也可以是多条代码(指令)，如果不只一条代码，线程苏醒时可以继续运行，但运行到安全区域边界时，必须要判定GC是否正在进行中，是的话则不允许走出安全区域。 何时开始GC在介绍了安全点之后，你可能会以为线程运行到安全点时就会发生GC，但其实并不是如此，安全点与GC之间是必要不充分关系，GC的发生只有在内存不足下才会发生，除非你手动调用。 对于经典垃圾收集器Serial来说，通常分配内存时会检测新生代内存是否足够，否则开始新生代垃圾收集，就像我们前面说的，一旦Survivor区无法装下需要复制的存活对象，JVM就会检查老年代是否有空间，如果老年代也没有空间，则会发起整堆回收(FULL GC)，如果还不行，则抛出异常。 记忆集与卡表让我们回到标记阶段，现在让我们考虑一个新的问题：跨代引用问题。顾名思义，即老年代对象引用了新生代对象(通常不会说新生代引用老年代，因为GC几乎都是对新生代发起的)。考虑下图情形，JVM通常只对新生代进行垃圾回收，为了节省性能，JVM并不会扫描指向老年代的GC ROOTS，而只会对指向新生代的GC ROOTS进行可达性分析，如果是这样，那么下图中的 Obj 2 将会被错误的回收。 可是如果遍历所有老年代或遍历所有GC ROOTS进行新生代的回收，代价是非常昂贵的，为此，官方提出了记忆集的概念，记忆集是一种用于记录从非收集区域指向收集区域的指针集合的数据结构。此处，记忆集将记录从老年代指向新生代的跨代指针。 记忆集是一种抽象的数据结构，而卡表则是具体的实现。还有其他不同的实现，但卡表已经是目前的主流实现了。 在hotspot虚拟机中，卡表是一个字节数组，数组的每一项对应着内存中的某一块连续地址的区域，如果该区域中有引用指向了待回收区域的对象，卡表数组对应的元素将被置为1，没有则置为0；例如如下代码，某块内存的地址向右移动9位(相当于除以512)定位到一个卡表元素，也就是说，内存中每512字节的连续区域会被定位到同一片卡表区域，如果卡表对应元素为1则代表该512个字节所在区域中有指向的指针。 CARD_TABLE [this address >> 9] = 0; 卡表是精确到一块内存区域的，只要这一块内存区域内有一个跨代引用则对应卡表都会被设置为1，没有精确到一个对象(一个卡表指向一个对象，对象内存在跨代引用则设置1)的原因是，对象通常是小而多的，这意味着需要更多的卡表项，增加了空间成本，而根据分代假说，跨代引用通常是很少的，因此稍微放松限制以节省内存是可以接受的。现在，GC开始时，JVM还会检查卡表，如果卡表项为1，则遍历检查对应的内存区域，找出对应的跨代引用，并把它加入GC ROOTS之中。 注意一个问题，即使像下图这样，并没有实际的引用指向 Obj 3，此时 Obj 3仍然会被加入 GC ROOTS，使得 Obj 2 不会被回收，但这是可以接受的，因为 Obj 2 很快就会进入老年代，跨代引用不存在了，Obj 2 和 Obj 3 会被一起回收。 对老年代的回收呢？老年代肯定也存在跨代引用，但事实上解决这个问题是顺带解决的，由于对老年代发起回收时，往往都需要发起对新生代的回收(因此称为FULL GC)，对新生代的回收需要标记存活的对象，而此时顺带检查一下是否存在跨代引用即可，存在则加入老年代的GC ROOTS。 并发的可达性分析我们想让GC过程与用户线程并发运行，来分析一些这可不可行。 根节点枚举是需要暂停的，其实也可以并发运行，但代价高的难以接受。 可达性分析算法理论上要求全过程都基于一个能保障一致性的快照中才能够进行分析，但后来的科学家们发现标记阶段也是可以并发运行的，只是需要一定的代价进行修正，经过实践发现，这种代价是可以接受的。 一旦标记成功了，清除阶段是可以并发运行的，这不会造成任何问题。 我们主要分析并发的可达性分析，在 深入理解JVM 中有一张很形象的图： 如果是本该删除的对象最终没有删除，这种情况是可以接受的，等到下一次GC时回收即可；但对于本该存活的对象意外删除，这种情况是不可接受的。 来看最后两张图，黑节点增加了一条引用链，但由于灰节点删除了引用链，已经没办法访问该白节点了，现在，用户需要的对象却被我们意外的删除了，这会导致致命的错误，官方称这种情况为 “对象消失”。 Wilson于1994年在理论上证明了，当且仅当以下两个条件同时满足时，会产生“对象消失”的问 题，即原本应该是黑色的对象被误标为白色： 赋值器插入了一条或多条从黑色对象到白色对象的新引用； 赋值器删除了全部从灰色对象到该白色对象的直接或间接引用。 因此，我们要解决并发扫描时的对象消失问题，只需破坏这两个条件的任意一个即可。由此分别 产生了两种解决方案：增量更新（Incremental Update）和原始快照（Snapshot At The Beginning， SATB）。 增量更新要破坏的是第一个条件，当黑色对象插入新的指向白色对象的引用关系时，就将这个新插入的引用记录下来，等并发扫描结束之后，再将这些记录过的引用关系中的黑色对象为根，重新扫描一次。这可以简化理解为，黑色对象一旦新插入了指向白色对象的引用之后，它就变回灰色对象了。 原始快照要破坏的是第二个条件，当灰色对象要删除指向白色对象的引用关系时，就将这个要删除的引用记录下来，在并发扫描结束之后，再将这些记录过的引用关系中的灰色对象为根，重新扫描一次，标记扫描到的对象为存活。这也可以简化理解为，无论引用关系删除与否，都会按照刚刚开始扫描那一刻的对象图快照进行搜索。 这是书上的原文，其实理解起来也很简单，增量更新意味着重新扫描一遍用户更新的引用，看看用户更新了哪条引用，顺着引用将用户指向的对象标记为存活，也就是不改变原来的状态，单独进行一次额外的更新，即增量更新；原始快照对被删除的引用重新遍历，可以抽象的理解为原来的链并没有删除，即一切还是原来的状态。 当进行二次扫描时(增量更新或原始快照)，不能再与用户并发的运行了，否则将会陷入死循环。因此这里并发不是绝对的，但二次扫描的时间是较为短暂的，是可以接受的。 现在还有一个问题是，如何额外记录下并发过程新的增量或旧的删除引用链，在发现这个问题的时候JVM已经比较成熟了，难以更改原来的架构了，因此需要考虑代理模式或装饰者模式，JVM采用了类似于动态代理技术，即写屏障。 要理解增加或删除引用都是发生对象与对象之间，栈上的局部引用不会对并发分析造成问题，而对象成员的复制原本的底层代码就像这样： /** * @param field 某对象的成员变量，如 D.fieldG * @param new_value 新值，如 null */ void oop_field_store(oop* field, oop new_value) &amp;#123; *field = new_value; // 赋值操作 &amp;#125; 现在，通过JVM插入字节码，新的操作可能像下面一样(针对删除引用)： void oop_field_store(oop* field, oop new_value) &amp;#123; pre_write_barrier(field); // 写屏障-写前操作 *field = new_value; //(null) &amp;#125; void pre_write_barrier(oop* field) &amp;#123; oop old_value = *field; // 获取删除前的旧值 remark_set.add(old_value); // 记录原来的引用对象 &amp;#125; 不必惊讶，JVM早就具备插入字节码的功能了，忘了提了，卡表的变脏也是基于写屏障实现的。 Eden 与 Survivo 大小对性能的影响默认情况下，eden 与 survivo 区的比例是 8 : 1 : 1，我们来分析下调大&#x2F;小 eden 区对垃圾收集的性能会有什么影响。 调大 Eden 区的比例 当 Eden 区变得更大时，意味着 survivo 空间也变的更小了，我们可能需要更多的时间去收集新生代的垃圾，但同时，由于 survivo 变小，当 survivo 区占满时，我们不得不去占用老年代的空间，这就会给老年代带来更多的压力，如果老年代空间达到阈值，就会触发 FULL GC，因此，整个的结果是：新生代回收的周期变得更长了，但回收时间也变长了。由于新生代可能过早移到老年代，老年代区压力过大，可能会提前回收，老年代的回收周期变短了，回收的频率和次数提高了，总体性能下降，总体停顿时间增加，但由于检测的比较及时，单次 STW 的时间会相应缩短。 调小 Eden 区的比例的结果与调大 Eden 区的比例是相反的。 垃圾收集器研究完理论之后，是时候来看看具体的实现了。 吞吐量是指用户应用程序线程用时占程序总用时的比例，即:$$吞吐量 &#x3D; \\frac{运行用户代码时间}{运行用户代码时间 + 垃圾收集时间}$$ Serial收集器Serial收集器是HotSpot在Client模式下默认的新生代收集器，也是最基本、发展历史最悠久的收集器。该收集器属于串行收集器，这意味着当开始垃圾收集时必须要暂停所有线程。 Serial收集器对新生代采用标记复制法，GC时，所有用户都必须在安全点处停下来，当 Survivor 区不够时，就像我们之前说的，Serial收集器尝试使用老年代中的空间，如果老年代空间不够，则发起一次FULL GC，FULL GC由 CMS 收集器或 Serial Old 收集器完成。 Serial收集器的优点是简单而高效，并且占用内存很小，但会带来较长时间的停顿，但对于客户端而言，这种停顿是可以接受的，直到现在，Serial收集器依旧是HotSpot在Client模式下默认的新生代收集器。 添加参数-XX:+UseSerialGC以显示指定Serial收集器。 ParNew收集器ParNew收集器只是Serial收集器的一个升级版本，ParNew收集器多线程并发收集，但遗憾的是，这里的并发并不是指与用户线程共同运行，而是并发地清除垃圾。换句话说，ParNew收集器在GC时仍然要暂停用户线程，然后多线程地去清理垃圾，我们在之前讨论过并发性的可达性分析，那时候的并发主要是考虑与用户线程同时运行，要理清楚ParNew收集器并发收集的概念。 要注意并发收集的效率并不是一定就比串行的Serial收集器高，如果只是单核心模拟出来的并发，那还不如直接串行，毕竟线程切换也是重量级别的。但如果处理器核心较多，并发收集的效率就会明显高于串行收集。 Parallel Scavenge收集器Parallel Scavenge收集器与 ParNew收集器十分相像，Parallel Scavenge收集器也是暂停式的，基于标记复制法多线程并发收集，但评价Parallel Scavenge收集器是全自动的、吞吐量优先的收集器。 我们已经提到过吞吐量的概念，Parallel Scavenge收集器允许用户指定一个比例，Parallel Scavenge收集器尽力的去保证程序的吞吐量接近该值，要想提高吞吐量，就得适当提升Eden区的空间，前面介绍过标记复制法的高效性，当我们提高了Eden区的空间时，下一次回收就能在较短的时间内回收更多的垃圾，从而提高吞吐量。 Parallel Scavenge收集器是在服务机下运行效率还不错的收集器。 添加参数-XX:MaxGCPauseMillis=val，val是指定的毫秒数，表示最大GC停顿时间，最小可为0，Parallel Scavenge只是会去尝试降低停顿时间，但Parallel Scavenge更关注吞吐量。 添加参数-XX:GCTimeRatio=val，val是 0 - 100 的值(百分之几)，表示吞吐量，当吞吐量与最大GC停顿时间冲突时，优先考虑吞吐量。 添加参数-XX:+UseAdaptiveSizePolicy表示让虚拟机自动调整 Eden 空间的大小、多大对象进入老年代、多就进入老年代等，虚拟机会尽力的保证一个吞吐量或停顿时间趋近于上述参数。 Serial Old收集器SerialOld收集器是老年代收集器，这个收集器也是串行的，基于标记整理法回收老年代，回收时必须要“STW”，因此难以胜任服务器下的工作，SerialOld收集器一般只存在与客户端模式下。 Parallel Old收集器Parallel Old收集器是服务器端可选的老年代收集器，该收集器的目的是为了提高FULL GC的吞吐量而生，为了实现这个目的，Parallel Old收集器采用并发的标记-整理法以清理老年代，但注意这里仍然要暂停用户线程，并发仅仅只是为了加快清理过程而非减少停顿时间，在多核处理下，这种方式确实能够提高FULL GC速度，从而提高吞吐量。 CMS收集器CMS是一款老年代收集器，CMS第一次几乎真正实现了与用户并发运行，但是那个时候还没有解决如何实现真正意义上的并发标记整理法，因此CMS采用的是标记清除法，这意味着即使CMS能够降低停顿时间，但依然会带来许多外部碎片。CMS的关注点就是低停顿，CMS期望能让用户线程尽可能的不停顿而完成GC。 CMS运作分为4个步骤： 初始标记(CMS-initial-mark)。初始标记生成GC ROOTS对象，并标记GC ROOTS能直接关联到的对象，正如我们前面说的，枚举GC ROOTS对象是需要暂停的，但鉴于已有技术优化，暂停时间会很短暂。 并发标记(CMS-concurrent-mark)。这一部分与我们在并发的可达性分析中一样，CMS采取的是增量更新的办法以消除并发问题。 重新标记(CMS-remark)。与我们在并发的可达性分析中一样，这一阶段CMS进行增量更新，重新遍历之前保存的引用以增量更新，这里需要“STW”。 并发清除(CMS-concurrent-sweep)。并发清除并没有什么问题，前提是我们已经正确的进行了标记。 在并发收集时，CMS必须要划分一些空间供正在运行的用户程序分配，CMS默认将这些空间标记为存活状态，这意味着这部分的空间产生的垃圾必须要等到下一次收集，这就是所谓的“浮动垃圾”，当这一部分预留空间被挤满时，CMS会停下所有工作，启动 Serial&#x2F;Serial Old 收集器发起 FULL GC。当程序核心不够时，CMS就会运行缓慢，很可能会导致预留空间不够的情况，最后反而还是要调用串行收集器，弄巧成拙，CMS只推荐处理器核心 &gt;&#x3D; 4时使用。 G1(Garbage First)收集器G1(Garbage First)垃圾收集器是当今垃圾回收技术最前沿的成果之一。早在JDK7就已加入JVM的收集器大家庭中，成为HotSpot重点发展的垃圾回收技术。同优秀的CMS垃圾回收器一样，G1也是关注最小时延的垃圾回收器，也同样适合大尺寸堆内存的垃圾收集，官方也推荐使用G1来代替选择CMS。G1最大的特点是引入分区的思路，弱化了分代的概念，合理利用垃圾收集各个周期的资源，解决了其他收集器甚至CMS的众多缺陷。 G1垃圾收集器的设计原则是“首先收集尽可能多的垃圾(Garbage First)”，目标是为了尽量缩短处理超大堆（超过4GB）产生的停顿。 因此，G1并不会等内存耗尽（比如Serial 串行收集器、Parallel并行收集器 ）或者快耗尽的时候才开始垃圾回收，而是在内部采用了启发式算法，在堆中找出具有高收集收益的分区（Region）进行收集。 G1淡化了分代的思想，它将整个堆分成相同大小的区，但G1没有放弃分代的思想，对于每个区，G1依然标记其年代，并基于不同年代采取不同的算法，值得注意的是，G1将大对象单独分区，即H区(Humongous区)，以避免对大对象标记整理的缓慢处理(直接GG)。这种分区不必在物理空间上连续，只需逻辑连续即可，这意味着G1可以动态的调整大小，当新生代空间不够时，G1会分配空闲的区，将他们组织成逻辑上的连续块，这使得G1的内存分配速率较高，并且这种做法消除了外部碎片，仅可能存在些许内部碎片。 G1期望能够“建立可预测的停顿时间模型”，这意味着G1能够支持回收时间不超过N毫秒的决策，这与Parallel Scavenge收集器是不同的，Parallel Scavenge收集器只是去尝试，但G1期望能够尽力确保实现。 G1的收集是基于区的回收，G1可以额外关注每个区的状态，G1跟踪各个区垃圾堆积的价值大小，得出预测回收空间大小与回收所须时间的比例，在满足用户指定的停顿时间下，G1会优先回收能够回收最大空间的区，在之前，停顿时间长主要是因为当老年代已经被占满了才会发起GC，而G1完全取消了这种模型，G1选择回收时不再是一味优先选择新生代了(但堆空间较大时仍然优先新生代)，而是根据预测的模型选择分区回收，这就使得几乎不会出现长时间的“STW”了。 如何确定区中可回收垃圾的价值是设计G1的难点，G1统计所有可能的选项，例如上一次回收前的卡表的脏页数量、上一次回收前区的分代以及使用空间大小等，然后结合上一次回收所耗费时间以及回收空间建立起一种联系，然后根据下一次回收前统计的数据，预测下一次的期望回收的时间，这种算法比我们想象的要复杂的多。 G1的一个分区被分为卡表以及512字节的块，G1的卡表更加复杂，G1的卡表更像是一个Map，key是该区被指向的区域，而Value指出是谁指向了自己，例如下图中Map可能存放 key &#x3D; addr(Region 1) 和 对于Region1中的区域 指向 Region 2区域的索引号，即2。这种卡表占用更大的空间，但更详细的信息利于每个分区的并发收集。 G1的垃圾回收包括了以下几种回收机制： 年轻代收集。 由于标记复制法的高效性，年轻代的收集并不需要与用户并发，G1采用与ParNew收集器相似的算法收集，年轻代的收集需要暂停用户线程。要注意的是，G1会动态调整 Eden 与 Survivor 区的大小以保证满足用户期望的停顿时间。 老年代收集&#x2F;并发标记。 当堆空间达到一定阈值时（**默认45%**），便会周期性的触发并发标记。触发并发标记时会经历四个步骤： 初始标记。这一阶段扫描GC ROOTS能够关联的对象，同时设置一块空间，供并发时用户分配新对象，这一部分空间默认标记存活。初始标记需要暂停，但G1并不立即开始工作，而是等到下一次年轻代收集暂停时一起运行。 并发标记。这与我们之前讲过的可达性分析类似。 重新标记。G1采用效率更高的原始快照进行二次标记，这一阶段结束后G1已经可以统计到堆中垃圾的“价值”了。 筛选。根据统计的数据预测回收的时间，根据用户期望停顿时间排序指定价值最大的回收计划。当计划生成后，G1 并不立即回收，而是等到新生代暂停时间进行“混合收集”。 混合收集 并发周期结束后是混合垃圾回收周期，不仅进行年轻代垃圾收集，而且根据“计划”回收价值最大的老年代区。然后恢复到常规的年轻代垃圾收集，最终再次启动并发周期。 异常时回退为 Serial Old 发起 FULL GC。 同CMS一样。主要是清理过慢，导致用户无可用内存分配，此时会发起一次FULL GC。 G1几乎是一个“全能”的垃圾收集器，但G1非常依赖计算机资源，仅是每个分区保存的卡表就可能占用总内存的15%左右，通常，仅当内存 &gt;&#x3D; 16G时，内核数 &gt;&#x3D; 8时，使用G1才会有明显的效率提升。 对G1的了解主要来源于碎片化的信息统计，如有错误，望指出。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"MQ 知识点总结","slug":"MQ 知识点总结","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.980Z","comments":true,"path":"post/830e.html","link":"","permalink":"http://example.com/post/830e.html","excerpt":"","text":"AMQP 0.9.1 协议模型AMQP 协议是什么AMQP（高级消息队列协议）是一个网络协议。它支持符合要求的客户端应用（application）和消息中间件代理（messaging middleware broker）之间进行通信。 消息代理（message brokers）从发布者（publishers）亦称生产者（producers）那儿接收消息，并根据既定的路由规则把接收到的消息发送给处理消息的消费者（consumers）。 由于AMQP是一个网络协议，所以这个过程中的发布者，消费者，消息代理 可以存在于不同的设备上。 AMQP 0.9.1 的工作过程如下图：消息（message）被发布者（publisher）发送给交换机（exchange），交换机常常被比喻成邮局或者邮箱。然后交换机将收到的消息根据路由规则分发给绑定的队列（queue）。最后AMQP代理会将消息投递给订阅了此队列的消费者，或者消费者按照需求自行获取。 发布者（publisher）发布消息时可以给消息指定各种消息属性（message meta-data）。有些属性有可能会被消息代理（brokers）使用，然而其他的属性则是完全不透明的，例如消息数据，消息代理完全不关系消息数据是什么。 从安全角度考虑，网络是不可靠的，接收消息的应用也有可能在处理消息的时候失败。基于此原因，AMQP模块包含了一个消息确认（message acknowledgements）的概念：当一个消息从队列中投递给消费者后（consumer），消费者会通知一下消息代理（broker），这个可以是自动的也可以由处理消息的应用的开发者执行。当“消息确认”被启用的时候，消息代理不会完全将消息从队列中删除，直到它收到来自消费者的确认回执（acknowledgement）。 在某些情况下，例如当一个消息无法被成功路由时，消息或许会被返回给发布者并被丢弃。或者，如果消息代理执行了延期操作，消息会被放入一个所谓的死信队列中。此时，消息发布者可以选择某些参数来处理这些特殊情况。 队列，交换机和绑定统称为AMQP实体（AMQP entities）。 交换机和交换机类型交换机是用来发送消息的AMQP实体。交换机拿到一个消息之后将它路由给一个或零个队列。它使用哪种路由算法是由交换机类型和被称作绑定（bindings）的规则所决定的。AMQP 0.9.1 的代理提供了四种交换机 Name（交换机类型） Default pre-declared names（预声明的默认名称） Direct exchange（直连交换机） (Empty string) and amq.direct Fanout exchange（扇型交换机） amq.fanout Topic exchange（主题交换机） amq.topic Headers exchange（头交换机） amq.match (and amq.headers in RabbitMQ) 交换机可以有两个状态：持久（durable）、暂存（transient）。持久化的交换机会在消息代理（broker）重启后依旧存在，而暂存的交换机则不会（它们需要在代理再次上线后重新被声明）。 默认交换机默认交换机（default exchange）实际上是一个由消息代理预先声明好的没有名字（名字为空字符串）的直连交换机（direct exchange）。它有一个特殊的属性使得它对于简单应用特别有用处：那就是每个新建队列（queue）如果没有指定交换机，将会自动绑定到默认交换机上，绑定的路由键（routing key）名称与队列名称相同。 举个栗子：当你声明了一个名为”search-indexing-online”的队列，AMQP代理会自动将其绑定到默认交换机上，绑定（binding）的路由键名称也是为”search-indexing-online”。因此，当携带着名为”search-indexing-online”的路由键的消息被发送到默认交换机的时候，此消息会被默认交换机路由至名为”search-indexing-online”的队列中。 直连交换机直连型交换机（direct exchange）是根据消息携带的路由键（routing key）将消息投递给对应队列的。直连交换机用来处理消息的单播路由（unicast routing）（尽管它也可以处理多播路由）。下边介绍它是如何工作的： 将一个队列绑定到某个交换机上，同时赋予该绑定一个路由键（routing key） 当一个携带着路由键为R的消息被发送给直连交换机时，交换机会把它路由给绑定值同样为R的队列。 直连交换机经常用来循环分发任务给多个工作者（workers）。当这样做的时候，我们需要明白一点，在AMQP 0.9.1中，如果有多个消费者绑定在某个路由键上，消息代理将在多个消费者之间选择一个投递。 直连型交换机图例： 扇型交换机扇型交换机（funout exchange）将消息路由给绑定到它身上的所有队列，而不理会绑定的路由键。如果N个队列绑定到某个扇型交换机上，当有消息发送给此扇型交换机时，交换机会将消息的拷贝分别发送给这所有的N个队列。扇型用来交换机处理消息的广播路由（broadcast routing）。 因为扇型交换机投递消息的拷贝到所有绑定到它的队列，所以他的应用案例都极其相似： 大规模多用户在线（MMO）游戏可以使用它来处理排行榜更新等全局事件 体育新闻网站可以用它来近乎实时地将比分更新分发给移动客户端 分发系统使用它来广播各种状态和配置更新 在群聊的时候，它被用来分发消息给参与群聊的用户。（AMQP没有内置presence的概念，因此XMPP可能会是个更好的选择） 扇型交换机图例： 主题交换机主题交换机（topic exchanges）通过对消息的路由键和队列到交换机的绑定模式之间的匹配，将消息路由给一个或多个队列。这很像直连交换机，唯一的区别是主题交换机的路由键是个模式匹配字符串，可以匹配多个队列。 主题交换机经常用来实现各种分发&#x2F;订阅模式及其变种。主题交换机通常用来实现消息的多播路由（multicast routing）。 主题交换机拥有非常广泛的用户案例。无论何时，当一个问题涉及到那些想要有针对性的选择需要接收消息的 多消费者&#x2F;多应用（multiple consumers&#x2F;applications） 的时候，主题交换机都可以被列入考虑范围。 头交换机有时消息的路由操作会涉及到多个属性，此时使用消息头就比用路由键更容易表达，头交换机（headers exchange）就是为此而生的。头交换机使用多个消息属性来代替路由键建立路由规则。通过判断消息头的值能否与指定的绑定相匹配来确立路由规则。 我们可以绑定一个队列到头交换机上，并给他们之间的绑定使用多个用于匹配的头（header）。这个案例中，消息代理得从应用开发者那儿取到更多一段信息，换句话说，它需要考虑某条消息（message）是需要部分匹配还是全部匹配。上边说的“更多一段消息”就是”x-match”参数。当”x-match”设置为“any”时，消息头的任意一个值被匹配就可以满足条件，而当”x-match”设置为“all”的时候，就需要消息头的所有值都匹配成功。 头交换机可以视为直连交换机的另一种表现形式。头交换机能够像直连交换机一样工作，不同之处在于头交换机的路由规则是建立在头属性值之上，而不是路由键。路由键必须是一个字符串，而头属性值则没有这个约束，它们甚至可以是整数或者哈希值（字典）等。 队列队列属性AMQP中的队列（queue）跟其他消息队列或任务队列中的队列是很相似的：它们存储着即将被应用消费掉的消息。队列跟交换机共享某些属性，但是队列也有一些另外的属性。 Name Durable（消息代理重启后，队列依旧存在） Exclusive（只被一个连接（connection）使用，而且当连接关闭后队列即被删除） Auto-delete（当最后一个消费者退订后即被删除） Arguments（一些消息代理用他来完成类似与TTL的某些额外功能） 队列在声明（declare）后才能被使用。如果一个队列尚不存在，声明一个队列会创建它。如果声明的队列已经存在，并且属性完全相同，那么此次声明不会对原有队列产生任何影响。如果声明中的属性与已存在队列的属性有差异，那么一个错误代码为406的通道级异常就会被抛出。 持久化队列（Durable queues）会被存储在磁盘上，当消息代理（broker）重启的时候，它依旧存在。没有被持久化的队列称作暂存队列（Transient queues）。 持久化的队列并不会使得路由到它的消息也具有持久性。倘若消息代理挂掉了，重新启动，那么在重启的过程中持久化队列会被重新声明。 无论怎样，如果要保证未被消费的消息持久化，必须进行单独设置，只有经过持久化的消息才能被重新恢复。 Rabbit Mq 中需要在发送消息时，设置消息的属性以开启消息持久化。 channel.basicPublish(EXCHANGE_NAME, ROUTING_KEY, MessageProperties.PERSISTENT_TEXT_PLAIN, message.getBytes()); 绑定交换机绑定（Binding）是交换机（exchange）将消息（message）路由给队列（queue）所需遵循的规则。如果要指示交换机“E”将消息路由给队列“Q”，那么“Q”就需要与“E”进行绑定。绑定操作需要定义一个可选的路由键（routing key）属性给某些类型的交换机。路由键的意义在于从发送给交换机的众多消息中选择出某些消息，将其路由给绑定的队列。 拥有了交换机这个中间层，很多由发布者直接到队列难以实现的路由方案能够得以实现，并且避免了应用开发者的许多重复劳动，达到了解耦的效果。 如果AMQP的消息无法路由到队列（例如，发送到的交换机没有绑定队列），消息会被就地销毁或者返还给发布者，如果应用没能编写处理程序接受退还消息，那么消息将被无情的抛弃。 死信队列死信队列也是一个普通的队列，也需要绑定在交换机中。 对于一个队列而言，每个队列可以设置一些限制，例如 消息最多重投次数、队列最大长度、消息对大存活时间 等，当消息达到限制时，消息代理可以简单的丢弃他们，或者将他们投递到预先设置的死信队列中。 在 Java 中，可以这样配置队列，并声明一些限制条件以及死信队列： @Bean(name = \"queue\") public Queue getOrderAddQueue() &amp;#123; Map&lt;String, Object> args = new HashMap&lt;>(5); // 绑定死信交换机和路由 args.put(\"x-dead-letter-exchange\",DEAD_EXCHANGE); args.put(\"x-dead-letter-routing-key\",ODEAD_ROUTEING_KEY); //队列的长度为 100 args.put(\"x-max-length\",100); //队列中的消息超过 3s 后过期 args.put(\"x-message-ttl\", 3000L); return new Queue(ORDER_ADD_QUEUE, true, false, false, args); &amp;#125; 死信队列通常用于实现一些兜底方案，如系统负载过高，队列已满，通知客户未能完成某项工作等；也可用于定时事件，例如订单超时未支付则自动取消，消费者可以根据订单是否以支付来决定是否要拒绝或确认消息（或者干脆不设置消费者），当消息在队列中超时时，他被投递至死信队列中处理。 消费者消息如果只是存储在队列里是没有任何用处的。被应用消费掉，消息的价值才能够体现。在AMQP 0-9-1 模型中，有两种途径可以达到此目的： 将消息投递给应用 (“push API”) 应用根据需要主动获取消息 (“pull API”) 使用 push API，应用（application）需要明确表示出它在某个特定队列里所感兴趣的，想要消费的消息。即消费者要指定一个队列的名字，表示订阅了这个队列。 随后，消息代理会与消费者打开一条 TCP 长连接，用以推送消息，消息代理会不断对消费者探活以确保消费者存活。大多数 AMQP 的实现都是采用 push 模型，但同时消息代理保留了 pull api 供外部调用。 每个消费者（订阅者）都有一个叫做消费者标签的标识符。它可以被用来退订消息。消费者标签实际上是一个字符串。 消息确认消费者应用（Consumer applications） - 用来接受和处理消息的应用 - 在处理消息的时候偶尔会失败或者有时会直接崩溃掉。而且网络原因也有可能引起各种问题。这就给我们出了个难题，AMQP代理在什么时候删除消息才是正确的？AMQP 0.9.1 规范给我们两种建议： 当消息代理（broker）将消息发送给应用后立即删除。（使用AMQP方法：basic.deliver或basic.get-ok） 待应用（application）发送一个确认回执（acknowledgement）后再删除消息。（使用AMQP方法：basic.ack） 前者被称作自动确认模式（automatic acknowledgement model），后者被称作显式确认模式（explicit acknowledgement model）。 在显式模式下，由消费者应用来选择什么时候发送确认回执（acknowledgement）。在此期间，消息代理不会重复投递消息，但是如果消息代理检测到与消费者的连接断开，那么消息代理会将消息重新投递给另一个消费者。 拒绝消息当一个消费者接收到某条消息后，处理过程有可能成功，有可能失败。应用可以向消息代理表明，本条消息由于“拒绝消息（Rejecting Messages）”的原因处理失败了。 当拒绝某条消息时，应用可以通过拒绝参数告诉消息代理如何处理这条消息——销毁它或者重新放入队列。当此队列只有一个消费者时，如果处理不当，可能会出现无限次投递、确认、重新投递的死循环。 在AMQP中，basic.reject 方法用来执行拒绝消息的操作。 但 basic.reject 有个限制：一次只能拒绝一个消息，无法做到批量拒绝，在 RabbitMq 中，一条消息可能会因为网络问题被多次投递到同一个消费者中，可以使用 basic.nack 方式来批量拒绝。 预取消息在多个消费者共享一个队列的案例中，明确指定在收到下一个确认回执前每个消费者一次可以接受多少条消息是非常有用的。这可以在试图批量发布消息的时候起到简单的负载均衡和提高消息吞吐量的作用。 注意，RabbitMQ只支持通道级的预取计数，而不是连接级的或者基于大小的预取。 通过 basic.qos 告知消息代理自己可以接受多少条消息。 消息属性和有效载荷（消息主体）AMQP模型中的消息（Message）对象是带有属性（Attributes）的。有些属性及其常见，以至于AMQP 0-9-1 明确的定义了它们，并且应用开发者们无需费心思思考这些属性名字所代表的具体含义。例如： Content type（内容类型） Content encoding（内容编码） Routing key（路由键） Delivery mode (persistent or not)投递模式（持久化 或 非持久化） Message priority（消息优先权） Message publishing timestamp（消息发布的时间戳） Expiration period（消息有效期） Publisher application id（发布应用的ID） 有些属性是被AMQP代理所使用的，但是大多数是开放给接收它们的应用解释器用的，有些属性是可选的也被称作消息头（headers），他们跟HTTP协议的X-Headers很相似，消息属性需要在消息被发布的时候定义。 AMQP的消息除属性外，也含有一个有效载荷 - Payload（消息实际携带的数据），它被AMQP代理当作不透明的字节数组来对待。 消息代理不会检查或者修改有效载荷，消息可以只包含属性而不携带有效载荷。 消息能够以持久化的方式发布，AMQP代理会将此消息存储在磁盘上，如果服务器重启，消息代理会保证收到的持久化消息不会丢失。 简单地将消息发送给一个持久化的交换机或者路由给一个持久化的队列，并不会使得此消息具有持久化性质：它完全取决与消息本身的持久模式（persistence mode）。将消息以持久化方式发布时，会对性能造成一定的影响（就像数据库操作一样，健壮性的存在必定造成一些性能牺牲）。 连接与通道有些应用需要与AMQP代理建立多个 TCP 连接，例如主机上存在多个消费者。无论怎样，同时开启多个TCP连接都是不合适的，因为这样做会消耗掉过多的系统资源并且使得防火墙的配置更加困难。 AMQP 0.9.1提供了通道（channels）来处理多连接，多个通道可以共享一个 TCP 连接，类似于 HTTP2.0 多路复用原理。 在 RabbitMq Java 客户端中，当收到消息代理的推送时，客户端会从线程池中获取一个线程，调用消费者逻辑，客户端会为每个线程分配不同的通道。 一个特定通道上的通讯与其他通道上的通讯是完全隔离的，因此每个 AMQP 方法都需要携带一个通道号，这样客户端就可以指定此方法是为哪个通道准备的。 在 RabbitMq 中，总是基于通道去进行操作。 同步发送AMQP 中并没有规定发送者如何同步发送，这在某些时候很有用处，例如对于一些事务而言，发送者必须要确认消息成功的被投递到消息代理中并被持久化。 Rabbit Mq 中支持两种同步发送模型。 Confirm 确认机制Confirm 确认机制是一种异步确认模型，一旦发送者将信道设置为 Confirm 模型，任何在此信道上发送的消息都会被指派一个唯一的 ID，一旦消息到达消息代理，如果消息属性包含了 Confirm ID，则消息代理会回送一个确认（包含消息 ID 和 Confirm ID）给发送者。 一旦发送者得到消息代理回送的结果，或是成功、或是失败、或是超时，Rabbitmq 客户端就会异步调用用户编写的 Confirm 处理程序。 @Component public class CustomConfirmAndReturnCallback implements RabbitTemplate.ConfirmCallback&amp;#123; @Override public void confirm(CorrelationData correlationData, boolean isSendSuccess, String error) &amp;#123; ......... &amp;#125; &amp;#125; 通常，如果消息未能发送成功，处理程序会将消息重复发送，以确保消息最终能够持久化。如果达到一定阈值后仍未发送成功，这应该要引起运维人员的注意（监控、告警）。 事务模式RabbitMq 提供了一种同步模型，被称为事务模式，在发送消息前，可以通过 select 方式在通道上开启事务，此时发送者会将 select 信息发送给消息代理告知此通道开启了事务模式，消息代理同意后方可继续事务。 当发送者提交时，消息代理检查消息是否到达或是否被持久化，如果一切正常，则同意提交，否则将会拒绝提交。 一旦任何异常发生，发送者可以调用回滚方法撤回消息，消息代理在提交前不会消费消息，而一旦消息代理收到回滚消息后，它会丢弃此条消息。 try &amp;#123; channel.txSelect(); channel.basicPublish(exchange, routingKey, MessageProperties.PERSISTENT_TEXT_PLAIN, msg.getBytes()); channel.txCommit(); &amp;#125; catch (Exception e) &amp;#123; e.printStackTrace(); channel.txRollback(); &amp;#125; 相较于 Confirm 而言，事务模式是完全同步的模型，txCommit() 方法会堵塞直至消息成功投递或发生异常，这能确保消息被成功投递了再去执行后面的逻辑；而 Confirm 模式则无法确保，因为其仍然是一种异步模型。但事务模型缺点是性能损失，通常而言，Confirm 模式是一种折衷的选择。 分布式事务MQ 可以用来处理一些分布式事务问题，核心思想是：开弓没有回头箭。 RocketMQ 实现了一些事务的功能，在 RocketMQ 中，存在两个概念： Half Message，半消息 暂时不能被 Consumer消费的消息。Producer已经把消息发送到 Broker端，但是此消息的状态被标记为不能投递，处于这种状态下的消息称为半消息。事实上，该状态下的消息会被放在一个叫做 RMQ_SYS_TRANS_HALF_TOPIC的主题下。 当 Producer端对它二次确认后，也就是 Commit之后，Consumer端才可以消费到；那么如果是Rollback，该消息则会被删除，永远不会被消费到。 事务状态回查 我们想，可能会因为网络原因、应用问题等，导致Producer端一直没有对这个半消息进行确认，那么这时候 Broker服务器会定时扫描这些半消息，主动找Producer端查询该消息的状态，这个也是半消息存在的意义。 例如如果上游服务提交了，但是未能来得及发送消息，就会存在不一致的问题。有了半消息之后，就相当于有了一个记录，当然通常上游服务自身也需要维护一个本地事务表，用以回答消息代理自身是否提交或未提交某个事务。 例如，一个经典的创建订单、增加积分分布式事务问题便可以通过消息队列实现，下图是整体的流程： 如果上游服务失败，则会发送回滚半消息到消息代理中，则消息代理会丢弃消息；如果上游服务成功，则发送提交消息，消息代理会投递事务消息到下游服务中；如果上游服务异常崩溃了，消息代理会回查事务状态；如果下游服务异常崩溃，消息队列能保证消息的持久化，并保证消息被消费者处理。 如果存在多个下游服务，则可以使用 topic 方式将事务消息投递到多个队列中，这可能需要消息队列本身的支持。 如果下游服务处理失败呢？例如扣减库存失败（库存为零），无论重试多少次都无法成功，在这个例子中可以让扣减库存成为上游服务，但在某些情况下，MQ 事务可能无能为力，毕竟：开弓没有回头🗡。 这种情况可能需要更强的 2PC 保证，在 2PC 事务中，事务协调器会发送 Prepare 消息给各个处理者，只有各个事务站点答复 OK 事务才能够被提交，例如如果库存为 0 了，这个事务处理者就会答复失败，从而导致整个事务回滚，如果事务站点答复 OK，则其可能需要锁或者预减库存来保证自己有能力扣减库存。 在 RabbitMQ 中没有对分布式事务的支持，但可以通过其本身提供的同步发送机制来保障事务消息发送到消息代理，对于发送者本地事务提交但未发送消息而崩溃的情况，仍然需要一个本地事务表来查询状态，但这可能需要由发送者自身主动检查（例如后台线程）。 分区日志使用日志进行消息存储在 AMQP 模型中，消息被赋予一个唯一的 ID，由消息代理投递并保障消息能正确消费，这会导致一些问题：重复消费、顺序消费、消息丢失……也许还有其他的方法！ 日志只是磁盘上简单的仅追加记录序列，在 Raft 算法中，我们研究过基于日志来实现主从复制、Leader 选举。 事实上，同样的结构可以⽤于实现消息代理：生产者通过将消息追加到日志末尾来发送消息，⽽消费者通过依次取日志来接收消息。如果消费者读到日志末尾，则会等待新消息追加的通知。 为了扩展到比单个磁盘所能提供的更⾼吞吐量，可以对日志进⾏分区。不同种类或是完全独立的日志可以分成不同的分区，不同的分区可以托管在不同的机器上。 在每个分区内，代理为每个消息分配⼀个单调递增的序列号或偏移量（offset）。这种序列号是有意义的，因为分区是仅追加写⼊的，所以分区内的消息是完全有序的，没有跨不同分区的顺序保证。 Kafak 便是使用了这种分区日志式的消息。为了实现负载均衡，可以将某个分区完全交由一组消费组节点处理，消费组节点内部使用负载均衡处理。 与 AMQP 模型的对比 AMQP 模型的中心在于消息代理；而分区日志的中心在于消费群组，分区日志模型总是主要是由消费组顺序的读取分区中的日志，如果读到末尾，则会等待新消息的追加通知，优点是吞吐量较高，但可能实时性较差。 AMQP 模型中，对于同一个队列中的消息，往往需要等待上一条消息确认后再次发送；对于分区日志而言，由于消息在分区内是顺序的，消费组可以一次性读取所有消息，并在本地顺序解析，对于海量数据场景下，吞吐量大幅度提升。 AMQP 模型中，需要跟踪每条消息的确认信息来判断消息是否被消费；对于分区日志而言，消息代理只需要得知消费组的读取偏移，那么这个偏移之前的日志肯定都被读取了，减少了额外的开销。 AMQP 模型中消息是否持久化取决于一系列配置，如果消息被消费了，那么消息就会被删除；而在分区日志而言，日志总是被持久化到磁盘，多个消费组可以重复读取，天然支持消息扇出、消息回溯，但缺点是会占用较大的磁盘空间。 AMQP 模型中，可以开启自动确认来实现完全异步的消息投递；而在分区日志中，消息总是要被顺序处理的。 AMQP 模型中可以支持一些事务机制来保障消息被顺利投递；而在分区日志中，并没有这种保障，消息代理不会去确认消息是否被投递，给用户的保障往往是一个很弱的 最终一致性。 AMQP 常见问题总结消息队列优点 解耦。发送者与消费者解耦，升级方便，伸缩性、扩展性都比较强。 可靠性保证。消息代理能够保证消息的持久化。 异步处理。可以立即返回，提高响应速度。 削峰。利用最大队列长度结合死信队列削峰，避免流量过多。 定时调度。利用私信队列结合消息存活时间，实现一个不太精确的定时调度，例如超时订单自动取消。 如何保障顺序消费如果有三种消息 A、B、C，他们之间需要保障顺序消费，如果将他们绑定在不同的队列上，由于队列分发消息速率、网络延时、消费者处理速率等情况，将无法保证顺序消费。 最好的办法是将三种消息绑定在一个队列中，并开启手动确认，消费者根据消息类型进行处理，在同一个队列中，只有当上一条消息被确认后，下一条消息才能够发送。但这缺点是耦合度变高了，可能会使系统吞吐量下降。 如何解决重复消费问题重复消费产生原因有两点： 消费者多次投递。例如因为网络超时，在 Confirm 回调中重复投递。 消息代理多次投递。例如如果开启了手动确认，并且消费者与消息代理的连接断开，则消息代理则会将消息投递到其他消费者。 消费者拒绝处理时选择重新入队。这是人为问题，不在我们的考虑之中。 MQ 本身并未提供一种解决办法，通常的解决办法是利用 Redis 中心化存储，在消费前，可以原子地的将消息 ID 存储起来，例如可以通过位图等方式。由于 Redis 是单线程处理的，如果消息存储失败或已存在消息（putIfAbsent），则可以响应 ack 告知消息代理不要再继续投递了。 分布式事务参考上述分布式事务即可。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"Mybatis 原理","slug":"Mybatis 原理","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.980Z","comments":true,"path":"post/fa86.html","link":"","permalink":"http://example.com/post/fa86.html","excerpt":"","text":"MyBatis 原理初始化阶段MyBatis 简单使用如下： public class Main &amp;#123; public static void main(String[] args) throws Exception &amp;#123; String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); try (SqlSession session = sqlSessionFactory.openSession()) &amp;#123; UserMapper mapper = session.getMapper(UserMapper.class); System.out.println(mapper.getUser(\"lsr\")); &amp;#125; &amp;#125; &amp;#125; 其启动时核心的逻辑在于 sqlSessionFactory.openSession() 这一行代码，SqlSessionFactory 是一个工厂，在 build 时创建了 XML 解析器，解析 XML 中的每一个属性，封装为 Configuration 类保存在 SqlSessionFactory 中。 public SqlSessionFactory build(InputStream inputStream, String environment, Properties properties) &amp;#123; SqlSessionFactory var5; try &amp;#123; XMLConfigBuilder parser = new XMLConfigBuilder(inputStream, environment, properties); var5 = this.build(parser.parse()); // xml 解析属性 &amp;#125; catch (Exception var14) &amp;#123; throw ExceptionFactory.wrapException(\"Error building SqlSession.\", var14); &amp;#125; return var5; &amp;#125; public Configuration parse() &amp;#123; if (this.parsed) &amp;#123; throw new BuilderException(\"Each XMLConfigBuilder can only be used once.\"); &amp;#125; else &amp;#123; this.parsed = true; this.parseConfiguration(this.parser.evalNode(\"/configuration\")); return this.configuration; &amp;#125; &amp;#125; 我们只需要知道这个 Configuration 包含了 XML 的全部属性即可，后面还会涉及到此类。 执行阶段创建会话首先来看 open 的逻辑： private SqlSession openSessionFromDataSource(ExecutorType execType, TransactionIsolationLevel level, boolean autoCommit) &amp;#123; Transaction tx = null; DefaultSqlSession var8; try &amp;#123; // 获取执行环境 Environment environment = this.configuration.getEnvironment(); // 创建事务信息 TransactionFactory transactionFactory = this.getTransactionFactoryFromEnvironment(environment); tx = transactionFactory.newTransaction(environment.getDataSource(), level, autoCommit); // 获取执行器 Executor executor = this.configuration.newExecutor(tx, execType); var8 = new DefaultSqlSession(this.configuration, executor, autoCommit); &amp;#125; catch (Exception var12) &amp;#123; this.closeTransaction(tx); throw ExceptionFactory.wrapException(\"Error opening session. Cause: \" + var12, var12); &amp;#125; return var8; &amp;#125; 这里的 Transaction 只是封装了数据源、隔离级别等事务信息，并没有真正开启连接。 执行器 Executor 是 Mybatis 中的一个重要的类： public Executor newExecutor(Transaction transaction, ExecutorType executorType) &amp;#123; Executor executor; if (ExecutorType.BATCH == executorType) &amp;#123; executor = new BatchExecutor(this, transaction); &amp;#125; else if (ExecutorType.REUSE == executorType) &amp;#123; executor = new ReuseExecutor(this, transaction); &amp;#125; else &amp;#123; executor = new SimpleExecutor(this, transaction); &amp;#125; if (cacheEnabled) &amp;#123; executor = new CachingExecutor(executor); &amp;#125; executor = (Executor) interceptorChain.pluginAll(executor); return executor; &amp;#125; 从代码中可以看出，执行器主要分为四大类，主要区别如下： BatchExecutor：缓存 SQL 并批量执行。 ReuseExecutor：复用 Statement，以 SQL 为 key，从缓存 Map&lt;String, Statement&gt; 中取 Statement 对象，使用完后放置缓存。 SimpleExecutor：每次使用时都会创建 Statement，每次执行一次 SQL。 CachingExecutor：组合上诉三种执行器，以 SQL 为 key，缓存结果。 JDBC 中的 Statement：一旦我们获得了数据库的连接，我们就可以和数据库进行交互，一个 Statement 就是一个连接，JDBC 的 Statement，CallableStatement 和 PreparedStatement 接口定义的方法和属性，可以让你发送 SQL 命令或 PL&#x2F;SQL 命令到数据库，并从你的数据库接收数据。 接口 推荐使用 Statement 可以正常访问数据库，适用于运行静态 SQL 语句。 Statement 接口不接受参数。 PreparedStatement 计划多次使用 SQL 语句， PreparedStatement 接口运行时接受输入的参数，可防止 SQL 注入。 CallableStatement 适用于当你要访问数据库存储过程的时候， CallableStatement 接口运行时也接受输入的参数。 上述还涉及到插件的加载，下文再讲。 动态代理此处我们的 UserMapper 仅仅只是个接口，为什么可以执行 SQL 呢？没错，就是动态代理技术！ 这个代理类为 class MapperProxy&lt;T&gt; implements InvocationHandler，透过 getMapper 这个方法，可以跟踪到源码： protected T newInstance(MapperProxy&lt;T> mapperProxy) &amp;#123; return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] &amp;#123; mapperInterface &amp;#125;, mapperProxy); &amp;#125; public T newInstance(SqlSession sqlSession) &amp;#123; final MapperProxy&lt;T> mapperProxy = new MapperProxy&lt;T>(sqlSession, mapperInterface, methodCache); return newInstance(mapperProxy); &amp;#125; 这其实就是 JDK 的动态代理，那么我们所执行的任何方法都是通过 MapperProxy.invoke 这个方法完成的。 核心逻辑进入到 MapperProxy.invoke 方法内，这个方法主要是调用了 MapperMethod.execute 方法： @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123; final MapperMethod mapperMethod = cachedMapperMethod(method); return mapperMethod.execute(sqlSession, args); &amp;#125; 并且会将 MapperMethod 实例缓存起来，避免频繁创建对象，MapperMethod 是 Mapper 类中的一个方法具体的执行逻辑，进入到他的执行方法： public Object execute(SqlSession sqlSession, Object[] args) &amp;#123; Object result; switch (command.getType()) &amp;#123; case INSERT: &amp;#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.insert(command.getName(), param)); break; &amp;#125; case UPDATE: &amp;#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.update(command.getName(), param)); break; &amp;#125; case DELETE: &amp;#123; Object param = method.convertArgsToSqlCommandParam(args); result = rowCountResult(sqlSession.delete(command.getName(), param)); break; &amp;#125; case SELECT: if (method.returnsMany()) &amp;#123; result = executeForMany(sqlSession, args); &amp;#125; else if (method.returnsMap()) &amp;#123; result = executeForMap(sqlSession, args); &amp;#125; else if (method.returnsCursor()) &amp;#123; result = executeForCursor(sqlSession, args); &amp;#125; else &amp;#123; Object param = method.convertArgsToSqlCommandParam(args); result = sqlSession.selectOne(command.getName(), param); &amp;#125; break; case FLUSH: result = sqlSession.flushStatements(); break; default: throw new BindingException(\"Unknown execution method for: \" + command.getName()); &amp;#125; return result; &amp;#125; 这个方法是一个中间方法，透过 SELECT 跟踪源码，最终会调用到 Executor#doQuery 方法， Executor 类型上面介绍过了，这里可能是三种 Executor 中的任意一种（Cache 依赖其他三种），这依赖与具体的环境与配置。 @Override public &lt;E> List&lt;E> doQuery(MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException &amp;#123; // 获取配置 Configuration configuration = ms.getConfiguration(); // 创建 StatementHandler StatementHandler handler = configuration.newStatementHandler(wrapper, ms, parameter, rowBounds, resultHandler, boundSql); // 参数准备，创建 JDBC 中的 Statement，这是与 jdk 交互的地方 Statement stmt = prepareStatement(handler, ms.getStatementLog()); // 使用 jdbc 执行方法与结果处理 return handler.&lt;E>query(stmt, resultHandler); &amp;#125; configuration.newStatementHandler 方法创建了 StatementHandler，负责与 jdk Statement 交互，在创建时，会向上调用 BaseStatementHandler 的无参构造器，这个构造器里会调用 Configuration 中的方法初始化 ParameterHandler、ResultSetHandler: public StatementHandler newStatementHandler(Executor executor, MappedStatement mappedStatement, Object parameterObject, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) &amp;#123; StatementHandler statementHandler = new RoutingStatementHandler(executor, mappedStatement, parameterObject, rowBounds, resultHandler, boundSql); statementHandler = (StatementHandler) interceptorChain.pluginAll(statementHandler); return statementHandler; &amp;#125; public ParameterHandler newParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql) &amp;#123; ParameterHandler parameterHandler = mappedStatement.getLang().createParameterHandler(mappedStatement, parameterObject, boundSql); parameterHandler = (ParameterHandler) interceptorChain.pluginAll(parameterHandler); return parameterHandler; &amp;#125; public ResultSetHandler newResultSetHandler(Executor executor, MappedStatement mappedStatement, RowBounds rowBounds, ParameterHandler parameterHandler, ResultHandler resultHandler, BoundSql boundSql) &amp;#123; ResultSetHandler resultSetHandler = new DefaultResultSetHandler(executor, mappedStatement, parameterHandler, resultHandler, boundSql, rowBounds); resultSetHandler = (ResultSetHandler) interceptorChain.pluginAll(resultSetHandler); return resultSetHandler; &amp;#125; 可以看到都使用了拦截器进行封装，下文会说到拦截器的工作原理。 doQuery 方法是一个模板方法，包含了 MyBatis 执行 SQL 的核心逻辑，这里总结一下： graph TD A(MapperProxy 动态代理) ==> B(Executor#query 模板方法) ==> C(StatementHandler#prepare 获取 Statement) ==> D(ParameterHandler#setParameters 设置参数) ==> E(StatementHandler#query 执行查询) ==> F(ResultSetHandler#handleCursorResultSets 处理结果) 拦截器拦截器是 Mybatis 里一个非常重要的知识点，拦截器可以在 Mybatis 特定流程处执行自己的逻辑，根据上诉可知，拦截器主要有四种，分别作用于 Executor、StatementHandler、ParameterHandler、ResultSetHandler 四个类上，并将原来的实例用拦截器替代。 public Object pluginAll(Object target) &amp;#123; for (Interceptor interceptor : interceptors) &amp;#123; target = interceptor.plugin(target); &amp;#125; return target; &amp;#125; 拦截器的接口为： public interface Interceptor &amp;#123; Object intercept(Invocation invocation) throws Throwable; Object plugin(Object target); void setProperties(Properties properties); &amp;#125; 来看一个简单的例子，这个拦截器拦截 ParameterHandler#setParameters 方法，并将参数强制改为 lsr 字符串： @Intercepts(&amp;#123; @Signature(type = ParameterHandler.class, method = \"setParameters\", args = PreparedStatement.class), &amp;#125;) public class ParameterInterceptor implements Interceptor &amp;#123; @Override public Object intercept(Invocation invocation) throws Throwable &amp;#123; if (invocation.getTarget() instanceof ParameterHandler ph) &amp;#123; Field parameter = ph.getClass().getDeclaredField(\"parameterObject\"); parameter.setAccessible(true); parameter.set(ph, \"lsr\"); &amp;#125; return invocation.proceed(); &amp;#125; @Override public Object plugin(Object o) &amp;#123; return Plugin.wrap(o, this); &amp;#125; @Override public void setProperties(Properties properties) &amp;#123; &amp;#125; &amp;#125; 这样即使我们传入的参数不是 “lsr”，查询时却会以 “lsr” 进行查询： 这个关键在于 @Intercepts 注解和 Plugin.wrap 方法，Plugin 方法本身就实现了 InvocationHandler 接口，可见这是一个代理类，拦截器的核心逻辑就在这个类中。 @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123; try &amp;#123; Set&lt;Method> methods = signatureMap.get(method.getDeclaringClass()); if (methods != null &amp;&amp; methods.contains(method)) &amp;#123; return interceptor.intercept(new Invocation(target, method, args)); &amp;#125; return method.invoke(target, args); &amp;#125; catch (Exception e) &amp;#123; throw ExceptionUtil.unwrapThrowable(e); &amp;#125; &amp;#125; 可以发现这个类的代理逻辑在于 if 语句，如果 methods 集合中包含这个方法，则会调用拦截器的方法。那么这个 methods 集合是怎么来的呢？ 其逻辑在 warp 方法内： public static Object wrap(Object target, Interceptor interceptor) &amp;#123; Map&lt;Class&lt;?>, Set&lt;Method>> signatureMap = getSignatureMap(interceptor); Class&lt;?> type = target.getClass(); Class&lt;?>[] interfaces = getAllInterfaces(type, signatureMap); if (interfaces.length > 0) &amp;#123; return Proxy.newProxyInstance( type.getClassLoader(), interfaces, new Plugin(target, interceptor, signatureMap)); &amp;#125; return target; &amp;#125; 注意 getSignatureMap 方法： private static Map&lt;Class&lt;?>, Set&lt;Method>> getSignatureMap(Interceptor interceptor) &amp;#123; // 获取注解 Intercepts interceptsAnnotation = interceptor.getClass().getAnnotation(Intercepts.class); Signature[] sigs = interceptsAnnotation.value(); Map&lt;Class&lt;?>, Set&lt;Method>> signatureMap = new HashMap&lt;Class&lt;?>, Set&lt;Method>>(); for (Signature sig : sigs) &amp;#123; Set&lt;Method> methods = signatureMap.get(sig.type()); if (methods == null) &amp;#123; methods = new HashSet&lt;Method>(); signatureMap.put(sig.type(), methods); &amp;#125; Method method = sig.type().getMethod(sig.method(), sig.args()); methods.add(method); &amp;#125; return signatureMap; &amp;#125; 这个方法获取了拦截器类上的注解，获取注解上的 @Signature，解析注解并封装至 SignatureMap 中。 这便是拦截器的工作原理，请别忘了将拦截器注册到拦截器链中。 目前比较常用的分页插件 PageHelper 就是使用了拦截器进行扩展： @Intercepts( &amp;#123; @Signature(type = Executor.class, method = \"query\", args = &amp;#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class&amp;#125;), @Signature(type = Executor.class, method = \"query\", args = &amp;#123;MappedStatement.class, Object.class, RowBounds.class, ResultHandler.class, CacheKey.class, BoundSql.class&amp;#125;), &amp;#125; ) 其拦截了 Executor#query 方法，运行时额外构造 LIMIT 字句到 SQL 中。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"NIO 与 epoll","slug":"NIO 与 epoll","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.980Z","comments":true,"path":"post/9442.html","link":"","permalink":"http://example.com/post/9442.html","excerpt":"","text":"epoll 与 select 本节出处：https://www.zhihu.com/question/20122137/answer/146866418，糅杂了一些个人思考 第一部分：select 和 epoll的任务 关键词：应用程序 文件句柄 用户态 内核态 监控者 要比较 epoll 相比较 select 高效在什么地方，就需要比较二者做相同事情的方法。 要完成对I&#x2F;O流的复用需要完成如下几个事情： 用户态怎么将文件句柄传递到内核态？ 内核态怎么判断I&#x2F;O流可读可写？ 内核怎么通知监控者有I&#x2F;O流可读可写？ 监控者如何找到可读可写的 I&#x2F;O 流并传递给用户态应用程序？ 继续循环时监控者怎样重复上述步骤？ 搞清楚上述的步骤也就能解开epoll高效的原因了。 select 的做法步骤1的解法：select 函数创建 3 个文件描述符集，并将这些文件描述符全部拷贝到内核中，32 位机器上限制了文件句柄的最大的数量为1024，在等待 IO 时，select 会在对应文件描述符条件上陷入休眠。 步骤2的解法：当 IO 事件到达主机时，触发IO中断，CPU 根据操作系统预设置的中断向量表调用相应处理程序，例如陷入 TCP&#x2F;IP 处理程序，随后内核针对读缓冲区和写缓冲区来判断是否可读可写，这个动作和 select 无关。 步骤3的解法：内核在检测到文件句柄可读&#x2F;可写时就设置相应条件（条件变量），唤醒正在等待该套接字的线程，这里是监控者 select，select 被内核触发之后，返回可读写的文件句柄的总数。 步骤4的解法：select 会将之前传递给内核的文件句柄再次从内核传到用户态（全部拷贝），select 返回给用户态的只是可读可写的文件句柄总数，再使用 FD_ISSET 宏函数来检测哪些文件I&#x2F;O可读可写，这是通过遍历解决的。 步骤5的解法：再次监控 IO 需要重复上述步骤，即重新将这些文件描述符全部拷贝到内核中。 epoll的做法步骤1的解法：首先执行 epoll_create 在内核专属于 epoll 的高速 cache 区，并在该缓冲区建立红黑树和就绪链表，用户态传入的文件句柄将被放到红黑树中。 步骤2的解法：这一步与上述相同。 步骤3的解法：epoll_ctl 执行 add 动作时除了将文件句柄放到红黑树上之外，还向内核注册了该文件句柄的回调函数，内核在检测到某句柄可读可写时则调用该回调函数，回调函数将文件句柄放到就绪链表，然后触发相应条件，唤醒等待队列中正在等待该条件的线程或进程，此处唤醒了 epoll。 步骤4的解法：epoll_wait 只监控就绪链表就可以，如果就绪链表有文件句柄，则表示该文件句柄可读可写，并返回到用户态（少量的拷贝），注意这里仅仅返回了文件描述符，对应的文件数据（或IO数据）仍然在内核缓冲区中或文件中，采用共享内存或 mmap 文件内存映射加速。 步骤5的解法：由于原先的文件句柄没有被修改或者移动，因此无须重复步骤一，内核可以继续监控这些文件句柄，直到使用epoll_ctl删除文件句柄，否则不需要重新传入，无须多次拷贝。 简单说：epoll 是继承了select&#x2F;poll 的I&#x2F;O复用的思想，并在二者的基础上从监控IO流、查找I&#x2F;O事件等角度来提高效率，具体地说就是内核句柄列表、红黑树、就绪链表来实现的。 文件句柄就是文件描述符。 第二部分：epoll详解epoll 系统调用先简单回顾下如何使用C库封装的3个epoll系统调用吧。 int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 使用起来很清晰： epoll_create 建立一个epoll对象，初始时红黑树和就绪链表都是空的。参数size是内核保证能够正确处理的最大句柄数，多于这个最大数时内核不保证效果。 epoll_ctl 可以操作上面建立的epoll，例如，将刚建立的 socket 加入到 epoll 中让其监控，或者把 epoll 正在监控的某个 socket 句柄移出 epoll，不再监控它等等(也就是将I&#x2F;O流放到内核)。 epoll_wait在调用时，在给定的timeout时间内，当在监控的所有句柄中有事件发生时，就返回文件可读写的的总数给进程，同时设置这些事件到参数 events 中，不需要用户去遍历查询（也就是在内核层面捕获可读写的I&#x2F;O事件）。 从上面的调用方式就可以看到 epoll 比 select&#x2F;poll 的优越之处： 因为 select&#x2F;poll 每次调用时都要传递你所要监控的所有 socket 给 select&#x2F;poll 系统调用，这意味着需要将用户态的 socket 列表 copy 到内核态，如果以万计的句柄会导致每次都要 copy 几十几百KB的内存到内核态，非常低效。而我们调用 epoll_wait 时就相当于以往调用 select&#x2F;poll，但是这时却不用传递socket句柄给内核，因为内核已经在epoll_ctl中拿到了要监控的句柄列表。 select监控的句柄列表在用户态，每次调用都需要从用户态将句柄列表拷贝到内核态，但是epoll中句柄就是建立在内核中的，这样就减少了内核和用户态的拷贝，高效的原因之一。 所以，实际上在你调用epoll_create后，内核就已经在内核态开始准备帮你存储要监控的句柄了，每次调用epoll_ctl只是在往内核的**数据结构**里塞入新的socket句柄。 在内核里，一切皆文件。所以，epoll向内核注册了一个文件系统，用于存储上述的被监控socket。当你调用epoll_create时，就会在这个虚拟的epoll文件系统里创建一个file结点。当然这个file不是普通文件，它只服务于epoll。 epoll在被内核初始化时（**操作系统启动），同时会开辟出epoll自己的内核高速cache区，用于安置每一个我们想监控的socket，这些socket会以红黑树的形式保存在内核cache里，以支持快速的查找、插入、删除。这个内核高速cache区，就是建立连续的物理内存页，然后在之上建立slab层，简单的说，就是物理上提前分配好你想要的size的内存对象，每次使用时都是使用空闲的已分配好的对象。** lab是Linux操作系统的一种内存分配机制。其工作是针对一些经常分配并释放的对象，如进程描述符等，这些对象的大小一般比较小，如果直接采用伙伴系统来进行分配和释放，不仅会造成大量的内存碎片，而且处理速度也太慢。而slab分配器是基于对象进行管理的，相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内碎片。slab分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。 epoll高效的原因这是由于我们在调用epoll_create时，内核除了帮我们在epoll文件系统里建了个file结点，在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket外，还会再建立一个list链表，用于存储准备就绪的事件. 当epoll_wait调用时，仅仅观察这个list链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait 非常高效。而且，通常情况下即使我们要监控百万计的句柄，大多一次也只返回很少量的准备就绪句柄而已，所以，epoll_wait 仅需要从内核态copy少量的句柄到用户态而已。 那么，这个准备就绪list链表是怎么维护的呢？ 当我们执行epoll_ctl时，除了把socket放到epoll文件系统里file对象对应的红黑树上之外，还会给内核中断处理程序注册一个回调函数，告诉内核，如果这个句柄的中断到了，就把它放到准备就绪list链表里。所以，当一个socket上有数据到了，内核在把网卡上的数据copy到内核中后就来把socket插入到准备就绪链表里了，然后 epoll 被唤醒，返回一个可读写的文件总数。 epoll综合的执行过程如此，一棵红黑树，一张准备就绪句柄链表，少量的内核cache，就帮我们解决了大并发下的socket处理问题。执行epoll_create时，创建了红黑树和就绪链表，执行epoll_ctl时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据。执行epoll_wait时立刻返回准备就绪链表里的数据即可。 epoll 水平触发（LT）和边缘触发（ET）的实现当一个socket句柄上有事件时，内核会把该句柄插入上面所说的准备就绪list链表，这时我们调用epoll_wait，会把准备就绪的socket拷贝到用户态内存，然后清空准备就绪list链表， 最后，epoll_wait干了件事，就是检查这些socket，如果不是ET模式（就是LT模式的句柄了），并且这些socket上确实有未处理的事件时，又把该句柄放回到刚刚清空的准备就绪链表了，所以，非ET的句柄，只要它上面还有事件，epoll_wait每次都会返回。而ET模式的句柄，除非有新中断到，即使socket上的事件没有处理完，也是不会次次从epoll_wait返回的。 LT 就是只要文件描述符关联的读内核缓冲区非空，有数据可以读取，就一直发出可读信号进行通知，当文件描述符关联的内核写缓冲区不满，有空间可以写入，就一直发出可写信号进行通知。LT模式支持阻塞和非阻塞两种方式。epoll默认的模式是LT。 ET 就是当文件描述符关联的读内核缓冲区由空转化为非空的时候，则发出可读信号进行通知；当文件描述符关联的内核写缓冲区由满转化为不满的时候，则发出可写信号进行通知。 两者的区别在哪里呢？水平触发是只要读缓冲区有数据，就会一直触发可读信号，而边缘触发仅仅在空变为非空的时候通知一次， LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select&#x2F;poll都是这种模型的代表。 当你必须要处理某个 IO 事件时，使用 LT 更加安全，但相对而言更耗资源。 当你会主动去查缓冲区是否有数据时，换句话说，当你收到一次通知后，你自己就会变得主动起来，而无需内核次次通知。 举个生活中的例子，如果你有 2000 元想去买东西，例如你想买 10 个价值 200 元的礼物，而你父母就是监控你的人： LT 的做法是：每买一次东西就向你父母汇报，一共汇报十次。 ET 的做法是：第一次买的时候汇报一下，剩余 9 次就不再通知你父母了，当你第一次汇报时，你的父母就应该要知道你可能会接着买东西。什么时候再次向你父母汇报呢？直到钱花光了，再次向你父母要钱，重新开始买东西，此时又会向你父母汇报一次。 第三部分：epoll高效的本质1. 通过红黑树维护各个文件句柄，维护句柄十分高效。 2. 通过双向链表维护就绪文件句柄。 3. 事件发生，不用采用轮询机制依次查询，直接采用回调机制。 4. 每次事件完成，用户不需要再次把文件句柄拷贝到内核。epoll只需第一次拷贝。后面就不需要了。每次新加入的文件句柄都会通过红黑树插入进去。 5. 当要检测的文件句柄数量很大的时候。轮询机制耗时太严重，而epoll就高效的回调效率就体现出来了 NIONIO（Non-blocking I&#x2F;O，在Java领域，也称为New I&#x2F;O），是一种同步非阻塞的I&#x2F;O模型，也是I&#x2F;O多路复用的基础，已经被越来越多地应用到大型应用服务器，成为解决高并发与大量连接、I&#x2F;O处理问题的有效方式。 那么NIO的本质是什么样的呢？它是怎样与事件模型结合来解放线程、提高系统吞吐的呢？ 本文会从传统的阻塞I&#x2F;O和线程池模型面临的问题讲起，然后对比几种常见I&#x2F;O模型，一步步分析NIO怎么利用事件模型处理I&#x2F;O，解决线程池瓶颈处理海量连接，包括利用面向事件的方式编写服务端&#x2F;客户端程序。最后延展到一些高级主题，如Reactor与Proactor模型的对比、Selector的唤醒、Buffer的选择等。 注：本文的代码都是伪代码，主要是为了示意，不可用于生产环境。 传统BIO模型分析 本节出处Java NIO浅析 - 知乎 (zhihu.com) 让我们先回忆一下传统的服务器端同步阻塞I&#x2F;O处理（也就是BIO，Blocking I&#x2F;O）的经典编程模型： &#123; ExecutorService executor = Excutors.newFixedThreadPollExecutor(100);//线程池 ServerSocket serverSocket = new ServerSocket(); serverSocket.bind(8088); while(!Thread.currentThread.isInturrupted())&#123;//主线程死循环等待新连接到来 Socket socket = serverSocket.accept(); executor.submit(new ConnectIOnHandler(socket));//为新的连接创建新的线程 &#125; class ConnectIOnHandler extends Thread&#123; private Socket socket; public ConnectIOnHandler(Socket socket)&#123; this.socket = socket; &#125; public void run()&#123; while(!Thread.currentThread.isInturrupted()&&!socket.isClosed())&#123;死循环处理读写事件 String someThing = socket.read()....//读取数据 if(someThing!=null)&#123; ......//处理数据 socket.write()....//写数据 &#125; &#125; &#125; &#125; 这是一个经典的每连接每线程的模型，之所以使用多线程，主要原因在于socket.accept()、socket.read()、socket.write()三个主要函数都是同步阻塞的，当一个连接在处理I&#x2F;O的时候，系统是阻塞的，如果是单线程的话必然就挂死在那里；但CPU是被释放出来的，开启多线程，就可以让CPU去处理更多的事情。其实这也是所有使用多线程的本质： 利用多核。 当I&#x2F;O阻塞系统，但CPU空闲的时候，可以利用多线程使用CPU资源。 现在的多线程一般都使用线程池，可以让线程的创建和回收成本相对较低。在活动连接数不是特别高（小于单机1000）的情况下，这种模型是比较不错的，可以让每一个连接专注于自己的I&#x2F;O并且编程模型简单，也不用过多考虑系统的过载、限流等问题。线程池本身就是一个天然的漏斗，可以缓冲一些系统处理不了的连接或请求。 不过，这个模型最本质的问题在于，严重依赖于线程。但线程是很”贵”的资源，主要表现在： 线程的创建和销毁成本很高，在Linux这样的操作系统中，线程本质上就是一个进程。创建和销毁都是重量级的系统函数。 线程本身占用较大内存，像Java的线程栈，一般至少分配512K～1M的空间，如果系统中的线程数过千，恐怕整个JVM的内存都会被吃掉一半。 线程的切换成本是很高的。操作系统发生线程切换的时候，需要保留线程的上下文，然后执行系统调用。如果线程数过高，可能执行线程切换的时间甚至会大于线程执行的时间，这时候带来的表现往往是系统load偏高、CPU sy使用率特别高（超过20%以上)，导致系统几乎陷入不可用的状态。 容易造成锯齿状的系统负载。因为系统负载是用活动线程数或CPU核心数，一旦线程数量高但外部网络环境不是很稳定，就很容易造成大量请求的结果同时返回，激活大量阻塞线程从而使系统负载压力过大。 所以，当面对十万甚至百万级连接的时候，传统的BIO模型是无能为力的。随着移动端应用的兴起和各种网络游戏的盛行，百万级长连接日趋普遍，此时，必然需要一种更高效的I&#x2F;O处理模型。 NIO是怎么工作的很多刚接触NIO的人，第一眼看到的就是Java相对晦涩的API，比如：Channel，Selector，Socket什么的；然后就是一坨上百行的代码来演示NIO的服务端Demo……瞬间头大有没有？ 我们不管这些，抛开现象看本质，先分析下NIO是怎么工作的。 常见I&#x2F;O模型对比所有的系统I&#x2F;O都分为两个阶段：等待就绪和操作。举例来说，读函数，分为等待系统可读和真正的读；同理，写函数分为等待网卡可以写和真正的写。 需要说明的是等待就绪的阻塞是不使用CPU的，是在“空等”；而真正的读写操作的阻塞是使用CPU的，真正在”干活”，而且这个过程非常快，属于memory copy，带宽通常在1GB&#x2F;s级别以上，可以理解为基本不耗时。 下图是几种常见I&#x2F;O模型的对比： 以socket.read()为例子： 传统的BIO里面socket.read()，如果TCP RecvBuffer里没有数据，函数会一直阻塞，直到收到数据，返回读到的数据。 对于NIO，如果TCP RecvBuffer有数据，就把数据从网卡读到内存，并且返回给用户；反之则直接返回0，永远不会阻塞。 最新的AIO(Async I&#x2F;O)里面会更进一步：不但等待就绪是非阻塞的，就连数据从网卡到内存的过程也是异步的。 换句话说，BIO里用户最关心“我要读”，NIO里用户最关心”我可以读了”，在AIO模型里用户更需要关注的是“读完了”。 NIO一个重要的特点是：socket主要的读、写、注册和接收函数，在等待就绪阶段都是非阻塞的，真正的I&#x2F;O操作是同步阻塞的（消耗CPU但性能非常高）。 如何结合事件模型使用NIO同步非阻塞特性回忆BIO模型，之所以需要多线程，是因为在进行I&#x2F;O操作的时候，一是没有办法知道到底能不能写、能不能读，只能”傻等”，即使通过各种估算，算出来操作系统没有能力进行读写，也没法在socket.read()和socket.write()函数中返回，这两个函数无法进行有效的中断。所以除了多开线程另起炉灶，没有好的办法利用CPU。 NIO的读写函数可以立刻返回，这就给了我们不开线程利用CPU的最好机会：如果一个连接不能读写（socket.read() 返回0或者socket.write()返回0），我们可以把这件事记下来，记录的方式通常是在Selector上注册标记位，然后切换到其它就绪的连接（channel）继续进行读写。 下面具体看下如何利用事件模型单线程处理所有I&#x2F;O请求： NIO的主要事件有几个：读就绪、写就绪、有新连接到来。 我们首先需要注册当这几个事件到来的时候所对应的处理器。然后在合适的时机告诉事件选择器：我对这个事件感兴趣。对于写操作，就是写不出去的时候对写事件感兴趣；对于读操作，就是完成连接和系统没有办法承载新读入的数据的时；对于accept，一般是服务器刚启动的时候；而对于connect，一般是connect失败需要重连或者直接异步调用connect的时候。 其次，用一个死循环选择就绪的事件，会执行系统调用（Linux 2.6之前是select、poll，2.6之后是epoll，Windows是IOCP），还会阻塞的等待新事件的到来。新事件到来的时候，会在selector上注册标记位，标示可读、可写或者有连接到来。 注意，select是阻塞的，无论是通过操作系统的通知（epoll）还是不停的轮询(select，poll)，这个函数是阻塞的。所以你可以放心大胆地在一个while(true)里面调用这个函数而不用担心CPU空转。 所以我们的程序大概的模样是： interface ChannelHandler&#123; void channelReadable(Channel channel); void channelWritable(Channel channel); &#125; class Channel&#123; Socket socket; Event event;//读，写或者连接 &#125; //IO线程主循环: class IoThread extends Thread&#123; public void run()&#123; Channel channel; while(channel=Selector.select())&#123;//选择就绪的事件和对应的连接 if(channel.event==accept)&#123; registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器 &#125; if(channel.event==write)&#123; getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件 &#125; if(channel.event==read)&#123; getChannelHandler(channel).channelReadable(channel);//如果可以读，则执行读事件 &#125; &#125; &#125; Map handlerMap;//所有channel的对应事件处理器 &#125; 这个程序很简短，也是最简单的 Reactor 模式：注册所有感兴趣的事件处理器，单线程轮询选择就绪事件，执行事件处理器。 优化线程模型由上面的示例我们大概可以总结出NIO是怎么解决掉线程的瓶颈并处理海量连接的： NIO由原来的阻塞读写（占用线程）变成了单线程轮询事件，找到可以进行读写的网络描述符进行读写。除了事件的轮询是阻塞的（没有可干的事情必须要阻塞），剩余的I&#x2F;O操作都是纯CPU操作，没有必要开启多线程。 并且由于线程的节约，连接数大的时候因为线程切换带来的问题也随之解决，进而为处理海量连接提供了可能。 单线程处理I&#x2F;O的效率确实非常高，没有线程切换，只是拼命的读、写、选择事件。但现在的服务器，一般都是多核处理器，如果能够利用多核心进行I&#x2F;O，无疑对效率会有更大的提高。 仔细分析一下我们需要的线程，其实主要包括以下几种： 事件分发器，单线程选择就绪的事件。 I&#x2F;O处理器，包括connect、read、write等，这种纯CPU操作，一般开启CPU核心个线程就可以。 业务线程，在处理完I&#x2F;O后，业务一般还会有自己的业务逻辑，有的还会有其他的阻塞I&#x2F;O，如DB操作，RPC等。只要有阻塞，就需要单独的线程。 Java的Selector对于Linux系统来说，有一个致命限制：同一个channel的select不能被并发的调用。因此，如果有多个I&#x2F;O线程，必须保证：一个socket只能属于一个IoThread，而一个IoThread可以管理多个socket。 另外连接的处理和读写的处理通常可以选择分开，这样对于海量连接的注册和读写就可以分发。虽然read()和write()是比较高效无阻塞的函数，但毕竟会占用CPU，如果面对更高的并发则无能为力。 NIO在客户端的魔力通过上面的分析，可以看出NIO在服务端对于解放线程，优化I&#x2F;O和处理海量连接方面，确实有自己的用武之地。那么在客户端上，NIO又有什么使用场景呢? 常见的客户端BIO+连接池模型，可以建立n个连接，然后当某一个连接被I&#x2F;O占用的时候，可以使用其他连接来提高性能。 但多线程的模型面临和服务端相同的问题：如果指望增加连接数来提高性能，则连接数又受制于线程数、线程很贵、无法建立很多线程，则性能遇到瓶颈。 每连接顺序请求的Redis对于Redis来说，由于服务端是全局串行的，能够保证同一连接的所有请求与返回顺序一致。这样可以使用单线程＋队列，把请求数据缓冲。然后pipeline发送，返回future，然后channel可读时，直接在队列中把future取回来，done()就可以了。 伪代码如下： class RedisClient Implements ChannelHandler&#123; private BlockingQueue CmdQueue; private EventLoop eventLoop; private Channel channel; class Cmd&#123; String cmd; Future result; &#125; public Future get(String key)&#123; Cmd cmd= new Cmd(key); queue.offer(cmd); eventLoop.submit(new Runnable()&#123; List list = new ArrayList(); queue.drainTo(list); if(channel.isWritable())&#123; channel.writeAndFlush(list); &#125; &#125;); &#125; public void ChannelReadFinish(Channel channel，Buffer Buffer)&#123; List result = handleBuffer();//处理数据 //从cmdQueue取出future，并设值，future.done(); &#125; public void ChannelWritable(Channel channel)&#123; channel.flush(); &#125; &#125; 这样做，能够充分的利用pipeline来提高I&#x2F;O能力，同时获取异步处理能力。 多连接短连接的HttpClient类似于竞对抓取的项目，往往需要建立无数的HTTP短连接，然后抓取，然后销毁，当需要单机抓取上千网站线程数又受制的时候，怎么保证性能呢? 何不尝试NIO，单线程进行连接、写、读操作？如果连接、读、写操作系统没有能力处理，简单的注册一个事件，等待下次循环就好了。 如何存储不同的请求&#x2F;响应呢？由于http是无状态没有版本的协议，又没有办法使用队列，好像办法不多。比较笨的办法是对于不同的socket，直接存储socket的引用作为map的key。 常见的RPC框架，如Thrift，Dubbo这种框架内部一般维护了请求的协议和请求号，可以维护一个以请求号为key，结果的result为future的map，结合NIO+长连接，获取非常不错的性能。 NIO高级主题Proactor与Reactor一般情况下，I&#x2F;O 复用机制需要事件分发器（event dispatcher）。 事件分发器的作用，即将那些读写事件源分发给各读写事件的处理者，就像送快递的在楼下喊: 谁谁谁的快递到了， 快来拿吧！开发人员在开始的时候需要在分发器那里注册感兴趣的事件，并提供相应的处理者（event handler)，或者是回调函数；事件分发器在适当的时候，会将请求的事件分发给这些handler或者回调函数。 涉及到事件分发器的两种模式称为：Reactor和Proactor。 Reactor模式是基于同步I&#x2F;O的，而Proactor模式是和异步I&#x2F;O相关的。在Reactor模式中，事件分发器等待某个事件或者可应用或个操作的状态发生（比如文件描述符可读写，或者是socket可读写），事件分发器就把这个事件传给事先注册的事件处理函数或者回调函数，由后者来做实际的读写操作。 而在Proactor模式中，事件处理者（或者代由事件分发器发起）直接发起一个异步读写操作（相当于请求），而实际的读写工作是由操作系统来完成的。发起时，需要提供的参数包括用于存放读到数据的缓存区、读的数据大小或用于存放外发数据的缓存区，以及这个请求完后的回调函数等信息。事件分发器得知了这个请求，它默默等待这个请求的完成，然后转发完成事件给相应的事件处理者或者回调。举例来说，在Windows上事件处理者投递了一个异步IO操作（称为overlapped技术），事件分发器等IO Complete事件完成。这种异步模式的典型实现是基于操作系统底层异步API的，所以我们可称之为“系统级别”的或者“真正意义上”的异步，因为具体的读写是由操作系统代劳的。 同步 IO 就是你自己下楼拿外卖，而异步 IO 就是外卖小哥送到你家，可以直接吃了！ 举个例子，将有助于理解Reactor与Proactor二者的差异，以读操作为例（写操作类似）。 在Reactor中实现读 注册读就绪事件和相应的事件处理器。 事件分发器等待事件。 事件到来，激活分发器，分发器调用事件对应的处理器。 事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。 在Proactor中实现读 处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。 事件分发器等待操作完成事件。 在分发器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分发器读操作完成。 事件分发器呼唤处理器。 事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分发器。 可以看出，两个模式的相同点，都是对某个I&#x2F;O事件的事件通知（即告诉某个模块，这个I&#x2F;O操作可以进行或已经完成)。在结构上，两者也有相同点：事件分发器负责提交IO操作（异步)、查询设备是否可操作（同步)，然后当条件满足时，就回调handler；不同点在于，异步情况下（Proactor)，当回调handler时，表示I&#x2F;O操作已经完成；同步情况下（Reactor)，回调handler时，表示I&#x2F;O设备可以进行某个操作（can read 或 can write)。 下面，我们将尝试应对为Proactor和Reactor模式建立可移植框架的挑战。在改进方案中，我们将Reactor原来位于事件处理器内的Read&#x2F;Write操作移至分发器（不妨将这个思路称为“模拟异步”），以此寻求将Reactor多路同步I&#x2F;O转化为模拟异步I&#x2F;O。以读操作为例子，改进过程如下： 注册读就绪事件和相应的事件处理器。并为分发器提供数据缓冲区地址，需要读取数据量等信息。 分发器等待事件（如在select()上等待）。 事件到来，激活分发器。分发器执行一个非阻塞读操作（它有完成这个操作所需的全部信息），最后调用对应处理器。 事件处理器处理用户自定义缓冲区的数据，注册新的事件（当然同样要给出数据缓冲区地址，需要读取的数据量等信息），最后将控制权返还分发器。如我们所见，通过对多路I&#x2F;O模式功能结构的改造，可将Reactor转化为Proactor模式。改造前后，模型实际完成的工作量没有增加，只不过参与者间对工作职责稍加调换。没有工作量的改变，自然不会造成性能的削弱。对如下各步骤的比较，可以证明工作量的恒定： 标准&#x2F;典型的Reactor 步骤1：等待事件到来（Reactor负责）。 步骤2：将读就绪事件分发给用户定义的处理器（Reactor负责）。 步骤3：读数据（用户处理器负责）。 步骤4：处理数据（用户处理器负责）。 改进实现的模拟Proactor 步骤1：等待事件到来（Proactor负责）。 步骤2：得到读就绪事件，执行读数据（现在由Proactor负责）。 步骤3：将读完成事件分发给用户处理器（Proactor负责）。 步骤4：处理数据（用户处理器负责）。 对于不提供异步I&#x2F;O API的操作系统来说，这种办法可以隐藏Socket API的交互细节，从而对外暴露一个完整的异步接口。借此，我们就可以进一步构建完全可移植的，平台无关的，有通用对外接口的解决方案。 代码示例如下： interface ChannelHandler&#123; void channelReadComplate(Channel channel，byte[] data); void channelWritable(Channel channel); &#125; class Channel&#123; Socket socket; Event event;//读，写或者连接 &#125; //IO线程主循环： class IoThread extends Thread&#123; public void run()&#123; Channel channel; while(channel=Selector.select())&#123;//选择就绪的事件和对应的连接 if(channel.event==accept)&#123; registerNewChannelHandler(channel);//如果是新连接，则注册一个新的读写处理器 Selector.interested(read); &#125; if(channel.event==write)&#123; getChannelHandler(channel).channelWritable(channel);//如果可以写，则执行写事件 &#125; if(channel.event==read)&#123; byte[] data = channel.read(); if(channel.read()==0)//没有读到数据，表示本次数据读完了 &#123; getChannelHandler(channel).channelReadComplate(channel，data;//处理读完成事件 &#125; if(过载保护)&#123; Selector.interested(read); &#125; &#125; &#125; &#125; Map handlerMap;//所有channel的对应事件处理器 &#125; Selector.wakeup()主要作用解除阻塞在Selector.select()&#x2F;select(long)上的线程，立即返回。 两次成功的select之间多次调用wakeup等价于一次调用。 如果当前没有阻塞在select上，则本次wakeup调用将作用于下一次select——“记忆”作用。 为什么要唤醒？ 注册了新的channel或者事件。 channel关闭，取消注册。 优先级更高的事件触发（如定时器事件），希望及时处理。 原理Linux上利用pipe调用创建一个管道，Windows上则是一个loopback的tcp连接。这是因为win32的管道无法加入select的fd set，将管道或者TCP连接加入select fd set。 wakeup往管道或者连接写入一个字节，阻塞的select因为有I&#x2F;O事件就绪，立即返回。可见，wakeup的调用开销不可忽视。 Buffer的选择通常情况下，操作系统的一次写操作分为两步： 将数据从用户空间拷贝到系统空间。 从系统空间往网卡写（同步 IO 与异步 IO 的区别发送在这里。 同理，读操作也分为两步： 将数据从网卡拷贝到系统空间（同步 IO 与异步 IO 的区别发送在这里）。 将数据从系统空间拷贝到用户空间。 对于NIO来说，缓存的使用可以使用 DirectByteBuffer 和 HeapByteBuffer。如果使用了DirectByteBuffer，一般来说可以减少一次系统空间到用户空间的拷贝。但Buffer创建和销毁的成本更高，更不宜维护，通常会用内存池来提高性能。 如果数据量比较小的中小应用情况下，可以考虑使用heapBuffer；反之可以用directBuffer。 NIO存在的问题使用NIO !&#x3D; 高性能，当连接数&lt;1000，并发程度不高或者局域网环境下NIO并没有显著的性能优势。 NIO并没有完全屏蔽平台差异，它仍然是基于各个操作系统的I&#x2F;O系统实现的，差异仍然存在。使用NIO做网络编程构建事件驱动模型并不容易，陷阱重重。 推荐大家使用成熟的NIO框架，如Netty，MINA等。解决了很多NIO的陷阱，并屏蔽了操作系统的差异，有较好的性能和编程模型。 总结最后总结一下到底NIO给我们带来了些什么： 事件驱动模型 避免多线程 单线程处理多任务 非阻塞I&#x2F;O，I&#x2F;O读写不再阻塞，而是返回0 基于block的传输，通常比基于流的传输更高效 更高级的IO函数，zero-copy IO多路复用大大提高了Java网络应用的可伸缩性和实用性","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"Netty 源码 — 线程模型的分析","slug":"Netty 源码 — 线程模型的分析","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.983Z","comments":true,"path":"post/46b9.html","link":"","permalink":"http://example.com/post/46b9.html","excerpt":"","text":"Netty 线程模型分析 阅读本文之前，需要了解 NIO 相关知识，可参阅我的文章：[NIO 与 epoll 知识详解](.&#x2F;NIO 与 epoll.md) Reactor 线程模型Netty 的线程模型 是基于 Reactor 线程模型的，Reactor 线程模型分为三种模型： 单线程模型：注册所有感兴趣的事件，一个线程管理多个 Channel，单线程轮询 IO 事件是否发生，若事件发生，在同一个线程中调用处理程序，属于 一对一 的模型。 多线程模型：多线程模型中，一个线程管理多个 Channel，仍然是单线程轮询 IO 事件是否发生，但将事件发生的处理程序交由线程池运行，属于 一对多 的模型。 主从线程模型：在这种模型中，有多个线程负责 IO 事件的连接，每个负责 IO 事件连接的线程又可以指派多个处理线程，属于 多对多 的模型。 这种模式通常有两种实现，严格意义上的实现应该是一个 Channel 可由多个线程管理，一个线程又可管理多个 Channel，这种实现需要在线程间共享 Channel，Netty 并没有采用这种方式。另一种不太规范的实现是一个线程管理多个 Channel，但创建多个线程，形象的说，就像多个多线程模型一起启动一样。 Netty 中可根据所调参数选择对应的模型，Netty 中有一个专门的线程组 BossGroup 用于接收发送 IO 事件，还有一个线程组 WorkerGroup 用以调用 handler。 在 Netty 中，即使设置 bossGroup 为多个线程，一个 Channel 仍然只属于一个线程管理，并不会由多个线程管理，因此如果服务端只有一个 ServerChannel，设置多线程 bossGroup 是没有意义的，除非有多个 Channel。 Netty 初始化线程池Netty 中的模型就是可创建 BossGroup 和 WorkerGroup 两个线程组，你可以指定对应的线程数。 在 Netty 中，每一个 EventLoop 其实就是一个线程，Netty 中的 IO 事件就是一个任务，每个任务都会被提交到 EventLoop 中，由 EventLoop 在事件循环中执行。 在 Netty 中，创建一个 EventLoopGroup 时就会自动创建多个 EventLoop 线程，数目由 nThreads 指定。 NioEventLoopGroup group = new NioEventLoopGroup(nThreads); 如果没有指定线程数，在 MultithreadEventLoopGroup 的静态方法中初始化默认的线程数为 CPU 核心数的两倍： static &amp;#123; DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt( \"io.netty.eventLoopThreads\", NettyRuntime.availableProcessors() * 2)); &amp;#125; Netty 使用 EventExecutor 数组来保存 EventLoop，EventLoop 继承于 EventExecutor，在 new NioEventLoopGroup 中，通过不断向上传递，在父类 MultithreadEventExecutorGroup 的构造方法中，EventExecutor 数组被创建： private final EventExecutor[] children; private final Set&lt;EventExecutor> readonlyChildren; protected MultithreadEventExecutorGroup(int nThreads, Executor executor, EventExecutorChooserFactory chooserFactory, Object... args) &amp;#123; children = new EventExecutor[nThreads]; for (int i = 0; i &lt; nThreads; i ++) &amp;#123; // 创建 NioEventLoop，此方法其实就是 new NioEventLoop children[i] = newChild(executor, args); &amp;#125; for (EventExecutor e: children) &amp;#123; // 添加监听器 e.terminationFuture().addListener(terminationListener); &amp;#125; // 去重 Set&lt;EventExecutor> childrenSet = new LinkedHashSet&lt;EventExecutor>(children.length); Collections.addAll(childrenSet, children); readonlyChildren = Collections.unmodifiableSet(childrenSet); &amp;#125; 所以，在创建 Group 的时候主要就是初始化了 EventLoop 线程组。 BossGroup 工作原理 绑定 Channel当调用了 bootstrap.bind() 方法时，开始正式进入核心环节，我们主要关注 Channel 是如何被绑定到 EventLoop 中的，调用此方法时，会经过如下调用链： AbstractBootstrap.bind() -> doBind() -> initAndRegister() -> config().group().register(channel) -> MultithreadEventLoopGroup.register(channel) -> SingleThreadEventLoop.register(channel) -> AbstractChannel.AbstractUnsafe.register() 从 MultithreadEventLoopGroup.register(channel) 方法看起： @Override public ChannelFuture register(Channel channel) &amp;#123; return next().register(channel); &amp;#125; 这个方法调用了 EventExecutorChooserFactory#next() 方法，next() 方法其实就是获取一个 EventLoop，跟进 next() 方法，发现 Netty 中只提供了轮询的方式获取 EventLoop： @Override public EventExecutor next() &amp;#123; return executors[Math.abs(idx.getAndIncrement() % executors.length)]; &amp;#125; 还记得 executors 数组吗？这里 executors 数组其实就是 Group 初始化的 EventLoop 数组，因此通过调用 next() 方法就轮询获得了一个 EventLoop，现在开始将 Channel 绑定到 EventLoop 中。 将目光移到调用链中的 AbstractUnsafe.register: public final void register(EventLoop eventLoop, final ChannelPromise promise) &amp;#123; // 省略, promise 是 channel 的包装, eventLoop 是调用 next() 得到的线程 AbstractChannel.this.eventLoop = eventLoop; // 如果给定的线程已经被启动运行了，那么直接注册 if (eventLoop.inEventLoop()) &amp;#123; register0(promise); &amp;#125; else &amp;#123; // 否则，要先启动一下，再注册，这里其实是向 Netty 提交了一个任务 eventLoop.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; register0(promise); &amp;#125; &amp;#125;); &amp;#125; &amp;#125; execute 方法是事件循环的开始方法，但这里我们先关注 register0(promise) 方法，register0 方法内调用了 AbstractNioChannel#doRegister() 方法，这个方法其实是 Netty NIO 与 JDK NIO 交互的地方： protected void doRegister() throws Exception &amp;#123; boolean selected = false; for (;;) &amp;#123; try &amp;#123; selectionKey = javaChannel().register(eventLoop().unwrappedSelector(), 0, this); return; &amp;#125; catch (CancelledKeyException e) &amp;#123; if (!selected) &amp;#123; eventLoop().selectNow(); selected = true; &amp;#125; else &amp;#123; throw e; &amp;#125; &amp;#125; &amp;#125; &amp;#125; javaChannel() 方法返回了已被绑定的、 jdk 原生的 Channel，此 Channel 由传递的地址注册，eventLoop().unwrappedSelector() 是对应线程的选择器，也是 jdk 原生的 Selector，doRegister() 方法还向通道附加了 this(AbstractNioChannel) 对象，在这里 Channel 正式向选择器注册了，而 selectionKey 被 AbstractNioChannel 所保存，用于后续 select。 事件循环现在来看看 execute(SingleThreadEventExecutor类下) 方法，这个方法将任务(doRegister方法)添加到任务队列后，然后调用了 startThread 方法，startThread 方法会判断线程是否已被启动： private void startThread() &amp;#123; if (state == ST_NOT_STARTED) &amp;#123; if (STATE_UPDATER.compareAndSet(this, ST_NOT_STARTED, ST_STARTED)) &amp;#123; try &amp;#123; doStartThread(); &amp;#125; catch (Throwable cause) &amp;#123; STATE_UPDATER.set(this, ST_NOT_STARTED); PlatformDependent.throwException(cause); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 如果未启动则调用 dotartThread 方法： private void doStartThread() &amp;#123; executor.execute(new Runnable() &amp;#123; public void run() &amp;#123; try &amp;#123; SingleThreadEventExecutor.this.run(); &amp;#125; catch (Throwable t) &amp;#123; logger.warn(\"Unexpected exception from an event executor: \", t); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 此方法提交任务到 Netty，执行 SingleThreadEventExecutor.this.run() 方法，这会新建线程执行： public void execute(Runnable command) &amp;#123; threadFactory.newThread(command).start(); &amp;#125; 也就是说到了这里才新建了线程，来看看 run 方法： protected void run() &amp;#123; for (;;) &amp;#123; switch(selectStrategy.calculateStrategy(selectNowSupplier, hasTasks())) &amp;#123; case SelectStrategy.CONTINUE: continue; case SelectStrategy.SELECT: // 堵塞等待 IO 事件到来，在这里面有解决 NIO 空轮询的 BUG // 内部实现有超时控制，一旦超时就会判断下有没有 Task，有 task 就退出循环，没有就继续循环x select(false); default: &amp;#125; // IO 事件与 时间调度任务执行的时间比例，默认是 50% final int ioRatio = this.ioRatio; final long ioStartTime = System.nanoTime(); try &amp;#123; // 处理 IO 事件 processSelectedKeys(); &amp;#125; finally &amp;#123; final long ioTime = System.nanoTime() - ioStartTime; // 处理任务，根据 ioRatio 与 IO 事件执行的时间计算出执行任务的最大允许时间 // 这不是很准确的，因为无论如何 Netty 必须会等待一个任务完成 // Netty 会等待一个任务完成再计算时间，如果超时，在下个任务开始前返回 runAllTasks(ioTime * (100 - ioRatio) / ioRatio); &amp;#125; &amp;#125; &amp;#125; public int calculateStrategy(IntSupplier selectSupplier, boolean hasTasks) throws Exception &amp;#123; // 如果有任务就执行非堵塞的 slect，否则返回 SELECT 执行堵塞的 select return hasTasks ? selectSupplier.get() : SelectStrategy.SELECT; &amp;#125; 在 select(wakenUp.getAndSet(false)) 方法中，有效解决了 Java NIO 空轮询的 BUG，出现这个 BUG 的原因是 某个连接出现异常，操作系统返回异常类型，因此会唤醒阻塞在selector.select上的线程，但由于 Java NIO 事件设计中并没有此异常事件，也没有对应的解决方案，因此被唤醒的线程将不停的运行，因为 select() 总是会返回(问题没有解决，在 Java 中会返回 0)，以至于占满 CPU。 在部分Linux的2.6的kernel中，poll和epoll对于突然中断的连接socket会对返回的eventSet事件集合置为POLLHUP，也可能是POLLERR，eventSet事件集合发生了变化，这就可能导致Selector会被唤醒。 在 Netty 的解决方案中，Netty 会统计空轮询出现的次数，一旦达到阈值时，Netty 会重新新建一个选择器，将原先选择器上有效的连接迁移至新的选择器上，重新运行。 当 IO 事件到来时，Netty 会根据 ioRatio 配置执行 IO 事件 和 任务，执行任务的时间与执行 IO 事件时间所占比例不高于 ioRatio，这么做是为了防止任务事件长时间堵塞而导致 IO 事件无法执行。 要想提交一条任务，只需执行如下代码，但记住，千万不要执行长时间堵塞代码，这会导致 IO 事件的执行也被堵塞： EventLoop eventLoop = channel.eventLoop(); eventLoop.execute(new Runnable() &amp;#123; @Override public void run() &amp;#123; System.out.println(\"Hello, Netty!\"); &amp;#125; &amp;#125;); 执行 IO 事件processSelectedKeys 方法其实调用了 processSelectedKeysOptimized 方法： private void processSelectedKeysOptimized() &amp;#123; for (int i = 0; i &lt; selectedKeys.size; ++i) &amp;#123; final SelectionKey k = selectedKeys.keys[i]; // 为了 GC，将其回收 selectedKeys.keys[i] = null; processSelectedKey(k, (AbstractNioChannel) a); &amp;#125; &amp;#125; 在这个方法内，遍历 select() 得到的 key，Netty 中准备就绪的 key 集合被封装成一个数组对象，而在 jdk 中的实现是一个 HashSet，这么做的好处是为了提高性能，操作数组比操作哈希快得多，当然，这里 Netty 更多的考虑是考虑到在实践中 HashSet.add() 发送哈希冲突的概率并不小，一旦发生哈希冲突，add 将是 O(N) 级别的。 随后调用 processSelectedKey 方法： private void processSelectedKey(SelectionKey k, AbstractNioChannel ch) &amp;#123; final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe(); try &amp;#123; int readyOps = k.readyOps(); if ((readyOps &amp; SelectionKey.OP_CONNECT) != 0) &amp;#123; int ops = k.interestOps(); ops &amp;= ~SelectionKey.OP_CONNECT; k.interestOps(ops); unsafe.finishConnect(); &amp;#125; if ((readyOps &amp; SelectionKey.OP_WRITE) != 0) &amp;#123; ch.unsafe().forceFlush(); &amp;#125; // 这里会触发连接事件 if ((readyOps &amp; (SelectionKey.OP_READ | SelectionKey.OP_ACCEPT)) != 0 || readyOps == 0) &amp;#123; unsafe.read(); &amp;#125; &amp;#125; catch (CancelledKeyException ignored) &amp;#123; unsafe.close(unsafe.voidPromise()); &amp;#125; &amp;#125; 这完全就是 jdk 的那一套嘛！根据 readyOps 判断事件的类型，进而调用不同的 unsafe 方法，注意这里 unsafe 是与对应通道绑定的，这在代码 final AbstractNioChannel.NioUnsafe unsafe = ch.unsafe() 中有体现，所以通过 unsafe 是可以获得到对应通道的配置和数据的， 这里分析下 unsafe.read() 方法，： @Override public void read() &amp;#123; assert eventLoop().inEventLoop(); final ChannelConfig config = config(); final ChannelPipeline pipeline = pipeline(); final RecvByteBufAllocator.Handle allocHandle = unsafe().recvBufAllocHandle(); Throwable exception = null; try &amp;#123; try &amp;#123; do &amp;#123; // 将消息写入缓存 int localRead = doReadMessages(readBuf); allocHandle.incMessagesRead(localRead); &amp;#125; while (allocHandle.continueReading()); &amp;#125; catch (Throwable t) &amp;#123; exception = t; &amp;#125; int size = readBuf.size(); for (int i = 0; i &lt; size; i ++) &amp;#123; readPending = false; // 将每个消息交由 pipeline, Netty 会帮我们整合 // readBuf 是一个 Object 数组 pipeline.fireChannelRead(readBuf.get(i)); &amp;#125; readBuf.clear(); allocHandle.readComplete(); pipeline.fireChannelReadComplete(); &amp;#125; finally &amp;#123; if (!readPending &amp;&amp; !config.isAutoRead()) &amp;#123; removeReadOp(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; 简单来说，此方法就是将数据读入缓存中，默认是使用池化技术的 ByteBuf，然后调用 pipeline.fireChannelRead(byteBuf) 方法进行转发。 一个 pipeline 对应一个 Channel，pipeline 其实就是一个双端链表，链表的节点由 Handler 组成，入站消息由 head 向 tail 依次遍历 Handler，出战事件由 tail 向 head 依次遍历 Handler。 来看看 readBuf.get(i) 到底是什么： 消息竟然是一个 NioSocketChannel，此 Channel 已经是对应 IO的通道了，将用于 WorkerGroup 工作！ NioSocketChannel 到底是如何产生的呢？一切都在 int localRead = doReadMessages(readBuf); 这一行代码中： protected int doReadMessages(List&lt;Object> buf) throws Exception &amp;#123; // 调用 javaChannel() 获取包装后的服务器 channel，然后调用 accept 获取与客户端的连接 SocketChannel ch = SocketUtils.accept(javaChannel()); try &amp;#123; if (ch != null) &amp;#123; // 将包装后的 channel 添加至缓存 buf.add(new NioSocketChannel(this, ch)); return 1; &amp;#125; &amp;#125; catch (Throwable t) &amp;#123; logger.warn(\"Failed to create a new channel from an accepted socket.\", t); &amp;#125; return 0; &amp;#125; 现在，一个崭新的 NioSocketChannel 终于诞生了，它将作为参数，调用fireChannelRead。 WorkerGroup 工作上述仅仅只是在 BossGroup 中工作，IO 事件已经就绪，ByteBuf 也已经准备好了，现在终于开始调用pipeline.fireChannelRead(byteBuf) 方法。 在一系列调用链中，会调用 ChannelInboundHandler#channelRead 方法，此方法仅当当前Channel已从对等方读取消息时调用。 这是个接口类，经过调试，这会调用 ServerBootstrap 下 channelRead 方法： public void channelRead(ChannelHandlerContext ctx, Object msg) &amp;#123; final Channel child = (Channel) msg; child.pipeline().addLast(childHandler); try &amp;#123; childGroup.register(child).addListener(new ChannelFutureListener() &amp;#123; @Override public void operationComplete(ChannelFuture future) throws Exception &amp;#123; if (!future.isSuccess()) &amp;#123; forceClose(child, future.cause()); &amp;#125; &amp;#125; &amp;#125;); &amp;#125; catch (Throwable t) &amp;#123; forceClose(child, t); &amp;#125; &amp;#125; 这个方法向 pipeline 中添加了我们在启动程序中配置的处理者，然后调用了 childGroup.register，这与我们之前分析的 register 方法是一样的，只不过之前默认是采用父类的 BossGroup 的方法，而现在指明调用 childGroup.register 方法，也就是向 WorkerGroup 注册一个通道！不过现在这个通道已经是对应 IO 的 NioSocketChannel，而不再是服务端接收请求的通道了。 然后这又会经历：轮询得到 EventLoop -&gt; 执行 register0 方法绑定 Channel -&gt; 执行doStratThread 方法启动新线程 -&gt; 事件循环 -&gt; 执行 select()，select 必然会立即返回 -&gt; 遍历结果 key 集合。 不过这一次，由于 Channel 已经是和客户端的连接，此次事件将会直接读取数据！ 具体的 read 操作仍然是在 unsafe.read() 函数封装里面，但是在 WorkGroup 实现中，doReadMessages 不再是创建连接，而是由 NioUdtMessageConnectorChannel 类实现： protected int doReadMessages(List&lt;Object> buf) throws Exception &amp;#123; final int maximumMessageSize = config.getReceiveBufferSize(); final ByteBuf byteBuf = config.getAllocator().directBuffer( maximumMessageSize); final int receivedMessageSize = byteBuf.writeBytes(javaChannel(), maximumMessageSize); if (receivedMessageSize &lt;= 0) &amp;#123; byteBuf.release(); return 0; &amp;#125; if (receivedMessageSize >= maximumMessageSize) &amp;#123; javaChannel().close(); throw new ChannelException( \"Invalid config : increase receive buffer size to avoid message truncation\"); &amp;#125; // delivers a message buf.add(new UdtMessage(byteBuf)); return 1; &amp;#125; 在这个实现方式里，数据会被封装为一个 ByteBufHolder，可以获取 ByteBuf，同时这里也涉及到了池化技术和直接内存等知识。 总结Netty 线程模型其实核心就是 boss 和 worker 两个线程组，通过构造这两个线程组，Netty 完美的贴切了 Reactor 模型，并且通过调整参数，我们可以任意的选择不同的 Reactor 模式。 在 Netty 中，我们可以提交自己的任务， 但 Netty 中的 任务 和 IO 事件处理是在同一个事件循环中运行的，长时间的任务会堵塞 IO 事件的处理，Netty 中的 ioRatio 适当缓解了这个问题，但没有根治，我们仍需小心提交任务。 Netty 中使用优化的 SelectedSelectionKeySet，在 Netty 中，存储 key 集合不再是 HashSet，而是一个数组，这使得 add 十分高效，Netty 通过反射的方式巧妙的替换掉了原生 Selector 的字段。 Netty 自定义的 select 方法相较于原生方法更加高效，并且也解决了一些问题，例如空轮询 Bug，Netty 通过检测空轮询次数，一旦到达阈值，则重建 Selector。 一旦消息经 boss 到达 worker，并由 worker 经过相同 select 步骤后（这里会调用重载的方法，不会创建连接），消息就正式进入管道，在双端链表中传递。 Netty 中的参数可参考：netty（十九）Netty优化 - option中的参数优化 - 掘金 (juejin.cn)","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"Redis 设计与实现重点回顾","slug":"Redis 设计与实现重点回顾","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.986Z","comments":true,"path":"post/b68f.html","link":"","permalink":"http://example.com/post/b68f.html","excerpt":"","text":"Redis 设计与实现重点回顾 注：本文是《Redis 设计与实现》章节后的重点回顾，夹杂着一些个人理解 第一部分：数据结构与对象简单动态字符串 Redis 只会使用 C 字符串作为字面量， 在大多数情况下， Redis 使用 SDS （Simple Dynamic String，简单动态字符串）作为字符串表示。 比起 C 字符串， SDS 具有以下优点： 常数复杂度获取字符串长度。 杜绝缓冲区溢出。 减少修改字符串长度时所需的内存重分配次数。 二进制安全。 兼容部分 C 字符串函数。 Redis 会共享值为 0 到 9999 的字符串对象。 链表 链表被广泛用于实现 Redis 的各种功能， 比如列表键， 发布与订阅， 慢查询， 监视器， 等等。 每个链表节点由一个 listNode 结构来表示， 每个节点都有一个指向前置节点和后置节点的指针， 所以 Redis 的链表实现是双端链表。 每个链表使用一个 list 结构来表示， 这个结构带有表头节点指针、表尾节点指针、以及链表长度等信息。 因为链表表头节点的前置节点和表尾节点的后置节点都指向 NULL ， 所以 Redis 的链表实现是无环链表。 通过为链表设置不同的类型特定函数， Redis 的链表可以用于保存各种不同类型的值。 字典 字典被广泛用于实现 Redis 的各种功能， 其中包括数据库和哈希键，例如set name abc就是通过哈希字典实现的，键是字符串对象 “name”，值是字符串对象 “abc”，redis 底层所有的存储几乎都依赖于字典实现。 Redis 中的字典使用哈希表作为底层实现， 每个字典带有两个哈希表， 一个用于平时使用， 另一个仅在进行 rehash 时使用，即 redis 保存了哈希数组 ht[2]，ht[0] 用以平时使用，ht[1] 用以 rehash。 当字典被用作数据库的底层实现， 或者哈希键的底层实现时， Redis 使用 MurmurHash2 算法来计算键的哈希值。 哈希表使用链地址法来解决键冲突， 被分配到同一个索引上的多个键值对会连接成一个单向链表。 在对哈希表进行扩展或者收缩操作时， 程序需要将现有哈希表包含的所有键值对 rehash 到新哈希表里面， 并且这个 rehash 过程并不是一次性地完成的， 而是渐进式地完成的，即可能每一次命令完成部分键值的重新散列。 扩展和收缩哈希表的工作可以通过执行 rehash （重新散列）操作来完成， Redis 对字典的哈希表执行 rehash 的步骤如下： 为字典的 ht[1] 哈希表分配空间， 这个哈希表的空间大小取决于要执行的操作， 以及 ht[0] 当前包含的键值对数量 （也即是 ht[0].used 属性的值）： 如果执行的是扩展操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used * 2 的 （2 的 n 次方幂)； 如果执行的是收缩操作， 那么 ht[1] 的大小为第一个大于等于 ht[0].used 的 。 将保存在 ht[0] 中的所有键值对 rehash 到 ht[1] 上面： rehash 指的是重新计算键的哈希值和索引值， 然后将键值对放置到 ht[1] 哈希表的指定位置上。 当 ht[0] 包含的所有键值对都迁移到了 ht[1] 之后 （ht[0] 变为空表）， 释放 ht[0] ， 将 ht[1] 设置为 ht[0] ， 并在 ht[1] 新创建一个空白哈希表， 为下一次 rehash 做准备。 跳跃表 跳跃表是有序集合的底层实现之一， 除此之外它在 Redis 中没有其他应用。 Redis 的跳跃表实现由 zskiplist 和 zskiplistNode 两个结构组成， 其中 zskiplist 用于保存跳跃表信息（比如表头节点、表尾节点、长度）， 而 zskiplistNode 则用于表示跳跃表节点。 每个跳跃表节点的层高都是 1 至 32 之间的随机数。 在同一个跳跃表中， 多个节点可以包含相同的分值， 但每个节点的成员对象必须是唯一的。 跳跃表中的节点按照分值大小进行排序， 当分值相同时， 节点按照成员对象的大小进行排序。 整数集合typedef struct intset &amp;#123; // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[]; &amp;#125; intset; 整数集合是集合键的底层实现之一。 整数集合的底层实现为数组， 这个数组以有序、无重复的方式保存集合元素， 在有需要时， 程序会根据新添加元素的类型， 改变这个数组的类型。在具体实现中，整数集合由一个结构体表示，结构体内存在一个字段 encoding，程序会根据这个字段的值来判断具体数组的编码，例如如果 encoding 为 int16_t，那么 contents 数组每两个元素表示一个值。 升级操作为整数集合带来了操作上的灵活性， 并且尽可能地节约了内存。 整数集合只支持升级操作， 不支持降级操作。 压缩列表压缩列表是 Redis 为了节约内存而开发的， 由一系列特殊编码的连续内存块组成的顺序型（sequential）数据结构。 一个压缩列表可以包含任意多个节点（entry）， 每个节点可以保存一个字节数组或者一个整数值。 图 7-1 展示了压缩列表的各个组成部分， 表 7-1 则记录了各个组成部分的类型、长度、以及用途。 每个 entry 又是由evious_entry_length 、 encoding 、 content 三个部分组成，这指示着 节点的前一个节点的长度、节点的编码、节点的内容。 表 7-1 压缩列表各个组成部分的详细说明 属性 类型 长度 用途 zlbytes uint32_t 4 字节 记录整个压缩列表占用的内存字节数：在对压缩列表进行内存重分配， 或者计算 zlend 的位置时使用。 zltail uint32_t 4 字节 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节： 通过这个偏移量，程序无须遍历整个压缩列表就可以确定表尾节点的地址。 zllen uint16_t 2 字节 记录了压缩列表包含的节点数量： 当这个属性的值小于 UINT16_MAX （65535）时， 这个属性的值就是压缩列表包含节点的数量； 当这个值等于 UINT16_MAX 时， 节点的真实数量需要遍历整个压缩列表才能计算得出。 entryX 列表节点 不定 压缩列表包含的各个节点，节点的长度由节点保存的内容决定。 zlend uint8_t 1 字节 特殊值 0xFF （十进制 255 ），用于标记压缩列表的末端。 图 7-2 展示了一个压缩列表示例： 列表 zlbytes 属性的值为 0x50 （十进制 80）， 表示压缩列表的总长为 80 字节。 列表 zltail 属性的值为 0x3c （十进制 60）， 这表示如果我们有一个指向压缩列表起始地址的指针 p ， 那么只要用指针 p 加上偏移量 60 ， 就可以计算出表尾节点 entry3 的地址。 列表 zllen 属性的值为 0x3 （十进制 3）， 表示压缩列表包含三个节点。 图 7-3 展示了另一个压缩列表示例： 列表 zlbytes 属性的值为 0xd2 （十进制 210）， 表示压缩列表的总长为 210 字节。 列表 zltail 属性的值为 0xb3 （十进制 179）， 这表示如果我们有一个指向压缩列表起始地址的指针 p ， 那么只要用指针 p 加上偏移量 179 ， 就可以计算出表尾节点 entry5 的地址。 列表 zllen 属性的值为 0x5 （十进制 5）， 表示压缩列表包含五个节点。 我们都知道在计算机底层内存都是 8 字节对齐的，这意味着如果使用不满 8 字节仍然会被填充以 8 字节对齐，这就产生了内存碎片，压缩列表就是为了解决这些内部碎片而生的，压缩列表使每一个元素紧密的连接在一起以避免内部碎片，在 C 语言中只需使用 void* 就可以做到这一点，但代价是必须要有额外的信息表示每个元素的大小或链表的总长度。 压缩列表是一种为节约内存而开发的顺序型数据结构。 压缩列表被用作列表键和哈希键的底层实现之一，在表示哈希时，键值是严格靠在一起的。 压缩列表可以包含多个节点，每个节点可以保存一个字节数组或者整数值。 添加新节点到压缩列表， 或者从压缩列表中删除节点， 可能会引发连锁更新操作， 但这种操作出现的几率并不高。 这是因为节点的 previous_entry_length 要么为 1字节（能够指示 255 字节大小的程度），要么为 5 字节，这取决与前一个节点的大小，如果前一个节点小于 255 字节，那么 previous_entry_length 为 1字节，否则为 5 字节。 现在如果某节点的 previous_entry_length 占用 1字节，而现在向其前面插入大小更大的节点，那么该节点的 previous_entry_length 的大小应该就会被重新分配，从而导致节点的大小被重新分配，从而又导致其他节点的更新。 对象typedef struct redisObject &amp;#123; // 类型 unsigned type:4; // 编码 unsigned encoding:4; // 指向底层实现数据结构的指针 void *ptr; // 最后一次被访问的时间 unsigned lru:22; // 引用计数 unsigned count:32; // 更多字段...... &amp;#125; robj; Redis 数据库中的每个键值对的键和值都是一个对象。 Redis 共有 字符串、列表、哈希、集合、有序集合 五种类型的对象， 每种类型的对象至少都有两种或以上的编码方式， 不同的编码可以在不同的使用场景上优化对象的使用效率。 列表对象的编码可以是 ziplist 或者 linkedlist ，这取决于列表对象的大小，较小的对象采用 ziplist； 集合对象的编码可以是 intset 或者 linkedlist，这取决于具体的数据类型。 有序集合的编码可以是 zipkist 或者 skiplist 和 hashtable ，跳跃表和哈希表的共同使用的效果类似与 Java 中的 TreeMap； 字符串对象的编码可以是 int 、 raw 或者 embstr ，例如 set age 123 则会使用 int 类型来保存 age 对应的字符串，raw 是简单动态字符串，embstr 是针对短字符串的，其分配内存的次数减少了一次，例如 set name abcd，row 编码会为 name 和 abcd 各分配一次，而 embstr 会一次性分配足够的空间。 TYPE key 可以查看 key 对应的 val 的对象类型，OBJECT ENCODING key 命令可以查看 key 对应的 val 的编码方式。 服务器在执行某些命令之前， 会先检查给定键的类型能否执行指定的命令， 而检查一个键的类型就是检查键的值对象的类型。 Redis 的对象系统带有引用计数实现的内存回收机制， 当一个对象不再被使用时， 该对象所占用的内存就会被自动释放。 Redis 会共享值为 0 到 9999 的字符串对象。 对象会记录自己的最后一次被访问的时间， 这个时间可以用于计算对象的空转时间。 第二部分：单机数据库的实现数据库 Redis 服务器的所有数据库都保存在 redisServer.db 数组中， 而数据库的数量则由 redisServer.dbnum 属性保存。 客户端通过修改目标数据库指针， 让它指向 redisServer.db 数组中的不同元素来切换不同的数据库。 数据库主要由 dict 和 expires 两个字典构成， 其中 dict 字典负责保存键值对， 而 expires 字典则负责保存键的过期时间。 因为数据库由字典构成， 所以对数据库的操作都是建立在字典操作之上的。 数据库的键总是一个字符串对象， 而值则可以是任意一种 Redis 对象类型， 包括字符串对象、哈希表对象、集合对象、列表对象和有序集合对象， 分别对应字符串键、哈希表键、集合键、列表键和有序集合键。 expires 字典的键指向数据库中的某个键， 而值则记录了数据库键的过期时间， 过期时间是一个以毫秒为单位的 UNIX 时间戳。 Redis 使用惰性删除和定期删除两种策略来删除过期的键： 惰性删除策略只在碰到过期键时才进行删除操作， 定期删除策略则每隔一段时间， 主动查找并删除部分过期键，这通常是由 redis 的后台线程serverCron 函数完成，默认的间隔是 100ms。 执行 SAVE 命令或者 BGSAVE 命令所产生的新 RDB 文件不会包含已经过期的键。 重载时会根据主服务器过期字典忽略过期键。 执行 BGREWRITEAOF 命令所产生的重写 AOF 文件不会包含已经过期的键。 当一个过期键被删除之后， 服务器会追加一条 DEL 命令到现有 AOF 文件的末尾， 显式地删除过期键。 当主服务器删除一个过期键之后， 它会向所有从服务器发送一条 DEL 命令， 显式地删除过期键。 从服务器即使发现过期键， 也不会自作主张地删除它， 而是等待主节点发来 DEL 命令， 这种统一、中心化的过期键删除策略可以保证主从服务器数据的一致性。 当 Redis 命令对数据库进行修改之后， 服务器会根据配置， 向客户端发送数据库通知。 当内存达到限制时，Redis 具体的回收策略是通过 maxmemory-policy 配置项配置的。 no-eviction：不清除数据，只是返回错误，这样会导致浪费掉更多的内存，对大多数写命令（DEL 命令和其他的少数命令例外） allkeys-lru：从所有的数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰，以供新数据使用 volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰，以供新数据使用 allkeys-random：从所有数据集（server.db[i].dict）中任意选择数据淘汰，以供新数据使用 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰，以供新数据使用 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰，以供新数据使用 RDB 持久化 RDB 文件用于保存和还原 Redis 服务器所有数据库中的所有键值对数据。 SAVE 命令由服务器进程直接执行保存操作，所以该命令会阻塞服务器。 BGSAVE 命令由子进程执行保存操作，所以该命令不会阻塞服务器，而是在后台工作。 服务器状态中会保存所有用 save 选项设置的保存条件，当任意一个保存条件被满足时，服务器会自动执行 BGSAVE 命令，这就需要 redis 在执行完命名后记录一些数据，例如是否变脏。 # 配置 save 900 1 # 900s 内对数据库有 1 次修改save 300 10 # 300s 内对数据库有 10 次修改save 60 10000 # 60s 内对数据库有 10000 次修改 检测配置文件仍然是由后台线程serverCron 函数完成，而该函数默认的间隔是 100ms，该函数会先检查时间间隔最短的配置，例如上面默认配置中，先检查 60s 内是否有 10000 次修改，如果没有则检查 300s 内是否有 10 次修改…… RDB 文件是一个经过压缩的二进制文件，由多个部分组成。 对于不同类型的键值对， RDB 文件会使用不同的方式来保存它们。 RDB 的保存方式是直接存储数据，对于不同类型的键值对， RDB 文件会使用不同的方式来保存它们。 AOF 持久化 AOF 文件通过保存所有修改数据库的写命令请求来记录服务器的数据库状态。 AOF 文件中的所有命令都以 Redis 命令请求协议的格式保存。 命令请求会先保存到 AOF 缓冲区里面， 之后再定期写入并同步到 AOF 文件。 appendfsync 选项的不同值对 AOF 持久化功能的安全性、以及 Redis 服务器的性能有很大的影响。 always 每次都将缓冲区的内容立即写入aof文件种 everysec(默认的) 距离上次同步超过一秒就进行同步，有专门的线程负责执行 no 就是由磁盘决定什么时候将缓冲区存入磁盘 服务器只要载入并重新执行保存在 AOF 文件中的命令， 就可以还原数据库本来的状态。 AOF 重写可以产生一个新的 AOF 文件， 这个新的 AOF 文件和原有的 AOF 文件所保存的数据库状态一样， 但体积更小。 AOF 重写是一个有歧义的名字， 该功能是通过读取数据库中的键值对来实现的， 程序无须对现有 AOF 文件进行任何读入、分析或者写入操作。 在执行 BGREWRITEAOF 命令时， Redis 服务器会维护一个 AOF 重写缓冲区， 该缓冲区会在子进程创建新 AOF 文件的期间， 记录服务器执行的所有写命令。 当子进程完成创建新 AOF 文件的工作之后， 服务器会将重写缓冲区中的所有内容追加到新 AOF 文件的末尾， 使得新旧两个 AOF 文件所保存的数据库状态一致。 最后， 服务器用新的 AOF 文件替换旧的 AOF 文件， 以此来完成 AOF 文件重写操作。 AOF 通过记录客户写操作命令来完成备份，好处是你可以很清晰的知道在数据丢失这段时间内客户执行了什么操作，坏处是这可能会造成一定的冗余，例如对同一个键执行多次 set 命令，那么只有最后一次 set 是有效的，前几次都是冗余的，因此长时间后，AOF 文件会变得臃肿，所以才有 BGREWRITEAOF（AOF 重写）这种操作出现。 事件Redis 基于 Reactor 模式 开发了自己的网络事件处理器： 这个处理器被称为文件事件处理器（file event handler）： 文件事件处理器使用 I&#x2F;O 多路复用 程序来同时监听多个套接字， 并根据套接字目前执行的任务来为套接字关联不同的事件处理器。 当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关闭（close）等操作时， 与操作相对应的文件事件就会产生， 这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。 虽然文件事件处理器以单线程方式运行， 但通过使用 I&#x2F;O 多路复用程序来监听多个套接字， 文件事件处理器既实现了高性能的网络通信模型， 又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接， 这保持了 Redis 内部单线程设计的简单性。 文件事件是对套接字操作的抽象， 每当一个套接字准备好执行连接应答（accept）、写入、读取、关闭等操作时， 就会产生一个文件事件。 因为一个服务器通常会连接多个套接字， 所以多个文件事件有可能会并发地出现。 I&#x2F;O 多路复用程序负责监听多个套接字， 并向文件事件分派器传送那些产生了事件的套接字。 尽管多个文件事件可能会并发地出现， 但 I&#x2F;O 多路复用程序总是会将所有产生事件的套接字都入队到一个队列里面， 然后通过这个队列， 以有序）、同步、每次一个套接字的方式向文件事件分派器传送套接字： 当上一个套接字产生的事件被处理完毕之后（该套接字为事件所关联的事件处理器执行完毕）， I&#x2F;O 多路复用程序才会继续向文件事件分派器传送下一个套接字， 如图 。 文件事件分派器接收 I&#x2F;O 多路复用程序传来的套接字， 并根据套接字产生的事件的类型， 调用相应的事件处理器。 服务器会为执行不同任务的套接字关联不同的事件处理器， 这些处理器是一个个函数， 它们定义了某个事件发生时， 服务器应该执行的动作。 事件调度程序伪代码： void aeProcessEvents() &amp;#123; while (true) &amp;#123; // 获取距离当前时间最近的事件事件 timeEvent = aeSerachNearestEvent(); // 计算距离现在还剩多久 deltaTime = timeEvent.when - nowTime; // 如果到时间了，则立即执行 if (deltaTime &lt;= 0) &amp;#123; doTimeEvent(timeEvent); continue; &amp;#125; // 否则等待堵塞文件事件产生 // 堵塞等待的最大时间为 deltaTime fileEvent = aeApiPoll(deltaTime); // 如果有文件事件发生，则执行文件事件 if (fileEvent != null) &amp;#123; doFileEvent(fileEvent); &amp;#125; // 如果到时间了，则执行时间事件，注意由于可能会等待文件事件执行完毕，deltaTime 可能为负 if (deltaTime &lt;= 0) &amp;#123; doTimeEvent(timeEvent); &amp;#125; &amp;#125; &amp;#125; Redis 服务器是一个事件驱动程序， 服务器处理的事件分为时间事件和文件事件两类。 文件事件处理器是基于 Reactor 模式实现的网络通讯程序。 文件事件是对套接字操作的抽象： 每次套接字变得可应答（acceptable）、可写（writable）或者可读（readable）时， 相应的文件事件就会产生。 文件事件分为 AE_READABLE 事件（读事件）和 AE_WRITABLE 事件（写事件）两类。 时间事件分为定时事件和周期性事件： 定时事件只在指定的时间达到一次， 而周期性事件则每隔一段时间到达一次。 服务器在一般情况下只执行 serverCron 函数一个时间事件， 并且这个事件是周期性事件。 文件事件和时间事件之间是合作关系， 服务器会轮流处理这两种事件， 并且处理事件的过程中也不会进行抢占。 时间事件的实际处理时间通常会比设定的到达时间晚一些。 客户端typedef struct redisClient &amp;#123; // 使用哪个数据库 int db; // 套接字描述符，当为 -1 时表示伪客户端 int fd; // 客户名字 robj *name; // 输入缓冲区，客户发来的请求命令会暂时的保存在这个简单字符串缓存中 sds querybuf; // 命令参数，由服务器对 querybuf 解析得出 robj **argv; // 命令参数长度，由服务器对 querybuf 解析得出 int argc; // 命令类型，指向一个具体的解决函数，由服务器对 querybuf 解析得出 struct redisCommand *cmd; // 回复缓存，服务器的回复，暂时存放 char buf[REDIS_REPLY_CHUNK_BYTES]; // ... &amp;#125; redisClient; 服务器状态结构使用 clients 链表连接起多个客户端状态， 新添加的客户端状态会被放到链表的末尾。 客户端状态的 flags 属性使用不同标志来表示客户端的角色， 以及客户端当前所处的状态，例如集群中任何一太服务器可能都是一个客户端，执行 AOF 文件时也需要一个伪客户端。 输入缓冲区记录了客户端发送的命令请求， 这个缓冲区的大小不能超过 1 GB 。 命令的参数和参数个数会被记录在客户端状态的 argv 和 argc 属性里面， 而 cmd 属性则记录了客户端要执行命令的实现函数。 客户端有固定大小缓冲区和可变大小缓冲区两种缓冲区可用， 其中固定大小缓冲区的最大大小为 16 KB ， 而可变大小缓冲区的最大大小不能超过服务器设置的硬性限制值。 输出缓冲区限制值有两种， 如果输出缓冲区的大小超过了服务器设置的硬性限制， 那么客户端会被立即关闭； 除此之外， 如果客户端在一定时间内， 一直超过服务器设置的软性限制， 那么客户端也会被关闭。 当一个客户端通过网络连接连上服务器时， 服务器会为这个客户端创建相应的客户端状态。 网络连接关闭、 发送了不合协议格式的命令请求、 成为 CLIENT_KILL 命令的目标、 空转时间超时、 输出缓冲区的大小超出限制， 以上这些原因都会造成客户端被关闭。 处理 Lua 脚本的伪客户端在服务器初始化时创建， 这个客户端会一直存在， 直到服务器关闭。 载入 AOF 文件时使用的伪客户端在载入工作开始时动态创建， 载入工作完毕之后关闭。 服务器现在，我们终于可以来看看客户键入命令后到收到回复这段时间发生了什么，举个例子， 如果我们使用客户端执行以下命令： redis&gt; SET KEY VALUE OK 客户端发送命令请求到服务器。当用户键入 SET KEY VALUE 时，redis-cli 会将命令封装成符合 redis 协议的命令，例如*3\\r\\n$3\\r\\nSET\\r\\n$3\\r\\nKEY\\r\\n$5\\r\\nVALUE\\r\\n。 服务器接收到客户端网络套接字，由 IO 多路复用程序读取套接字，事件分发器根据协议类型交由命令请求处理器。 处理器解析客户请求，将请求放入 redisClient 请求缓存中，并解析参数和参数长度。随后命令请求处理器会调用命令执行器执行命令。 命令执行器首先会根据请求类型到内置命令哈希表中查找对应的 redisCommand（执行对应命令的函数），例如这里会找到 setCommand，然后将它放入 redisClient 结构体中。 接下来命令执行器会进行一些健壮性检查，例如： redisCommand 是否为 NULL。 客户是否通过了身份验证。 如果服务器正在进行 AOF 或 RDB 载入，则拒绝执行。 客户端是否开启了订阅功能，如果开启则拒绝执行与订阅无关的命令。 …… 如果检查都能通过，命令执行器会调用 redisCommand，传入参数执行命令。 执行完命令后，命令执行器会进行一些代理操作，例如增加客户调用次数，检查是否需要写入 AOF，记录脏数据次数…… 一切都完成后，命令执行器为客户端的套接字描述符关联命令回复处理器，一旦 IO 多路复用程序检测到套接字变的可写，会调用命令回复处理器，命令回复处理器会将处理结果发送给客户端。 客户端收到回复后，由于回复也是符合 redis 协议字符串，客户端会转换成客户可读的模式。例如服务器发送+ok\\r\\n1 会被转换成ok\\r\\n。 重点回顾： 一个命令请求从发送到完成主要包括以下步骤： 1. 客户端将命令请求发送给服务器； 2. 服务器读取命令请求，并分析出命令参数； 3. 命令执行器根据参数查找命令的实现函数，然后执行实现函数并得出命令回复； 4. 服务器将命令回复返回给客户端。 serverCron 函数默认每隔 100 毫秒执行一次， 它的工作主要包括更新服务器状态信息， 处理服务器接收的 SIGTERM 信号， 管理客户端资源和数据库状态， 检查并执行持久化操作， 等等。 服务器从启动到能够处理客户端的命令请求需要执行以下步骤： 1. 初始化服务器状态； 2. 载入服务器配置； 3. 初始化服务器数据结构； 4. 还原数据库状态； 5. 执行事件循环。 第三部分：多机数据库的实现复制复制通常是针对主从复制的，主服务器需要向从服务器发送写命令，而从服务器也可以要求主服务器进行同步复制，前者是命令传播，进行增量更新，后者是复制快照。 早期版本的 SYNC 命令十分暴力，主服务器会发送所有的 RDB 文件给从服务器，复制是异步的，在发送的这段时间，所有的数据变更被积累在一个缓冲区中，发送完成后在同步将缓冲区的数据变更全部发送即可完成复制。 SYNC 命令的缺陷十分明显，不能实现增量更新，即部分复制，后来的 PSYNC 解决了这个缺陷，PSYNC 拥有完全同步和部分同步两个语义。 在 PSYNC 的实现中，部分重同步通过复制偏移量、复制积压缓冲区、服务器运行 ID 三个部分来实现。 在命令传播时，主从服务器各自维护复制语句的偏移量，例如如果主服务器偏移量为 100，而从服务器偏移量为 50，服务器应该补偿 50 ~ 100 字节的数据给服务器，RDB 肯定无法做到这一点，因为 RDB 存储的是整个数据库数据，没办法抽离，因此需要引入复制积压缓冲区. 主服务器传播命令时还会将命令写入复制积压缓冲区，命令会有一个对应的偏移量为标识，如果从服务器发来的偏移量能够在复制积压缓冲区找到，那么就执行部分复制，否则执行完全同步。当然，前提是双方维护的主服务器 RUN ID 确实一致，如果从服务器之前 salve 的不是当前的主服务器，那么自然就不能执行部分复制。 有了 PSYNC 命令后，主从复制也能更加高效的应对网络问题，例如如果某条命令因为网络问题没有同步到从服务器怎么办？ 在 Redis 中，每个从服务器如果超过一定时间没有收到命令后，就会发送命令请求主服务器执行一次 PSYNC 增量更新，从而解决这个问题。 Redis 2.8 以前的复制功能不能高效地处理断线后重复制情况， 但 Redis 2.8 新添加的部分重同步功能可以解决这个问题。 部分重同步通过复制偏移量、复制积压缓冲区、服务器运行 ID 三个部分来实现。服务器 ID 主要是让从服务器确认主服务器是不是之前的那个。 在复制操作刚开始的时候， 从服务器会成为主服务器的客户端， 并通过向主服务器发送命令请求来执行复制步骤， 而在复制操作的后期， 主从服务器会互相成为对方的客户端。 主服务器通过向从服务器传播命令来更新从服务器的状态， 保持主从服务器一致， 而从服务器则通过向主服务器发送命令来进行心跳检测， 以及命令丢失检测。 若想让一台服务器成为从服务器，只需要在配置文件中加入： # 假设 192.168.88.111 为主节点ip，6379为端口 slaveof 192.168.88.111 6379 然后以该配置文件启动 redis 即可：redis-server redis.conf 哨兵 Sentinel一致性与共识就是经典的 Raft 算法了，不过 redis 做到巧妙的一点是，每个 Sentinel 都订阅同一个频道，它们会以每两秒一次的频率， 通过该频道发送消息来向其他 Sentinel 宣告自己的存在，这就使得每个 Sentinel 不必互相见面就能知道彼此的存在。 启动一个 Sentinel 需要在配置文件加上： # sentinel monitor [master-group-name] [ip] [port] [quorum] # 该行的意思是：监控的master的名字叫做mymaster （可以自定义），地址为192.168.88.111:6379 # 行尾最后的一个2代表在sentinel集群中，多少个sentinel认为master死了，才能真正认为该master不可用了。 sentinel monitor my_master 192.168.88.111 6379 2 可以使用命令启动： $ redis-sentinel redis.conf 或者命令： $ redis-server redis.conf --sentinel 这两个命令的效果完全相同。 当一个 Sentinel 启动时， 它需要执行以下步骤： 初始化服务器。 将普通 Redis 服务器使用的代码替换成 Sentinel 专用代码。 初始化 Sentinel 状态。 根据给定的配置文件， 初始化 Sentinel 的监视主服务器列表。 创建连向主服务器的网络连接。 Sentinel 只是一个运行在特殊模式下的 Redis 服务器， 它使用了和普通模式不同的命令表， 所以 Sentinel 模式能够使用的命令和普通 Redis 服务器能够使用的命令不同。 Sentinel 会读入用户指定的配置文件， 为每个要被监视的主服务器创建相应的实例结构， 并创建连向主服务器的命令连接和订阅连接， 其中命令连接用于向主服务器发送命令请求， 而订阅连接则用于接收指定频道的消息。 Sentinel 通过向主服务器发送 INFO 命令来获得主服务器属下所有从服务器的地址信息， 并为这些从服务器创建相应的实例结构， 以及连向这些从服务器的命令连接和订阅连接。 在一般情况下， Sentinel 以每十秒一次的频率向被监视的主服务器和从服务器发送 INFO 命令， 当主服务器处于下线状态， 或者 Sentinel 正在对主服务器进行故障转移操作时， Sentinel 向从服务器发送 INFO 命令的频率会改为每秒一次。 对于监视同一个主服务器和从服务器的多个 Sentinel 来说， 它们会以每两秒一次的频率， 通过向被监视服务器的 __sentinel__:hello频道发送消息来向其他 Sentinel 宣告自己的存在。 每个 Sentinel 也会从 __sentinel__:hello 频道中接收其他 Sentinel 发来的信息， 并根据这些信息为其他 Sentinel 创建相应的实例结构， 以及命令连接。 Sentinel 只会与主服务器和从服务器创建命令连接和订阅连接， Sentinel 与 Sentinel 之间则只创建命令连接。 Sentinel 以每秒一次的频率向实例（包括主服务器、从服务器、其他 Sentinel）发送 PING 命令， 并根据实例对 PING 命令的回复来判断实例是否在线： 当一个实例在指定的时长中连续向 Sentinel 发送无效回复时， Sentinel 会将这个实例判断为主观下线。 当 Sentinel 将一个主服务器判断为主观下线时， 它会向同样监视这个主服务器的其他 Sentinel 进行询问， 看它们是否同意这个主服务器已经进入主观下线状态。 当 Sentinel 收集到足够多的主观下线投票之后， 它会将主服务器判断为客观下线， 并发起一次针对主服务器的故障转移操作。 让我们来考虑具体的细节，当哨兵进行选举之前，必须要选举出一个领头哨兵进行选举，在 Redis 的实现中，它默认任何一个哨兵都能够进行故障转移，于是最先发现主节点宕机的哨兵将自己的纪元加一，并且询问其他哨兵，其他哨兵检查主节点是否下线，如果确实下线并且当前纪元小于对方纪元（或者是等于但没投票），这个时候会投票给对方，并且更新纪元为对方纪元，只有一个节点收到了半数以上的节点的赞成，它才会成为领头节点。 这个其实就是 Raft 算法，每个节点在一个纪元内只会投一票，并且只有半数以上的节点投赞成票才会成功，这就会使得任意一个纪元内只能有一个领头，从而保障安全性，如果一时间没有协商出来，那么哨兵会间隔一段时间重新自增纪元发起投票。 领头哨兵选举出来后，接下来就是选举从节点了，这首先哨兵会过滤掉长时间没有和主服务器通信的节点，然后按照一定的排序规则：用户设定优先级、从节点复制偏移、RUN ID 选举一个最优的节点，然后执行 SLEAVEOF NO ONE 命令让其成为主节点，随后就是广播告知。 集群一个 Redis 集群通常由多个节点（node）组成， 在刚开始的时候， 每个节点都是相互独立的， 它们都处于一个只包含自己的集群当中， 要组建一个真正可工作的集群， 我们必须将各个独立的节点连接起来， 构成一个包含多个节点的集群。 连接各个节点的工作可以使用 CLUSTER MEET 命令来完成， 该命令的格式如下： CLUSTER MEET &lt;ip&gt; &lt;port&gt; 向一个节点 node 发送 CLUSTER MEET 命令， 可以让 node 节点与 ip 和 port 所指定的节点进行握手（handshake）， 当握手成功时， node节点就会将 ip 和 port 所指定的节点添加到 node 节点当前所在的集群中。 不过，如果想要进入集群模式，还必须要将配置中的 cluster-enabled 选项配置为 true。 节点通过握手来将其他节点添加到自己所处的集群当中。 集群中的 16384 个槽可以分别指派给集群中的各个节点， 每个节点都会记录哪些槽指派给了自己， 而哪些槽又被指派给了其他节点。槽位是针对数据库中的所有的 key 而言的，redis 会将所有的 key 尽可能均匀映射到 0 ~ 16384，用户请求相关key时，会根据key的槽位选择对应的节点。槽位信息必须在集群中传播，节点可以通过 bitset 来快速查看相关槽位是否是自己负责的。 节点在接到一个命令请求时， 会先检查这个命令请求要处理的键所在的槽是否由自己负责， 如果不是的话， 节点将向客户端返回一个MOVED 错误， MOVED 错误携带的信息可以指引客户端转向至正在负责相关槽的节点，客户端会自动完成重定向，这对用户是不可见的。 对 Redis 集群的重新分片工作是由客户端执行的， 重新分片的关键是将属于某个槽的所有键值对从一个节点转移至另一个节点。 如果节点 A 正在迁移槽 i 至节点 B ， 那么当节点 A 没能在自己的数据库中找到命令指定的数据库键时， 节点 A 会向客户端返回一个 ASK 错误， 指引客户端到节点 B 继续查找指定的数据库键。 单个 Key 的迁移操作是原子的，在迁移过程中，会堵塞客户端的访问。 MOVED 错误表示槽的负责权已经从一个节点转移到了另一个节点， 而 ASK 错误只是两个节点在迁移槽的过程中使用的一种临时措施。 集群里的从节点用于复制主节点， 并在主节点下线时， 代替主节点继续处理命令请求。 集群中的节点通过发送和接收消息来进行通讯， 常见的消息包括 MEET 、 PING 、 PONG 、 PUBLISH 、 FAIL 五种。 集群中的通信是采用 Gossip 协议（流行病协议）进行通信的，这个通信协议并不是实时传输的，而是具有一定的滞后性，但优点是即使集群非常多，每个节点仍然只需要和固定的几个节点打交道就行了，减少了节点的压力。 这个协议具体的工作原理就像传染病一样，不停的传播消息，节点没必要向其他所有节点传播，而是根据一定的规则选取一些节点进行传播，而这些节点按照同样的方式进行传播（就像病毒一样感染），一段时间后集群中任意一个节点都会被感染，这样所有节点都能维护一张集群中的槽指派表 每个节点每隔一定周期时都会向周围节点发送 PING、PUBLISH 等命令广播消息，集群中允许主节点向从节点进行复制，并且集群中有着自动的故障转移机制，这和哨兵机制有所不同。 当一个节点向周围节点发送 PING 消息却 PING 不通时，节点就会认为该节点疑是下线，然后就在集群中依赖 Gossip 传递消息，每个节点都记录下“谁认为谁疑是下线”，并且一旦有半数以上的主节点都认为某个节点疑是下线，就会在集群中广播该节点客观下线的实时，并且集群纪元配置加一。 一旦从节点收到自己主节点下线的通知，这里每个从节点都会自己发起选举，这和哨兵机制有很大的不同，集群中是一种毛遂自荐的方式，每个从节点都向主节点（携带纪元配置）发送投票请求，如果从节点纪元不小于当前节点并且主节点没投过票，则可以投给从节点。 一旦一个节点收到半数以上（所以只会有一个节点胜出）的投票时，它将成为主节点，否则，将间隔一段时间重新开始。 这里的问题是，如何选取最优的从节点呢？事实上集群并不能保障全局出来的从节点是最优的，但是集群仍然会尽力的去保证，它有如下机制：从节点检测到主节点下线时，会间隔一段时间后才会发起选举，而间隔时间是通过一定算法生成的，优先级越低（参考哨兵机制）的间隔时间越长。 当主节点重新上线时，由于主节点纪元低于其他节点，其他节点不会接受该节点的请求，而当主节点收到其他节点传播的消息时，发现已经有新主节点了，并且自己的确已经“落伍”（纪元配置低于集群中纪元配置），于是更新纪元配置，心甘情愿成为从节点。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"Redis 高可用","slug":"Redis 高可用","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.984Z","comments":true,"path":"post/2e4c.html","link":"","permalink":"http://example.com/post/2e4c.html","excerpt":"","text":"Redis 高可用Redis Sentinel概述Redis sentinel 是 redis 的高可用解决方案，在redis2.8之后的版本正式生产可用。Redis sentinel通过引入sentinel节点（也是一个redis进程）集合来对redis的数据节点集合进行监控，发现故障节点并自动进行故障转移，从而提高生产环境下redis的高可用性。 解决问题常规的redis主从复制结构模式下，主节点可以将数据同步给从节点，这样做的原因是：一旦主节点发生了故障，从节点可以直接作为后备顶替上来成为新的主节点，并尽最大努力保证数据不丢失（由于主从复制之间有一定的时延，只能保证最终一致性）。 为了实现这一点，需要运维人员实时地去监控主节点的状态，通常情况下是很难及时地发现主节点的异常状态。并且，一旦发现主节点发生了故障，还需要运维人员手动的去进行故障转移，故障转移的实时性和准确性上都无法保障。以下为人工干预进行故障转移所需要的步骤： 检测到某个主节点发生故障，客户端连接主节点失败，从节点与主节点间的复制失败。 选择一个从节点，执行 slave of no one，使其成为主节点。 通知应用方，使其重新初始化客户端，连接新晋主节点。 对其他从节点执行 salve of new master，让这些从节点去复制新晋主节点的数据。 监控之前的主机点，待其恢复后，执行 slave of new master，让其成为新晋主节点的从节点，并开始执行复制操作。 高可用性从上图中可以看出手动进行故障转移需要运维人员手动执行一系列繁琐的操作，为了能够自动实现故障发现和故障转移，从而实现真正的高可用，redis 给出了 redis sentinel 的解决方案。 redis sentinel 通过引入一系列 redis sentinel 节点来对 redis 数据节点进行监控，当某个 sentinel 节点发现数据节点出现故障时，会对数据节点做主观下线操作，如果主观下线的是主节点，这个 sentinel 节点还会和 redis sentinel 节点集合中的其它 sentinel 节点进行协商，当大多数的 sentinel 节点认为某个节点发生了故障，会判定这个数据节点为客观下线，并继续协商投票选出一个 sentinel 节点来负责对故障节点进行故障转移的工作，这个过程都是自动化完成，实现了真正的高可用性。 从图中的拓扑结构上看，sentinel 节点集合会定时对所有的数据节点进行监控，当发生故障，会自动进行恢复。 Redis sentinel 仅仅是在普通的 redis 主从复制模式增加了一系列的 sentinel 节点，用于监控主从模式中的 redis 数据节点，并没有对redis 的数据节点进行额外的处理。 实现原理三个定时任务 每隔10s，sentinel 会向主节点和从节点发送info命令来获取最新的数据节点拓扑结构，用于及时感知节点之间的变化。就是因为有了这个定时任务，在配置 redis sentinel 节点的时候就只需要配置主节点的信息，从节点的信息可以由这个定时任务获取到。 每隔2s，sentinel 节点会向 sentinel:hello 频道发送自身的 sentinel 信息以及对主节点的故障判断，sentinel 节点集合中的所有节点都会订阅这个频道。当有新的 sentinel 节点加入进来时，通过订阅这个频道，各个 sentinel 节点可以及时的获取到新加入的 sentinel 节点信息，sentinel 之间会创建一条命令连接用以通信。 每隔1s，每个 sentinel 节点会向主节点、从节点和其它的 sentinel 节点发送 ping 命令做心跳检测，来确认这些节点是否可达，如果节点不可达，则标记节点下线。这个定时任务是判断节点故障的重要依据。 主观下线和客观下线 主观下线：利用第三个定时任务，可以对所有节点进行故障检测。当 sentinel 向其它节点发送 ping 后，超过参数down-after-millliseconds配置的时间后仍没有收到有效的回复，就会判定这个节点为故障的，并标记这个节点下线，这个行为就叫做主观下线。主观下线是某一个sentinel节点对另外的节点的主观方面的故障判断，存在误判的可能性，因此不能作为节点实际下线的判断依据。 客观下线：正如之前所说，主观下线存在误判的可能性，所有需要多个sentinel节点共同参与商讨对某个节点的下线判断，从而确定该节点是否真的处于不可达的状态。具体操作是：sentinel节点会向其它sentinel节点发送命令is-master-down-by-addr询问其他节点对主节点的故障判断，只有当达到quorum个sentinel节点对主节点做出故障判断时，才会执行对主节点的客观下线。 down-after-millisecondes：该参数可以在redis sentinel节点启动配置文件中设置。这个参数设置得越大，则误判节点故障的概率就越小，但这也意味着故障转移的操作延后了，降低了对故障节点的反应速度。反之，该参数设置得越小，虽然提高了对故障节点的反应速度，但是对故障判断的错误率也随之升高。 quorum：该参数也是在sentinel节点启动配置文件中设置的，可用于客观下线的判断和sentinel领导者的选举。如果该参数设置得太小，则客观下线的条件就越宽松，反之越严格。 is-master-down-by-addr：这个命令除了可以用于交换sentinel节点之间对主节点的主观下线判断，还可以用于sentinel领导者的选举，不同的行为由不同的参数决定。 Sentinel领导者选举当sentienl节点对主节点做出了客观下线的判断后，不会立即执行故障转移的操作，此时sentinel节点结合会选举出一个领导者，由该领导者sentinel节点来执行后续的故障转移。Redis使用了Raft算法来选举领导者，这里介绍整个选举的流程。 只有没有标记为主观下线的 sentinel 节点才有资格成为候选人。sentinel 节点通过向其它sentinel节点发送is-master-down-by-addr命令寻求对方将选票投个自己，每次发起选举，sentinel 的配置纪元都会自增。 收到命令的 sentinel 节点会判断对方纪元是否高于自身，如果高于则更新自身纪元，并投票给对方（先来先得），一旦投票之后，同一纪元内无法投第二次选票。如果对方纪元低于自身，则不会投票给对方，并且会告知对方自己赞成的领头人。 此时如果sentinel节点发现自己获得的选票达到 $max(quorum, num(sentinels)&#x2F;2)$，那么它将成为领导，由于每轮选举每个sentinel 节点都只有一张票，因此只有人拿到半数以上的票数，其它人就不可能拿到半数以上的票。 如果本轮投票没有选出领导者，开启下一轮选举。 为了达到半票以上，sentinel节点的个数至少为3个，并且为了最小化部署，通常选择sentinel节点的个数为奇数 故障转移这里介绍一些sentinel进行故障转移中的细节，整个流程见下图。 sentinel会从过滤掉不健康的候选从节点，包括主观下线、5s 没有回复sentinel节点ping响应、与主节点失联超过 down-after-milliseconds * 10 秒的节点 选择从节点优先级最高的从节点，如果存在直接返回 选择复制偏移量最大的从节点，复制偏移量代表了主从同步的完整度 选择run id最小的从节点 部署Redis sentinel 节点和普通的数据节点的启动并没有什么不同，都是读取配置文件，然后运行redis server，它们之间的区别在于配置文件内容。这里简单介绍如何搭建图2-2的redis sentinel服务。 启动主节点 # redis-6379.conf port 6379 # 端口号 daemonize yes # 守护进程运行 logfile \"6379.log\" # 日志名 dbfilename \"dump-6379.rdb\" # 持久化文件名 dir \"/opt/redis/data\" # 工作目录，存放rdb文件 启动两个从节点 # redis-6380.conf port 6380 # 端口号 daemonize yes # 守护进程运行 logfile \"6380.log\" # 日志名 dbfilename \"dump-6380.rdb\" # 持久化文件名 dir \"/opt/redis/data\" # 工作目录，存放rdb文件 slaveof 127.0.0.1 6379 # 作为6379的从节点 # redis-6381.conf port 6381 # 端口号 daemonize yes # 守护进程运行 logfile \"6381.log\" # 日志名 dbfilename \"dump-6381.rdb\" # 持久化文件名 dir \"/opt/redis/data\" # 工作目录，存放rdb文件 slaveof 127.0.0.1 6379 # 作为6379的从节点 部署sentinel节点， # redis-sentinel-26379.conf port 26379 # 端口号 daemonize yes # 守护进程运行 logfile \"26379.log\" # 日志名 dir \"/opt/redis/data\" # 工作目录，存放rdb文件 sentinel monitor master 127.0.0.1 6379 2 # 监控127.0.0.1:6379的主节点，名字为master，quorum为2 sentinel down-after-milliseconds master 30000 # 设置下线时间为30s sentinel parallel-syncs master 1 # 设置故障转移后同时进行复制新主节点的从节点的个数 sentinel failover-timeout master 180000 # 设置故障转移超时时间为180s # redis-sentinel-26380.conf port 26380 ... # redis-sentinel-26381.conf port 26381 ... Redis Cluster概述Redis Cluster是Redis官方的分布式解决方案，在redis3.0之后生产环境正式可用。在实现了高可用的同时，分布式的架构极大扩展了redis的存储、读写能力。由于redis cluster所涉及的内容太多，本文只会对redis cluster中的节点通信、集群伸缩和故障转移进行介绍，其它部分包括集群搭建、请求路由、集群运维等内容可以参考《Redis开发与运维》一书。 解决问题 单集群主节点的写能力受到限制，传统主从模式和redis sentinel无法提升写性能。 单集群主节点的存储能力受到限制。 拓扑结构从中可以看出 redis cluster 采用的是去中心化的分布式架构，它们之间通过不断的交换信息来获取集群整体的状态（图中集群的从节点也参与信息交换，为简化结构，忽略它们之间的连线)。其中redis cluster中的节点也区分主从，从节点负责处理当主节点出现故障时的自动故障转移，默认情况下从节点不支持任何的读写操作，仅作为主节点的一个“热备”存在。 注意：在Redis cluster模式下，成为从节点的salveof命令将会失效，应使用cluster replication命令 数据分区分布式数据库首先要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整体数据的一个子集。redis 使用虚拟槽的分区规则。其主要思想就是每个节点负责一部分虚拟槽，而数据经过哈希计算后直接映射到对应的槽上，每个槽又维护着一定量的数据。Redis cluster使用的槽范围为0～16383，共计16384个槽。数据到槽的映射可以通过 $hash(key)&amp;16383$ 的方式进行计算。 相较于哈希取余、一致性哈希等自动映射节点的算法，Redis 将这种主动权交由运维人员管理，可由运维人员手动将某些槽位分配给一些节点。 redis cluster是去中心化的分布式架构，它们之间通过gossip进行通信，因此每个redis节点都保存集群中其他节点的槽信息。 节点间通信在分布式存储中需要提供维护节点元数据信息的机制，所谓元数据是指：节点负责哪些数据，是否出现故障等状态信息。常见的元数据维护方式分为：集中式和P2P方式。Redis集群采用P2P的Gossip协议（是一种去中心化的协议），Gossip协议工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息，这种方式类似流言传播。 Gossip协议Gossip协议的主要职责就是信息交换。信息交换的载体就是节点彼此发送的Gossip消息。常用的Gossip消息可分为：ping消息、pong消息、meet消息、fail消息等。 ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其他节点（不是全部）发送ping消息，用于检测节点是否在线和交换彼此状态信息，ping消息中封装了自身节点和部分其他节点的状态数据。 meet消息：用于通知新节点加入。发送该消息的节点通知接收节点自己要加入到当前集群，meet消息通信正常完成后，接收节点会加入到集群中并进行周期性的ping、pong消息交换，从而把自己的加入到集群的信息传播到整个集群。 pong消息：当接收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息内部也封装了自身状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新。 fail消息：当节点判定集群内另一个节点客观下线时，会向集群内广播一个fail消息，其他节点接收到fail消息之后把对应节点更新为客观下线状态，从节点收到fail消息会执行自动故障转移。 通信节点选择虽然Gossip协议的信息交换机制具有天然的分布式特性，但它是有成本的。由于内部需要频繁地进行节点信息交换，而ping&#x2F;pong消息会携带当前节点和部分其他节点的状态数据，势必会加重带宽和计算的负担。 Redis集群内节点通信采用固定频率，因此节点每次选择需要通信的节点列表变得非常重要。通信节点选择过多虽然可以做到信息及时交换但成本过高，节点选择过少会降低集群内所有节点彼此信息交换频率，从而影响故障判定、新节点发现等需求的速度。因此Redis集群的Gossip协议需要兼顾信息交换实时性和成本开销，通信节点选择的规则如图所示。从图中可以得出每个节点每秒会向 1+10*num (最后通信时间 &gt; node_timeout&#x2F;2) 个节点发送 ping 消息来告知自身和其它部分节点的信息。 当集群规模不断增大时，集群间会产生大量的gossip消息，这限制cluster集群的大小。 集群扩缩容Redis cluster提供了灵活的集群扩缩容方案，主要得益于redis抽象了虚拟槽这一存储单元，集群的扩缩容的底层操作实际上就是虚拟槽在各个redis节点之间的移动，如图所示。 扩容集群扩容集群分为一下几步： 准备新节点，为了高可用，至少准备两个节点，启动这两个redis-server，新启动的节点作为孤儿节点运行，没有与任何节点通信。 加入集群，新节点向集群中任意节点发送meet消息，请求加入到节点，集群中节点收到消息后回复pong消息，并在与集群中其它节点正常的ping&#x2F;pong通信时将新节点的信息传播到整个集群。 执行槽迁移，给其中一个节点分配槽，并开始执行节点与节点之间的槽中数据的迁移。 执行cluster replication命令，使新节点中的其中一个成为另一个具有槽的节点的从节点。 收缩集群收缩集群的操作与扩容集群相反： 如果需要将主从节点一起下线，需要先下线从节点，否则主节点下线后从节点会被分配给从节点最少的主节点并执行复制操作，增加了额外的带宽压力。 下线主节点，将槽迁移至集群中的其它的节点。 对集群中其它的节点执行cluster forget命令来忘记下线节点，忘记节点后，节点就不会向下线节点发送gossip消息。 停止下线节点进程。 故障转移故障发现redis cluster中的ping&#x2F;pong消息除了进行节点间信息交流，还可以检测节点是否可达。 主观下线：集群中每个节点都会定期地向其它节点发送ping消息告诉自身节点和保存的其它节点的信息，收到消息的节点也会回复pong信息来告诉对方自己的节点和保存的其它节点的信息。如果在配置 cluster-node-timeout 时间一直没收到pong信息，则会认为这个节点存在故障，标识这个节点为主观下线（pfail）并保存在本地。 客观下线：当某个节点判断另一个节点主观下线后，后续的ping消息会将这个主观下线判断传播到集群中的其它节点，其它节点收到这个主观下线报告后，会维护一个链表记录下线节点的报告者，并尝试进行客观下线。当这个下线节点链表中的报告者的数量大于num(nodes)&#x2F;2 + 1时，执行客观下线（fail），并向集群中广播fail信息。 这个流程见图: 这里进行决策的节点都是带有槽的主节点，不带有槽的节点和从节点不参与客观下线的决策。 故障恢复故障节点被标志为客观下线后，为了保证系统的高可用，必须从从节点中选出一个成为新的主节点。从节点的内部定时任务发现其主节点被标志为客观下线后，将会触发故障恢复流程： 资格检查：每个从节点都要检查最后与主节点断线时间，判断是否有资格替换故障的主节点。如果断线时间过长，不会发起投票选举。 准备选举延迟时间：当从节点符合故障转移资格后，更新触发故障选举的时间，只有到达该时间后才能执行后续流程。从节点根据自身复制偏移量设置延迟选举时间，保证复制延迟低的从节点优先发起选举。 发起选举：递增全局配置epoch，并赋值给从节点本地epoch，并广播选举消息。 选举投票：每个具有槽的主节点在每个epoch内有一张选票，在收到从节点的选举消息后，如果选票还在，就会投出这一票。当从节点收到的票数达到N&#x2F;2+1，从节点就可以执行替换主节点的操作，其中N为具有槽的主节点个数。为了能够达到选举票数，必须保证N大于等于3。如果在一个epoch内从节点没有获取到足够的选票，会更新epoch，并发起下一轮投票。 替换主节点：取消复制主节点，接管主节点的槽并广播pong消息通知集群当前节点以晋升为主节点并接管了原主节点的槽。 epoch的作用： 全局配置epoch用于标志当前的选举的轮数，只有在同一个epoch中的选票才会进行统计。 另外，当选举完成后，新的主节点的本地epoch会设为当前的全局配置epoch，因此全局配置epoch也表示当前集群的最新版本。 具有更大的本地epoch的主节点具有跟高的优先级，当故障主节点恢复后，由于已经进行了故障转移，新的主节点和老的主节点具有同样的虚拟槽，当虚拟槽信息在集群中传播时，以节点本地opoch最大的主节点为准。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"Raft 算法","slug":"Raft 算法","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.984Z","comments":true,"path":"post/a67a.html","link":"","permalink":"http://example.com/post/a67a.html","excerpt":"","text":"Raft 算法Raft 算法将一致性问题分解为 Leader 选举、日志同步、成员变更 等一系列子问题，Raft 算法相较于 Paxos 算法理解起来更加通俗易懂。 Raft 算法将节点分为三种角色： Leader、领导者：负责接受客户端的写请求，并将请求日志同步给 Follower 追随者，当大多数 Follower 成功同步后，则允许 Follower 提交日志。 Follower、追随者：允许接受读请求，负责接受 Leader 的同步日志，在 Leader 告知日志可以提交后，提交日志。 Candidate、候选者：当检查到 Leader 下线时发起 Leader 选举竞选 Leader。 Leader 选举动画演示：Raft Consensus Algorithm Raft 算法保证任一任期内只能有一个领导者，领导者是 Follower 一致选举出来的。 作为 Leader，除了同步请求日志之外，还必须要周期性的向所有 Follower 发送心跳包，每个 Follower 都维护者一个定时器（超时时间是随机的），一旦指定时间内未收到 Leader 的心跳包，则认为 Leader 故障下线，Follower 作为 Candidate 发起选举竞选 Leader： Candidate 任期自增，首先投票给自己，然后发送投票信息给其他所有节点。 节点收到投票信息后，取出投票信息中 Candidate 最新的日志，日志条目由 任期 + 编号 组成，节点会将 Candidate 最新的日志与自身最新的日志进行对比，如果 Candidate 日志没有自己的新，则投反对篇，比较的规则是先比较任期，任期相同再比较编号。 如果 Candidate 的日志确实新与自身，则比较 Candidate 任期和自身任期，只有当 Candidate 的任期大于自身，节点才会投赞成票，并将自身任期更改为 Candidate 的任期。 当 Candidate 收到超过一半节点数目的赞成票后，Candidate 晋升为 Leader，开始定时发送心跳包。 在任意时刻，一旦节点收到来自 任期大于等于自身 的 Leader 的心跳包，节点将成为该 Leader 的 Follower，并更新自身的任期为 Leader 的任期，同时刷新超时计时器。 要注意即使节点成为 Candidate，节点依然会维护超时计时器以期望收到 Leader 的消息，如果超时，将继续自增任期重复上述步骤。 在上述流程中，由于每个节点一旦投赞成票就会更改任期追随 Candiate，一旦任期更改，节点无法继续投给 Candidate 赞成票，所以隐含的规则是： 任意节点只能投给任意一个任期 Candidate 一票。 又因为对于任意一个 Candidate 而言，要想成为 Leader，就必须要有半数以上的赞成票，所以这两个规则保证了：任意一个任期内，只会有一个 Leader。 任期是为了防止 脑裂 的情况发生：某个 Leader 由于网络原因被隔绝，此时重新竞选 Leader，而后网络又恢复，这样就会存在多个 Leader。有了任期的概念，这个问题很好解决：只服务任期等于自己的 Leader，一旦收到任期大于自身的 Leader 的消息，节点会更新任期追随此 Leader（旧 Leader 就会成为 Follower 追随新 Leader）。 在上述流程中，第二点比较日志的新旧其实是为了防止这样一种情况发生：某个节点由于网络问题被隔绝，于是它收不到任何消息，将会不断自增任期并发起选举，于是此节点的任期将会非常大，但是数据可能是陈旧的，此节点上的日志的任期会非常小。 所以 Raft 算法将日志新旧也作为投票的规范，这意味着一个 Leader 中的数据至少等于或新于大多数节点的数据。 但是仍然有两个棘手的问题： 候选人由于网络问题脱离集群，于是它自身的 term 可能会变得无限大，当他重新加入集群时，虽然由于要比较日志新旧，候选人无法竞选成功，但候选人的任期非常大，它会拒绝 Leader 的心跳，从而造成 即使候选人回到集群中，也无法正常工作的情况。 对称分区问题，例如 ABC 三个节点，由于网络问题，AC 能通信、BC 也能通信，但 AB 断联，某一时刻假设 A 为领导，但是 B 收不到领导的节点，于是 B 会竞选 Leader，假设日志都是一样的新旧，于是 B 能竞选成功，此时 A…..重复循环…… 上述这两个问题都可以通过 preVote 解决，即在自增任期时，首先发起 preVote，只有多数节点同意才能自增任期参与正式竞选，其他节点赞成的要求是： 自身也没有收到领导人的心跳。 对方的日志比自己的新（或一致）。 由于其他节点一直稳定收到领导人心跳，因此 preVote 不会通过。但是 preVote 会引入额外的网络开销，这种开销不容忽视。 日志同步Leader 将客户端的请求作为日志条目加入到它的日志中，日志由有序编号的日志条目组成，每个日志条目都包含对应的任期。 Leader 会向所有 Follower 发起 RPC 广播日志条目，但为了保证一致性，只有当多数 Follower 回复 RPC 成功后，Leader 才会发起 commit 让 Follower 提交日志。 由于 Leader 崩溃，Follower 上的日志可能多于新 Leader 也可能少于新 Leader，这完全取决于 多数节点的状态，为保证一致性，Raft 算法一切以 Leader 为准，即 Leader 的日志可以覆盖 Follower 上的日志，这意味着最新的日志信息是可能被丢失的。 具体的做法： 发送日志条目时，Leader 还会附加上这条日志条目的上一个日志条目的编号 prevIndex 和任期号 prevTerm，当 Follower 收到 RPC 信息时，它会检查本地日志中编号为 prevIndex 的日志条目任期是否为 prevTerm，如果相同，则将最新的信息覆盖在对应编号（prevIndex + 1）位置上。 如果不同，节点返回一个错误码，当 Leader 收到错误码时，Leader 从后往前开始同步每一条日志，直到某条日志同步成功，从这条日志开始同步的后续的日志。这就是 Leader 强制性覆盖 Follower 日志的一致性检查的过程。 上述流程第二点的一致性检查保证了如下规则成立： index 和 term 都相同的两个日志条目存储的命令一定是相同的。 这是因为按照一致性检查的要求，Follower 中的日志最终会和 Leader 中的日志保持一致性，而一个 Leader 任意任期内在同一 index 内最多只会产生一条条目。 通过这种方式 Raft 能够保证 Leader 和 Follower 的日志一致性。 日志压缩当新的 Follower 上线或者 Follower 丢失太多日志时，重放日志成本过高，因此 Raft 算法采用 Snapshot（快照）解决这个问题。 Snapshot 表示的是 Leader 的系统状态，日志是基于命令的，而 Snapshot 是 Leader 的系统状态，可以理解为数据，就好比 RDB 和 AOF 的区别，发送 Snapshot 使用 InstalledSnapshot RPC。 传输 Snapshot 会比传输日志命令快得多。 Leader 会不定期的对已提交的日志生成快照，快照包含如下内容： 最后的 log index 最后的 log term 数据 当 Follower 新上线或丢失过多消息时，Leader 会选择发送最新的 Snapshot 给 Follower，当 Follower 收到 Snapshot 时，如果当前日志旧与 Snapshot 中的最后的日志编号，那么 Follower 会全部替换 Snapshot 并丢弃所有日志；当然，Follower 的日志可能也会比 Snapshot 新，这种情况下只会丢弃 last index 之前的日志，并保留之后的日志。 在 Snapshot 同时，Leader 会并发的接受新消息，可以采用 Linux 自带的 CopyOnWrite 技术实现并发，利用 fork 函数在子进程内发送 Snapshot，而父进程继续接受新消息。 Follower 也需要不定期 Snapshot，因为 Follower 在未来的某一刻可能会成为 Leader。 节点再平衡成员变更可能会造成最终选举出现两个 Leader，例如有两个节点 A、B 正在同时竞选，此时 A 已经获得了多数节点的赞成，而就在这一时刻，新增两个节点，由于延迟问题，A 不知道新增两个节点，于是 A 仍然认为自己成为了 Leader，而 B 发现自增两个节点，于是发送投票给他们，这两个节点都投了 B，现在 B 成为了多数派，B 也将成为 Leader！ 如果我们严格控制每次新增或删除的节点数只有一个的话，那么我们是允许采用一般性的一致性解决方案，这意味着在上一次成员变更尚未完成的情况下，不允许接下来的成员变更。 因此我们可以按照一般化的方案解决： 同一时刻只允许一个节点变更，并且上一次变更未完成不允许下一次变更。 成员变更由 Leader 发起作为一条特殊的日志记录同步给 Follower。 当多数 Follower 确认后，成员变更成功，Leader 变更成员状态，同时 Leader 发送 commit 给 Follower。 Follower 变更成员状态。 这是基于一个简单的数学道理，设总节点数为 N： 如果 N 是奇数：$$多数节点数目 &#x3D; \\frac{N + 1}2 \\新增一个节点后多数节点数目 &#x3D; \\frac{N + 2}2$$这意味着如果 B 原本还差一个赞成票的话，即当前赞成票 $ P &#x3D; \\frac{N}2$，即使新增一个节点也无法让 B 得到多数赞成 $\\frac{N + 2}2$ 。 偶数同样分析。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"SPI 机制以及 jdbc 打破双亲委派","slug":"SPI 机制以及 jdbc 打破双亲委派","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.984Z","comments":true,"path":"post/913.html","link":"","permalink":"http://example.com/post/913.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记 SPI 机制以及 JDBC 打破双亲委派 本文基于 jdk 11 SPI 机制简介何为 SPI 机制？ SPI 在Java中的全称为 Service Provider Interface，是JDK内置的一种服务提供发现机制，是Java提供的一套用来被第三方实现或者扩展的API，它可以用来启用框架扩展和替换组件。 例如本文的中心 jdbc，我们可以使用统一的接口 Connection 去操控各种数据库，但你有没有想过，难道 jdk 真的内置了所有的数据库驱动吗？ 显然这是不可能的，我们平时使用需要我们自己导入对应 jar 包去使用不同的数据库，例如 MySQL、SqlServer 数据库等。可是，我们使用的Connection conn = DriverManager.getConnection(url,user,pass) 又是确确实实是 jdk 内置的一个接口，其实这就是一种 SPI 机制，即官方定义好一个接口，由不同的第三方服务者去实现这个接口。 那么问题来了，SPI 机制是如何实现的呢？ 答案很简单，遵守官方的约定！ jdk SPI 原理SPI 可以有不同实现，但无论怎样核心思想都是遵守官方规则。官方不一定要是 jdk，例如 SpringBoot 就定义了一套规则，但我们这里仍然讲 jdk 的实现原理。 实现 SPI 机制的关键点在于要知道接口的具体实现类是哪一个，这些实现类是第三方服务提供的，必须得有一种方法让 JVM 知道使用哪个实现类，因此官方定义了如下规则： 服务提供者的类必须要实现官方提供的接口（或继承一个类）。 将该具体实现类的全限定名放置在资源文件下 META-INF&#x2F;services&#x2F;${interfaceClassName} 文件中，其中 ${interfaceClassName} 是接口的全限定名。 如果扫描到多个具体实现类，jdk 会初始化所有的这些类。 这就是 jdk 的约定，既然要求服务者提供的类名放在 META-INF&#x2F;services&#x2F;${interfaceClassName} 文件下，那么官方肯定要去扫描这个文件，官方提供了一个实现：ServiceLoader.load 方法。 获取具体类实例的伪代码如下： ServiceLoader load = ServiceLoader.load(XXX.class); for (XXX x : load) &amp;#123; // o 就是我们要获取的实例，XXX 是一个官方定义的接口接口 System.out.println(x); &amp;#125; ServiceLoader.load 方法返回一个 ServiceLoader 实例，我们需要通过遍历其迭代器去获取所有可能的实例，核心代码就在迭代器中了。 我们来看看这个迭代器的源码，我们主要看 hasNext 方法，因为 next 方法本身依赖于 hasNext 方法： public Iterator&lt;S> iterator() &amp;#123; return new Iterator&lt;S>() &amp;#123; int index; @Override public boolean hasNext() &amp;#123; if (index &lt; instantiatedProviders.size()) return true; return lookupIterator1.hasNext(); &amp;#125; &amp;#125;; &amp;#125; 跳到了 lookupIterator1.hasNext() 方法中，lookupIterator1 是调用 newLookupIterator() 方法返回的，来看看这个方法： private Iterator&lt;Provider&lt;S>> newLookupIterator() &amp;#123; Iterator&lt;Provider&lt;S>> first = new ModuleServicesLookupIterator&lt;>(); Iterator&lt;Provider&lt;S>> second = new LazyClassPathLookupIterator&lt;>(); return new Iterator&lt;Provider&lt;S>>() &amp;#123; @Override public boolean hasNext() &amp;#123; return (first.hasNext() || second.hasNext()); &amp;#125; @Override public Provider&lt;S> next() &amp;#123; if (first.hasNext()) &amp;#123; return first.next(); &amp;#125; else if (second.hasNext()) &amp;#123; return second.next(); &amp;#125; else &amp;#123; throw new NoSuchElementException(); &amp;#125; &amp;#125; &amp;#125;; &amp;#125; 可以发现主要有两种加载方式，一种是模块化的加载，另一种是普通的懒加载方式，我们应该会进到 second.hasNext() 方法： @Override public boolean hasNext() &amp;#123; if (acc == null) &amp;#123; return hasNextService(); &amp;#125; else &amp;#123; PrivilegedAction&lt;Boolean> action = new PrivilegedAction&lt;>() &amp;#123; public Boolean run() &amp;#123; return hasNextService(); &amp;#125; &amp;#125;; return AccessController.doPrivileged(action, acc); &amp;#125; &amp;#125; second.hasNext() 方法又调用了 hasNextService() 方法，来看看这个方法的逻辑： private boolean hasNextService() &amp;#123; while (nextProvider == null &amp;&amp; nextError == null) &amp;#123; try &amp;#123; Class&lt;?> clazz = nextProviderClass(); if (clazz == null) return false; if (service.isAssignableFrom(clazz)) &amp;#123; Class&lt;? extends S> type = (Class&lt;? extends S>) clazz; Constructor&lt;? extends S> ctor = (Constructor&lt;? extends S>)getConstructor(clazz); ProviderImpl&lt;S> p = new ProviderImpl&lt;S>(service, type, ctor, acc); nextProvider = (ProviderImpl&lt;T>) p; &amp;#125; &amp;#125; catch (ServiceConfigurationError e) &amp;#123; nextError = e; &amp;#125; &amp;#125; return true; &amp;#125; 这个方法首先判断 nextProvider 是不是空，如果不是的话说明已经有资源，直接返回；我们是初次加载，肯定为空，因此进入循环，可以看到主要的方法就是 nextProviderClass()，通过这个方法返回一个构造器，然后进行实包装，并设置 nextProvider 等于包装后的 ProviderImpl，有了 ProviderImpl，自然可以通过反射获取实例！ 这里核心方法应该是 nextProviderClass() ： static final String PREFIX = \"META-INF/services/\"; private Class&lt;?> nextProviderClass() &amp;#123; if (configs == null) &amp;#123; // 路径名 String fullName = PREFIX + service.getName(); // 根据路径名取得资源，这个 loader 是线程上下文取得的 configs = loader.getResources(fullName); &amp;#125; // pending 是一个 String 的迭代器 while ((pending == null) || !pending.hasNext()) &amp;#123; if (!configs.hasMoreElements()) &amp;#123; return null; &amp;#125; pending = parse(configs.nextElement()); &amp;#125; String cn = pending.next(); try &amp;#123; return Class.forName(cn, false, loader); &amp;#125; catch (ClassNotFoundException x) &amp;#123; return null; &amp;#125; &amp;#125; 可以看到在这一步通过 PREFIX + service.getName() 获取文件名，这个就是我们说的 META-INF/services/$&#123;interfaceClassName&#125; 约定的文件，然后取得对应资源，pending 是一个 String 的迭代器，其内就是具体实现类的全限定名，如果这个迭代器存在，说明已经解析过了，则直接返回 Class.forName(pending.next(), false, loader)。 如果 pending 迭代器到底了，那么会再一次进入循环，并调用 configs.nextElement() 再次读取，这也就是说明如果有多个配置文件，那么所有的类都会被加载！直到真的什么都没有了，那么抛出异常，返回 null，这里返回 null 的话，那么hashNext 方法就会返回 false。 如果是第一次解析，那么会进入到 pending = parse(configs.nextElement()); 方法，来看看这个方法： private Iterator&lt;String> parse(URL u) &amp;#123; Set&lt;String> names = new LinkedHashSet&lt;>(); // preserve insertion order URLConnection uc = u.openConnection(); uc.setUseCaches(false); try (InputStream in = uc.getInputStream(); BufferedReader r = new BufferedReader(new InputStreamReader(in, UTF_8.INSTANCE))) &amp;#123; int lc = 1; while ((lc = parseLine(u, r, lc, names)) >= 0); &amp;#125; return names.iterator(); &amp;#125; 这个方法很简单，就是读取配置中的每一行，添加到 Set 中，然后返回其迭代器。所以我们将返回一个配置文件中所有的全限定名！ 这就是 jdk 提供的 SPI 机制的具体实现原理！ 注：上述源码经过了些许简化 写一个 demo假如我们有一个 HelloPrinter 的接口，这个接口需要第三方来提供，则可以这样编写来获取具体实现类： public class Test &amp;#123; public static void main(String[] args) &amp;#123; ServiceLoader&lt;HelloPrinter> load = ServiceLoader.load(HelloPrinter.class); Iterator&lt;HelloPrinter> iterator = load.iterator(); while (iterator.hasNext()) &amp;#123; HelloPrinter helloPrinter = iterator.next(); helloPrinter.hello(); &amp;#125; &amp;#125; &amp;#125; 试问，这里有没有出现任何关于具体实现类的信息？没有！具体实现类对客户来说是完全透明的，客户只知道 HelloPrinter 这个接口！现在什么都没做，这个代码什么也不会输出。 然后我们启动另一个项目写两个实现类 HelloPrinterImpl1 和 HelloPrinterImpl2，按照约定建立如下目录： 在这个文件中填写实现者的全限定名: com.demo.HelloPrinterImpl1 com.demo.HelloPrinterImpl2 然后 maven 打包，让客户端引入这个 jar 包，重新运行，现在客户端的输出是： 我是第一个实现者！ 我是第二个实现者！ JDBC 打破双亲委派模型 本节前置知识：类加载机制 JDBC 其实也是一种 SPI 机制，例如当我们引入 MYSQL 驱动的 jar 包时： 可以发现这与我们上面讲的一模一样，由此可见我们使用的驱动应该是 “com.mysql.cj.jdbc.Driver” 这个类。 当引入了 jar 包之后，则可以通过代码： Connection connection = DriverManager.getConnection(\"jdbc:mysql://127.0.0.1:3306/xxx?serverTimezone=GMT\", \"root\", \"123456\"); 来获取数据库连接，Connection 是官方的接口，无论什么数据库都可以一样操作，非常方便。 但我们为什么说 jdbc 打破了双亲委派模型呢？ 原因在于 DriverManager.getConnection 方法其实是加载了 com.mysql.cj.jdbc.Driver 这个类，然后这个驱动去创建连接。 问题是 DriverManager 是属于 jdk 的官方类，应当是由引导类加载器（jdk8 以前叫启动类加载器）加载的，而 com.mysql.cj.jdbc.Driver 这个类明显不能由引导类加载器加载，而是由应用类加载器（也叫系统类加载器）加载。 public class Test &amp;#123; public static void main(String[] args) throws Exception &amp;#123; System.out.println(DriverManager.class.getClassLoader().getName()); Class c = Class.forName(\"com.mysql.cj.jdbc.Driver\"); System.out.println(c.getClassLoader().getName()); &amp;#125; &amp;#125; 输出是： platform app 可见确实是由平台类加载器和应用类加载器去加载这两个类，问题是 DriverManager 要如何加载 com.mysql.cj.jdbc.Driver 驱动，直接使用 Class.forName 可行吗？ 不可行！因为 Class.forName 默认会采用调用者自己的类加载器去加载，DriverManager 的类加载器是平台类加载器，显然加载不到驱动类。 所以 DriveManager 必须要使用次一级的类加载器去加载，这里是使用了 SPI 机制，在 getConnection 方法中，我们调用了一行代码： private static Connection getConnection( String url, java.util.Properties info, Class&lt;?> caller) throws SQLException &amp;#123; // 省略 ensureDriversInitialized(); // 省略 return driver.connect(url, info); &amp;#125; ensureDriversInitialized() 这个方法： private static void ensureDriversInitialized() &amp;#123; synchronized (lockForInitDrivers) &amp;#123; if (driversInitialized) &amp;#123; return; &amp;#125; String drivers; AccessController.doPrivileged(new PrivilegedAction&lt;Void>() &amp;#123; public Void run() &amp;#123; ServiceLoader&lt;Driver> loadedDrivers = ServiceLoader.load(Driver.class); Iterator&lt;Driver> driversIterator = loadedDrivers.iterator(); while (driversIterator.hasNext()) &amp;#123; driversIterator.next(); &amp;#125; return null; &amp;#125; &amp;#125;); driversInitialized = true; &amp;#125; &amp;#125; 可以看到在这个方法内调用了 loadedDrivers &#x3D; ServiceLoader.load(Driver.class) 方法，然后遍历迭代器，driversIterator.next() 相当于实例化了 Drive，别看它好像啥也没做，但事实上在实例化的过程中，触发了 Drive 类的初始化语句块的调用： public class Driver extends NonRegisteringDriver implements java.sql.Driver &amp;#123; public Driver() throws SQLException &amp;#123; &amp;#125; static &amp;#123; try &amp;#123; DriverManager.registerDriver(new Driver()); &amp;#125; catch (SQLException var1) &amp;#123; throw new RuntimeException(\"Can't register driver!\"); &amp;#125; &amp;#125; &amp;#125; 它向 DriverManager 注册了自己！因此 DriverManager 可以保存这个 Driver！ ServiceLoader 加载实现原理上面已经说了，但我故意没讲 ServiceLoader.load 方法： @CallerSensitive public static &lt;S> ServiceLoader&lt;S> load(Class&lt;S> service) &amp;#123; ClassLoader cl = Thread.currentThread().getContextClassLoader(); return new ServiceLoader&lt;>(Reflection.getCallerClass(), service, cl); &amp;#125; load 方法内，设置默认的加载器为线程上下文加载器，这个线程上下文类加载器在上一篇文章已经详细说了，就不再赘述了。 由于我们在主线程调用的 DriverManager.getConnection 方法，现在已经很明显了，ServiceLoader 使用了主线程的类加载器去加载，这当然是应用加载器！ 现在再来总结一下为什么说 jdbc 打破了双亲委派，我认为有两点： DriverManager 属于 jdk 官方类，使用平台加载器，然而却使用了应用加载器去加载 Driver 类，这相当于是高层次的类使用了低层次的类加载器，这算是逆向打通了双亲委派模型。 另外就是 ServiceLoader 使用线程上下文加载器直接获得类加载器，而没有一层一层向上调用，这肯定也是违反了双亲委派模型的。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"TCP详解","slug":"TCP详解","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.986Z","comments":true,"path":"post/2681.html","link":"","permalink":"http://example.com/post/2681.html","excerpt":"","text":"TCP详解简介传输控制协议（TCP，Transmission Control Protocol）是为了在不可靠的互联网络上提供可靠的端到端字节流而专门设计的一个传输协议。 互联网络与单个网络有很大的不同，因为互联网络的不同部分可能有截然不同的拓扑结构、带宽、延迟、数据包大小和其他参数。TCP的设计目标是能够动态地适应互联网络的这些特性，而且具备面对各种故障时的健壮性。 每台支持TCP的机器都有一个TCP传输实体。TCP实体可以是一个库过程、一个用户进程，或者内核的一部分。在所有这些情形下，它管理TCP流，以及与IP层之间的接口。TCP传输实体接受本地进程的用户数据流，将它们分割成不超过64KB（实际上去掉IP和TCP头，通常不超过1460数据字节）的分段，每个分段以单独的IP数据报形式发送。当包含TCP数据的数据报到达一台机器时，它们被递交给TCP传输实体，TCP传输实体重构出原始的字节流。为简化起见，我们有时候仅仅用“TCP”来代表TCP传输实体（一段软件）或者TCP协议（一组规则）。根据上下文语义你应该能很消楚地推断出其实际含义。例如，在“用户将数据交给TCP”这句话中，很显然这里指的是TCP传输实体。 IP层并不保证数据报一定被正确地递交到接收方，也不指示数据报的发送速度有多快。正是TCP负责既要足够快地发送数据报，以便使用网络容量，但又不能引起网络拥塞：而且，TCP超时后，要重传没有递交的数据报。即使被正确递交的数据报，也可能存在错序的问题，这也是TCP的责任，它必须把接收到的数据报重新装配成正确的顺序。简而言之，TCP必须提供可靠性的良好性能，这正是大多数用户所期望的而IP又没有提供的功能。 (源IP，源port，目的IP，目的port) 四元组唯一的标识了一个 TCP 连接，如果不考虑目的 ip 和 端口，在本机只有一个 IP 的情况下，一台主机最多只能有 65536 个 TCP 连接，如果考虑不同 IP 或是 目的地址的话，TCP 连接可以更多，但每一个网络 IO 都是一个特殊文件描述符，因此 TCP 连接数仍然限制于 文件描述符的最大数量与物理极限。 我们主要从 TCP 报文格式、滑动窗口协议、超时重传机制、拥塞控制机制、连接过程以及粘包丢包来分析TCP。 TCP报文格式 TCP报文前 20 字节是固定的，选项部分可选的可以补充一些数据，但不管怎么样，TCP 总长度被要求必须是 4 字节的整数倍，这意味着可能会填充0以对齐。 源端口与目的端口：各占 2 字节。 序列号码：4字节，序列号是循环使用的，TCP 中每一个字节对应与一个序列号，这里的序列号是该数据中第一个字节的序列号。 确认号：4字节，确认号指示 期望收到对方下一个报文段的第一个数据字节的序号，例如，当对方发送了 0 - 100 序列字节给你，此时你期望收到第 101 个序列字节，此时便可以设置 ACK &#x3D; 101。 数据偏移：4bit，这个字段指示数据的偏移位置，事实上它等价于 TCP 首部的总长度。数据偏移是基于**字(1 字 &#x3D; 4字节)**为单位的，数据偏移最大4 位，意味着 TCP 首部最大不允许超过 24-1字，即 15 字、60字节。 保留：3位，必须为 0。 标志位：9 位(旧版本只有 6 位，事实上重点也就是标黑的6位) NS。ECN显式拥塞通知（Explicit Congestion Notification）是对TCP的扩展，定义于RFC 3540（2003）。ECN允许拥塞控制的端对端通知而避免丢包。ECN为一项可选功能，如果底层网络设施支持，则可能被启用ECN的两个端点使用。在ECN成功协商的情况下，ECN感知路由器可以在IP头中设置一个标记来代替丢弃数据包，以标明阻塞即将发生。数据包的接收端回应发送端的表示，降低其传输速率，就如同在往常中检测到包丢失那样。 CWR—Congestion Window Reduced，定义于RFC 3168（2001）。 ECE—ECN-Echo有两种意思，取决于SYN标志的值，定义于RFC 3168（2001）。 URG—为1表示高优先级数据包，紧急指针字段有效。当该字段为 1 时，应用程序可以将紧急数据插入到数据字节流的最前方，以便接收方可以尽快的处理紧急数据。 ACK—为1表示确认号字段有效。 PSH—为1表示是带有PUSH标志的数据，指示接收方应该尽快将这个报文段交给应用层而不用等待缓冲区装满。 RST—为1表示出现严重差错。可能需要重新创建TCP连接。还可以用于拒绝非法的报文段和拒绝连接请求。 SYN—为1表示这是连接请求或是连接接受请求，用于创建连接和使顺序号同步。 FIN—为1表示发送方没有数据要传输了，要求释放连接。 窗口大小：2字节，以字节为单位，窗口大小是接收方告知发送方自己能缓存多大的数据，让发送方动态的调整发送数据的大小。 校验和：2字节，采用类似与 IP 校验一样的反码加检验，检验不是完全准确的，TCP只校验首部和头7字节数据。 紧急指针：2字节，当 URG 为 1 时，紧急指针有效，紧急指针指向紧急数据的最后一个字节，是紧急数据与普通数据的分界线。 流量控制 — 滑动窗口协议运作原理TCP 的发送是基于字节流的，在混乱的网络传输中，每一个字节可能被并不是按需到达的，后发送的完全有可能先到达，为了解决这个问题，TCP为每一个数据字节分配了一个序号，通过序号使得接收方能够有序的整理数据。 窗口通俗的来说就是缓存，发送方和接收方各自维护者自己的窗口，发送方需要将缓存中的数据发送出去，而接收方需要接收数据存储在缓存中，设置中断，等待应用程序读取。滑动窗口协议就是为了维护发送方发送速率和接收方处理速率的一致性，也就是所谓的流量控制，不至于说接收方只有 1 字节缓存的大小，而这个时候发送方还疯狂的发送 1460 字节，那么这个时候多余的 1459 字节就会丢失。 来看上面这个简单的窗口，由前沿指针与后沿指针确定了发送方 A 的发送窗口大小，A 只被允许发送 7 - 17 字节大小的字节，当 A 发送完了这 11 字节它必须要等待接收方 B 的 ACK 确认号与窗口大小才能继续调整 A 的发送窗口。 例如，当 A 发送 7 - 17 字节给 B 后，B 只收到了 7 - 10 字节，剩下的可能丢包了，B 期望接收 A 的第 11 字节，于是 B 将 ACK 字段设为 1，将 ACK 序列号设置为 11，同时 B 的缓存最多只能装下 9 字节了，于是 B 将 TCP 首部的窗口大小设置为 9，B 将 TCP 应答发送给 A。 A 收到后 B 的回送消息后，根据 B 的 TCP 应答去动态的调整窗口，此时窗口如上图所示，通过这样一个 ACK 确认机制，使得发送方发送速率始终与接收方接收速率一致，不会发生接收方缓存大小不够但发生方还猛发消息的情况。 前沿指针不允许收缩如果接收方窗口变小了怎么办？前沿指针可以收缩吗？例如在开始的例子里，如果 B 回送 ACK确认号 &#x3D; 11，窗口大小 &#x3D; 1 怎么办？ 要将前沿指针收缩为 12(开区间) 吗？ 前沿指针可以收缩，但 TCP 官方强烈不赞成这样做，因为这些数据很可能已经发送了，就像我们的例子中 12 - 17 字节数据已经发送给 B 了，这个时候如果还收获前沿指针就有点自相矛盾了，例如，如果 12 -17 字节仅仅只是在网络中多转了几圈，最终还是到达了 B，而恰好这个时候 B 的接收缓存又恢复了，能够收下这 5 字节，于是 B 回送 ACK &#x3D; 18 给 A，这就产生了一些错误(如果前沿指针回退的话)。 1 字节报文探测当接收方的窗口为 0 怎么办 —— 这个时候发送方会为这条 TCP 连接启动一个持续计时器，当计时器到期后，发生方就会发送一个 1 字节的 TCP 报文段询问，如果接收方调整过来了，则一切继续，否则，将会重新启动计时器继续探测。 当探测达到一定次数时，发送方会自动断开 TCP 连接。 糊涂窗口综合征糊涂窗口增综合症可以从发送方和接收方两个层面去解决。 发送端引起的糊涂窗口综合症如果发送端为产生数据很慢的应用程序服务(典型的有telnet应用)，例如，一次产生一个字节。这个应用程序一次将一个字节的数据写入发送端的TCP的缓存。如果发送端的TCP没有特定的指令，它就产生只包括一个字节数据的报文段。结果有很多41字节的IP数据报就在互连网中传来传去，这样会导致网络由于太多的包而过载，这就是糊涂窗口综合症。 解决的方法是防止发送端的TCP逐个字节地发送数据。必须强迫发送端的TCP收集数据，等待数据达到一定大小时再发送出去。。 发送端的TCP要等待多长时间呢？如果它等待过长，它就会使整个的过程产生较长的时延。如果它的等待时间不够长，它就可能发送较小的报文段。 Nagle找到了一个很好的解决方法，发明了Nagle算法。 Nagle算法的规则（可参考tcp_output.c文件里tcp_nagle_check函数注释）： （1）如果包长度达到MSS，则允许发送； （2）如果该包含有FIN，则允许发送； （3）设置了TCP_NODELAY选项，则允许发送； （4）未设置TCP_CORK选项时，若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送； （5）上述条件都未满足，但发生了超时（一般为200ms），则立即发送。 接收端引起的糊涂窗口综合症接收端的TCP也可能产生糊涂窗口综合症。 假如接收端缓存已满，而发送端不断的轮询，但接收端处理速度非常慢，可能很久才处理 1字节，接收端的TCP宣布其窗口大小为1字节，正渴望等待发送数据的发送端的TCP会把这个宣布当作一个好消息，并发送只包括一个字节数据的报文段。 这样的过程一直继续下去 —— 一个字节的数据被消耗掉，然后发送只包含一个字节数据的报文段。 对于这种糊涂窗口综合症，即应用程序消耗数据比到达的慢，有两种建议的解决方法。 Clark解决方法 Clark解决方法是只要有数据到达就发送确认，但宣布的窗口大小为零，直到或者缓存空间已能放入具有最大长度的报文段(例如常见的，1460字节)，或者缓存空间的一半已经空了。 延迟确认 这表示当一个报文段到达时并不立即发送确认。接收端在确认收到的报文段之前一直等待，直到入缓存有足够的空间为止。 超时重传机制TCP既然要实现可靠的连接，那么肯定不能置哪些丢包的数据而不管，因此必须要有一个超时重传机制。 超时时间如何计算？我们将超时时间记为 RTO（Retransmission-Time-Out），RTO 应该略大于理想状态的 RTT(报文往返时间)， 我们来思考一下RTO的选定依赖于什么呢？ 首先，在网络波动较小的情况下，所有报文的 RTT 相差不大，此时 RTO 可以设置为所有报文的 RTT 的加权平均值 ERTT，但这只是理想状态，我们仍需要考虑到网络波动情况，例如，如果第一次测试 RTT 样本为 10000ms(设样本 RTT 为 SRTT)，但第二次、第三次、第四次 SRTT 均只有不到 10ms，如果让我们人为的去选择，我们很容易会偏向于小一点的 RTO(例如10ms)，但如果采用计算加权平均的方法，RTO 会被第一次样本 SRTT 所影响，使得 RTO 高达几千，所以我们必须还要考虑到网络波动情况，即两次 SRTT 之间的偏差值，我们需要统计一个加权平均的偏差值 DRTT 以作为参考。 现在我们知道，RTO的选定主要依赖于两种数据： 样本 SRTT 的加权平均值 ERTT。 两次 SRTT 之间的加权平均偏差值 DRTT。 那么有$$ERTT &#x3D; \\alpha \\times ERTT + (1 - \\alpha) \\times SRTT \\DRTT &#x3D; \\beta \\times DRTT + (1 - \\beta) \\times |SRTT - ERTT|$$在 DRTT 的计算中，我们用 ERTT 代替上一次的 SRTT，TCP 官方推荐的权重因子为：$$\\alpha &#x3D; 0.125 \\\\beta &#x3D; 0.25$$现在知道了 ERTT 和 DRTT，我们可以计算 RTO 了，官方给出的公式是：$$RTO &#x3D; ERTT + 4 \\times DRTT$$注意，对重传的报文不应该计算 SRTT，也根本没法计算，你不知道接收到的应答是对重传之前的报文的应答还是重传的报文。 GBN 回退N步(Go Back N) 和 SR 选择重传(SELECR RETURN) 还是这个例子，如果发送方发送了 7 - 17字节，我们假设接收方的窗口如下： 考虑这个例子，此时接收方 B 理应回送 ACK &#x3D; 7，那接收方收到这个 ACK 之后，重传序号 7 字节不假，那 8，9，10…..之后已经发过的还要不要传？ 回退 N 步算法中要求 TCP 发送方从 ACK 处重传一切，而接收方接到冗余的报文也会像往常一样回送 ACK，一切的一切就好像回到了之前，这就是回退 N 步名字的由来，这种做法是实现简单，但缺点也比较明显。 选择重传算法中要求 TCP 连接双方协商好要重传的报文，例如这里的例子，接收方 B 应该明确告诉发送方 A 你得给我发 7 和 12、13，这些数据被记为紧急数据，此时，USG标志有效。 糅合的实现，SACK选择确认GBN 和 SR 各有千秋，那为什么不将它们糅合起来呢？ SACK 就是这样一个思想，SACK允许接收方有选择的确认最后一个接收的正确有序报文段，这允许接收方跳过那些已接收但未确认的报文段。 例如还是上面的例子： B 设置 ACK &#x3D; 7 A 从 7 开始重发，A 会继续发送 7、8、9…..等报文 当 B 收到 7 后，他会选择确认 ACK &#x3D; 12，而跳过 8、9、10、11这些报文。 A 收到 ACK &#x3D; 12后，之前没发完的报文(小于 12)也不发了，直接从 12 开始继续重传。 B 收到 12 后，选择确认 ACK &#x3D; 18，而跳过 13, 14…… 这就是选择确认的工作原理，也是当下的主流实现，糅合和 GBN 和 SR 的思想，其中发送方默认 ACK 之前的报文段均被确认。 快速重传有些时候，我们已经明确知道了一些数据报已经丢失了，这个时候没有必要继续等待超时计时器触发，我们可以直接选择重传这些数据报。 TCP 规定，当收到对同一个数据字节的 3 次冗余 ACK 时，我们有理由相信这个数据已经丢失了，这是因为能收到 ACK 说明网络不算堵塞，而在网络不堵塞的前提下，按道理数据早就到了，但仍收到 ACK 说明数据并没有到，那么这个数据报大概率已经丢失了，而不是在网络中迷路。 这就好比接收方在说：“大哥，其他的我都收到了啊，就差这一个了啊，赶紧的啊”。 就像接收方说的，此时没有必要磨蹭，我们可以直接重传而不必等待超时事件触发。 要几个定时器？难不成为每一个要发送的 TCP 数据报都维护一个定时器，如果你想你的电脑下一秒就爆炸那就这么做吧。 好吧，事实上是没必要的，我们只需要维护一个定时器就好了，发送报文前，来看看超时器是否未启用，如果未启用，则启用，否则什么也不做，仅仅只是发送报文（RFC 6298推荐的做法）。 当计时器超时时，重发在窗口内、收到的、最大的 ACK 数据段(也就是我们要重传的最小序号的报文段)，并重启计时器。 当收到 ACK 时，这意味着之前发送的报文得到了确认，那么定时器可能也是之前启动的，此时应该停止定时器，因为它很可能是过时的，并且重新启动(如果还有报文未确认的话)。 这样做虽然不是很精确，但它节省了大量的开销，而且大多数情况下工作的良好，因为从整体的角度看过去，计时器一直都在工作，没有一刻闲着，这意味着，即使有误差，误差也绝不会超过一个 RTO。 可参阅Information on RFC 6298 » RFC Editor (rfc-editor.org) TCP 发送方精简伪代码var nextSeqNum = 初始确认的序号; // 下一个要发送的 var sendBase = 初始确认的序号; // 发送窗口左指针(后沿) var size = 初始接收方窗口大小; // 窗口大小 while (true) &amp;#123; Event e = 堵塞监听事件; switch (e) &amp;#123; 事件：从应用程序中收到数据 data，data 不超过 size，准备将其发送 生成TCP首部序号为 nextSeqNum 的 TCP 报文段; if (定时器没有运行) 启动定时器; 向IP传递报文段; nextSeqNum = nextSeqNum + data.length; // 一个字节一个序号 break; 事件：定时器超时 // TCP 应当缓存序号为在窗口内、收到的、最大的 ACK 的数据报大小 重发在窗口内、收到的、最大的 ACK 数据段(也就是我们要重传的最小序号的报文段); 启动定时器; break; 事件：收到 ACK，ACK 标志位有效，ACK确认序号为 y，收到窗口大小为 size this.size = size; // 判断 y 是否在窗口内 if (y > sendBase) &amp;#123; // 这之前的默认确认(SACK)，窗口左指针移动 sendBase = y; if (当前存在未被确认的报文段) &amp;#123; 重启定时器 &amp;#125; else &amp;#123; 对 y 收到的冗余 ACK 数加 1; if (对 y 收到的冗余 ACK 数 == 3) &amp;#123; 立即重传需要为 y 的数据报 // TCP 应当缓存序号为 y 的数据报大小 &amp;#125; &amp;#125; &amp;#125; break; &amp;#125; &amp;#125; 拥塞控制在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络就会热载，这种情况就叫做网络拥塞。若出现拥塞而不进行控制，仍然我行我素的发送大量资源，整个网络就会变得越来越拥堵，所以我们要做一个文明人，避免拥塞时发送大量消息，这就是 TCP 的拥塞控制。 这个时候，多了一个拥塞窗口，拥塞窗口的大小根据网络拥塞程度动态改变。现在 TCP 发送速率不仅取决于滑动窗口，还取决去拥塞窗口，即：$$发送窗口大小 &#x3D; min(拥塞窗口大小，接收方的滑动窗口大小)$$TCP 拥塞控制的算法就是根据网络状态去动态的调整拥塞窗口的大小，TCP 希望网络好拥塞窗口能大些，网络差，拥塞窗口能小些，那么现在问题是，如何判断网络好不好呢？这有几种实现的思想： 让路由器报告网络拥塞情况。事实上 TCP 标志位里有些就是为此而生的，让路由器报告的优点时相对比较准确，缺点是如果网络本身就是拥堵的，发送报告无疑也增加了负担。 每收到一个 ACK 就认为网络没问题，而每一次超时事件都认为网络发送了拥塞。 TCP 广泛采用了第二种实现方式，相对简单，而且误差并不会很大。 TCP拥塞控制算法主要包括 3 个部分： 慢启动 拥塞避免 快速恢复 在次之前，我们先定义一些全局变量，我们定义:$$cwnd &#x3D; 拥塞窗口大小 \\ssthresh &#x3D; 慢启动的阈值 &#x3D; 检测到网络拥塞时 cwnd 的一半$$并且我们不会考虑滑动窗口的问题，约定发送窗口 &#x3D; 拥塞窗口。 慢启动别被误导了，慢启动可一点也不慢，慢启动存在的意义就是疯狂作死，它将以最快的速度去试探网络所能承载的极限(网络即将或已经拥塞)，并快速增大 cwnd 到网络能承载的最大阈值。 初始时，TCP 通常将 cwnd 置为 1 个 MSS(TCP 最大报文段长度，通常等同于 MTU，1460字节)，此时发送方只能发送 cwnd 个字节。 当 TCP 收到一个报文段 ACK 时，他会认为网络很好，于是开始作死，设置：$$cwnd &#x3D; SMSS + cwnd，\\text SMSS &#x3D; 发送方发送的最大报文段大小，这通常是一个 MSS、1460字节$$ 一般没有特殊说明，将默认 SMSS &#x3D; MSS &#x3D; 1460字节 还要注意如果接收方使用 SACK，那么很可能会一次性确认多个报文段，此时需要计算报文段个数$$N &#x3D; (ACK - baseSend) \\div SMSS$$ 于是下一次 TCP 可以发送 2 个 MSS 字节，此时接收端完全可以一次性确认两个报文段，于是 cwnd += 2MSS，下一次 TCP 可以发送 4 个 MSS 字节，而接收端又可以一次性确认 4 个报文段，那么 cwnd 变成 8MSS，下一次可以发送 8 个 MSS 字节……这一点也不慢，这可是指数级别的，如果时间复杂度是这个的话写算法题肯定超时了。 慢启动何时停止？有两种情况: 当 cwnd &gt;&#x3D; ssthresh(初始为无限大)时。根据我们对 ssthresh 的定义，$ssthresh &#x3D; 慢启动的阈值 &#x3D; 检测到网络拥塞时 cwnd 的一半$，当 cwnd &gt;&#x3D; ssthresh 时，cwnd 不能翻倍的增长下去了，TCP已经探测到了阈值，慢启动的任务已经完成了。上次它就是死在 2 * ssthresh，翻倍增长下去就会超过这个数，这次不能犯同样的错误。此时 TCP 会由慢启动转向拥塞避免。 当网络确实发生拥塞时，即触发了超时机制，慢启动探测到了阈值，这个阈值应该小于等于当前的 cwnd 的一半，它仍然不确定具体的阈值，此时设置 ssthresh &#x3D; cwnd &#x2F; 2，TCP 将 ssthresh 视为阈值，然后重新进入慢启动状态去试探阈值是否准确，此时 cwnd 重新设置为 1MSS。 当收到三次冗余 ACK 时，正如我们前面讲的，既然能接收到 ACK，网络肯定不会那么糟糕，那到没有必要重新进入慢启动尝试，TCP 将 ssthresh &#x3D;设为 cwnd &#x2F; 2，然后直接进入快速恢复阶段。 拥塞避免进入拥塞避免时，如果将 cwdn 在翻个倍就达到了阈值，但此时的 cwnd 确确实实又是没达到的阈值的，因此不能停止试探，而是要慢慢试探。 拥塞避免并非完全能够避免拥塞，是说在拥塞避免阶段将拥塞窗口控制为按线性规律增长，让 cwnd 慢慢的增长，使网络比较不容易出现拥塞。 具体的思路是： 让拥塞窗口cwnd缓慢地增大，即报文段每经过一个往返时间 RTT 就把发送方的拥塞控制窗口加上 1 MSS，这等价于每收到一个 ACK(默认是对报文段的 ACK，即一次确认 1MSS) 就增加 cwdn 一个 MSS。 拥塞避免何时停止？与慢启动一样，我直接内容复制过来： 当网络确实发生拥塞时，即触发了超时机制，慢启动探测到了阈值，这个阈值应该小于等于当前的 cwnd 的一半，它仍然不确定具体的阈值，此时设置 ssthresh &#x3D; cwnd &#x2F; 2，TCP 将 ssthresh 视为阈值，然后重新进入慢启动状态去试探阈值是否准确，此时 cwnd 重新设置为 1MSS。 当收到三次冗余 ACK 时，正如我们前面讲的，既然能接收到 ACK，网络肯定不会那么糟糕，那到没有必要重新进入慢启动尝试，TCP 将 ssthresh &#x3D;设为 cwnd &#x2F; 2，然后直接进入快速恢复阶段。 快速恢复当收到 3 个冗余 ACK 时，并不会将 cwnd 置为 1MSS，我们有理由相信此时网络没那么糟糕，因此快速恢复会将 cwnd 减半，即“乘法减小”：$$cwnd &#x3D; cwnd \\times 0.5$$就像我们之前说的，然后 TCP 会快速重传冗余数据报，在此期间，每收到一个 ACK 就增大一个 MSS，直到冗余数据报重传完毕并被确认，此时重新进入拥塞避免状态。 连接管理3次握手TCP三次握手如图： 第一次握手客户端给服务器发送一个SYN数据段(在 TCP 标头中 SYN 位字段为 1 的 TCP&#x2F;IP 数据包)，该TCP数据段中也包含客户端的初始序列号(Sequence number &#x3D; J)，同时会告知服务器缓存窗口大小。 第二次握手服务器返回客户端 SYN +ACK 段(在 TCP 标头中SYN和ACK位字段都为 1 的 TCP&#x2F;IP 数据包)， 该段中包含服务器的初始序列号(Sequence number &#x3D; K)；同时使 Acknowledgment number &#x3D; J + 1来表示确认已收到客户端的 SYN段(Sequence number &#x3D; J)，同时会告知客户端缓存窗口大小。 同时这个时候服务器会将连接放入半连接队列中，如果半连接队列已满，则不会回送 SYN + SCK，而是丢弃该连接。 第三次握手客户端给服务器响应一个ACK段(在 TCP 标头中 ACK 位字段为 1 的 TCP&#x2F;IP 数据包)，该段中 Acknowledgment number &#x3D; K + 1 来表示确认已收到服务器的 SYN段(Sequence number &#x3D; K)。 TCP连接从半连接队列转向全连接队列，当全连接队列满时，此时不会简单的抛弃，处理比较复杂，服务器可能会丢弃连接，也可能会发送 RST 报文重置连接。 经过三次握手，双方协商好了对应的初始序列号和缓存端口大小(双方都可当发送方或者接收方)。 这是我(50562端口)随便搜了个鬼玩意抓的包，上面是我像服务器发送的握手报文，因此 ACK 无效，同时我将我的序列号和窗口大小一并发送给服务器。 这是服务器给我的答复，可以看到 ACK 和 SYN 都设置为 1，同时对方也发送了窗口大小和初始序号给我门，这样我们双方都可作为发送方，而且可以看到 ACK 就是我们发送过去的序号加 1。 客户端回送 ACK 的图就不发了。 为什么不能 2 次握手 看图，其实主要是没法确认客户端的握手报文是已经超时丢弃的，还是真要握手….如上图，如果客户端一直超时就会有大量握手报文留在网络种，而在某一时刻它们突然达到服务器，服务器就不得不开启这么多连接。 让客户端在确认一次就可以解决这个问题，通过客户端的 ACK 可以唯一的标识一条握手报文。 啥？为啥不能四次？当然可以啊，谁说不能的，服务器把 ACK 和 SYN 当两次发就是四次了….. 同理，挥手也是可以三次的。 SYN 泛洪我们在握手阶段说了，如果半连接队列已满，服务器会丢弃该连接，SYN泛洪就是利用了这个漏洞，攻击者向服务器发送大量 TCP 连接，但是不确认它，让其占满服务器半连接队列，从而让服务器连接资源耗尽，陷入瘫痪的状态。 先说明一个问题，我们为什么要有半连接队列，这是客户端会发送第三次握手的 ACK，我们必须要有足够多的信息来确定这是一个合法的报文，我们要枚举队列中每一个半连接，看看是否匹配，若匹配，则生成全连接，否则，无视这个报文。 解决的方法不少，比较流行的是部署 SYN cookie 防御系统，Syn Cookie技术则完全不使用任何存储资源，这种方法比较巧妙，它使用一种特殊的算法生成 Sequence Number，这种算法考虑到了对方的IP、端口、己方IP、端口的固定信息，以及对方无法知道而己方比较固定的一些信息，如MSS、时间等， Syn Cookie 将这个 Sequence Number 作为序列号发送给客户端，在收到对方的ACK报文后，重新计算一遍，看其是否与对方回应报文中的 ACK Number -1 相同，从而决定是否分配TCB资源。 4次挥手 第一次挥手：客户端发送 FIN 报文段。 第二次挥手：服务器确认该 FIN 报文段。 第三次挥手：服务器发送 FIN 报文段。 第四次挥手：客户端确认，并进入TIME-WAIT阶段等待2MSL ( 最大报文生存时间，即报文在网络中理论上能生存的最大时间) 后再断开连接，服务端收到最终确认报文后立即断开连接，双方断开TCP连接。 为什么要Time-WaitTIME_WAIT状态存在的原因有两点： 可靠的终止TCP连接：保证客户发送的 ACK 能够被服务器正确收到，如果没有收到，服务器会重传 FIN，所以客户必须要等待一定的时间。 如果客户确实异常断开了，服务器端也会有保活机制，在重传一定次数后无反应后，服务器会断开连接。 保证让迟来的相同TCP报文有足够的时间被识别并丢弃。 过多 Time-Wait 占用端口如果主动发起 close 的是服务器，那么服务器就会存在 Time-wait 在占用端口，当 Time-wait 过多时，服务器压力就会变大，端口紧缺(客户端也是一样)，在 Linux 中可以开启TIMEWAIT重用和快速回收。 重用：允许将TIME-WAIT sockets重新用于新的TCP连接。 快速回收：不必等待 2MSL，加快速度！ 编辑Linux内核配置文件 &#x2F;etc&#x2F;sysctl.conf，找到如下参数： net.ipv4.tcp_syncookies = 1 // 表示开启SYN Cookies。 当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭； net.ipv4.tcp_tw_reuse = 1 // 表示开启重用。允许将TIME-WAIT sockets重新用于新的TCP连接，默认为0，表示关闭； net.ipv4.tcp_tw_recycle = 1 // 表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。 net.ipv4.tcp_fin_timeout = 30 // 修改系默认的 TIMEOUT 时间 30 s 粘包拆包先提出一个问题，你能通过 TCP 首部确定 TCP 数据大小吗？ 很遗憾，你应该不能，好吧，如果算上选项的话，那你应该又能了。 大多数情况下，这个问题的答案是不能，也就是说，TCP是无消息边界的，TCP首部 起到的仅仅只是简单的校验和流量空中，对一条消息是没有边界限定的，你只能不断的去读取 TCP 字节流。 对于像传输文件、传输视频等这样的，是没有粘包的概念的，因为它本身就是一个整体，自然也没有谁粘谁了。 但是考虑下面这种情况，你正在和别人用 TCP 聊天： 你发送了一条消息：I will select d。但是 TCP 认为数据太少了，现在发出去会造成糊涂窗口综合征，我要等多一点在发送出去，，然后你又键入了：ad to carry，这个时候数据被转换为字节流加入缓存中，TCP认为差不多了，是时候该发送了，于是接收方就受到了： I will select dad to carry 啥？你要选你爹去 Carry？你和你朋友二脸懵逼。 这就是粘包，可能引发粘包的原因有： 发送方收到数据后并不立即发送，而是等待数据大小达到一定阈值。 接收方处理速度不快，使得下一个数据报头部黏在前一个数据报尾部。 什么是拆包呢？ 假设发送方缓存只剩下 200 字节，而你现在要发送 1000 字节数据，那么这个时候就会发生拆包，1000 字节的数据将会拆成 200 + 800 发送，200字节将会粘在前一个数据的尾部。 怎么处理粘包拆包呢？ 在首部字段的选项中加上消息大小。 发送方与接收方约定好，每个消息都是固定的长度。 以约定好的特殊字符作为结尾。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"synchronized底层原理","slug":"synchronized底层原理","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.987Z","comments":true,"path":"post/db0.html","link":"","permalink":"http://example.com/post/db0.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 synchronized底层原理前言在JDK1.5之前，synchronized的实现是依赖于操作系统的，采用的是一种悲观的机制，必须严格保证资源的安全性，因此无论是否存在并发问题，都必须严格的经过获取锁操作，获取锁必须切换至内核态，而当线程尝试获取失败后，必须挂起线程然后切换，休眠或切换线程也都必须切换至内核态由操作系统调度，这种操作是重量级的，然而研究者发现绝大多数情况下，并不会存在资源竞争问题，为此，JDK1.6之后对synchronized进行了大量的优化，线程初始抱着乐观的心态进行尝试(不借助OS)，除非迫不得已，线程才会将其托管给操作系统。 本文基于JDK1.6之后的synchronized讲解，synchronized拥有如下几个阶段，其中无锁与偏向锁是同一级别的，常理上来说锁只能升级不能降级，但后面我们会说到这并不是绝对的： graph LR A(无锁阶段) --> B(偏向锁阶段) --> C(轻量级锁阶段) --> D(重量级锁阶段) B --> A A --> C 使用过synchronized的朋友都知道，synchronized是基于对象锁定的，即使不传入任何参数，synchronized也会自动锁定this，研究synchronized之前有必要研究一下对象的内存布局，因为在对象头中，存在与synchronized相关的信息。 对象头(Object Head)主要分为两个部分，第一个部分是我们着重要研究的，它是实现synchronized的关键，被称作 “Mark Word”，第二部分记载着指向方法区对象类型的指针，这一部分称为 “Class Metdata”，这一部分并不是我们研究的终点。 请注意实际的对象头通常只有 32bit，这意味着 “Mark Word” 字段是复用的，字段修改将会覆盖原来的数据，你完全可以将他理解为C语言中的共用体。 不过，目前大多数机器都是64位的了，这意味着Mark Word字段为64bit，其中主要是线程ID增加到了54位，其余没有改变(1位占位)。 无锁当锁标志位被设置成01且偏向为设置为0，此时对象处于无锁状态，你可能会觉得无锁阶段就是让线程不持有锁而去访问共享资源，但事实上并不是这样如此，无锁会产生并发问题，无锁仅仅是对象初始时的状态，即当对象未使用synchronized或其他并发语句时，对象处于无锁状态。 请注意，无锁与偏向锁是同一级别的，当开启了偏向锁后，新 new 出来的对象将不再是无锁状态，而是直接处于偏向锁状态(在JVM启动时有所不同，JVM启动时延迟开启偏向锁，这一段时间内对象处于无锁)。 偏向锁偏向锁的工作原理当只有一个线程工作时，自然不会发生并发问题，但诸如StringBuffer这样的类内部实现几乎每个函数都使用了synchronized标识，而我们通常使用的String内部也大量借助了StringBuffer类，在JDK1.6以前即使是单线程运行也会造成可怕的性能问题，偏向锁主要用于解决这个问题，即解决数据在无竞争情况下发生不必要的同步机制，从而提高程序性能。 偏向锁中的”偏向“意味着这个锁偏向于某一个线程，这个线程往往是第一个使用偏向锁的线程，在这之前，对象要么处于无锁状态，要么处于匿名偏向锁状态。如果在接下来的过程中，一直没有别的线程申请锁，那么持有偏向锁的线程将不用采用任何的同步机制。 通过引入偏向锁，在单线程内进行synchronized操作将不会陷入内核申请锁，在前面讲过初始状态下，对象处于匿名偏向状态，此时对象偏向于一个匿名的线程，当第一个线程A调用synchronized语句时，JVM发现对象头中的线程ID为匿名ID，于是JVM记录下该线程A的ID到对象头中，这标志着线程A持有了该对象偏向锁，现在该锁会偏向与线程A，只要是线程A申请锁，JVM会无条件直接放行，而无须由操作系统调度，这大大提高了效率。 一旦线程获取到了偏向锁，线程会在自己栈帧中创建一个锁记录。 然而，一旦有其他线程尝试获取偏向锁，如果偏向锁处于非匿名状态，此时 JVM 认为当前环境为并发环境，JVM 会宣告偏向模式结束，升级为轻量级锁（不考虑重偏向）。 不考虑重偏向的情况下，偏向锁只能偏向一次，因此偏向锁一旦撤销为无锁或升级后，就再也不会进入偏向模式了。 如果此时线程A仍然处于运行状态，线程 A 必须跑到安全点才能停下来进行偏向锁的撤销(升级)，安全点是会触发GC的必要条件，我没有真正理解为什么要到安全点处停下来，猜测升级锁的过程可能需要暂停所有线程或是需要触发GC(触发GC猜测是有根据的，查看下面打印出的对象头，锁升级时对象的分代年纪增加，由此判断必定发生GC)，因此需要让线程在安全点处停下来。 我们借助JOL工具来打印对象头信息，从而理解偏向锁，考虑如下代码，这里我们显示的添加了参数-XX:+UseBiasedLocking强制性要求JVM开启偏向锁: class A &amp;#123; boolean flag = false; &amp;#125; public class Test &amp;#123; public static void main(String[] args) &amp;#123; A a = new A(); //该代码表示打印对象头信息，前提是引入了 JOL 依赖 System.out.println(ClassLayout.parseInstance(a).toPrintable()); synchronized (a) &amp;#123; System.out.println(ClassLayout.parseInstance(a).toPrintable()); &amp;#125; synchronized (a) &amp;#123; System.out.println(ClassLayout.parseInstance(a).toPrintable()); &amp;#125; var t = new Thread(new Runnable() &amp;#123; @Override public void run() &amp;#123; synchronized (a) &amp;#123; System.out.println(ClassLayout.parseInstance(a).toPrintable()); &amp;#125; &amp;#125; &amp;#125;); t.start(); t.join(); &amp;#125; &amp;#125; 我们直接来看打印出的结果，在此我只将 Mark Word信息展示出来： 第几次 说明 线程ID Epoch(时间戳) 分代年龄 是否可偏向 锁标志位 第一次 此时对象刚创建，处于匿名偏向锁状态，可以看到，当线程ID全为0时表示匿名状态 &#x3D;&#x3D; 00 0000 1 01 第二次 此时线程被锁定，进入有名偏向，a对象保存该线程ID T1 00 0000 1 01 第三次 对象发现线程ID一致，直接允许线程进入同步代码块，而不陷入OS T1 00 0000 1 01 第四次 新的线程想要获取锁，JVM发现该锁处于有名偏向状态，撤销偏向锁，升级为轻量级锁 T2 &#x3D;&#x3D; &#x3D;&#x3D; &#x3D;&#x3D; 00 批量重偏向class文件中存在一个计数器，每一次与之关联的对象进行升级或撤销时，都会自增 class 中的计数器，当达到阈值后(默认的是20次)，JVM 认为该类可能频繁的被其他线程访问，于是会允许重偏向，允许对象重新偏向一个线程。 为搞清楚发生了什么，我们来看一个例子： class A &amp;#123; &amp;#125; public class Test &amp;#123; public static void main(String[] args) throws InterruptedException &amp;#123; List&lt;A> list = new ArrayList&lt;>(); var t1 = new Thread(() -> &amp;#123; for (int i = 0; i &lt; 30; i++) &amp;#123; A a = new A(); list.add(a); synchronized (a) &amp;#123; System.out.println(String.format(\"T1::%d \", i + 1) + ClassLayout.parseInstance(a).toPrintable()); &amp;#125; &amp;#125; &amp;#125;); t1.start(); t1.join(); for (int i = 0; i &lt; 25; i++) &amp;#123; A a = list.get(i); synchronized (a) &amp;#123; System.out.println(String.format(\"T2::%d \", i + 1) + ClassLayout.parseInstance(a).toPrintable()); &amp;#125; &amp;#125; System.out.println(ClassLayout.parseInstance(list.get(25)).toPrintable()); &amp;#125; &amp;#125; 上面代码中让 t1 执行20次，每次都创建一个新的对象，结果显示，t1 时所有对象都是偏向锁。 t2时，根据规则，偏向锁将会升级为轻量级锁。但注意，由于对象都关联到一个A.class中，经历20次撤销升级后，会触发批量重偏向，通过实践发现 t2 中前 19 次确实升级了锁，但第 20次之后，又变回了偏向锁。 如图，索引 19 的对象使用了轻量级锁，而索引 20 的对象重新使用了偏向锁，偏向了线程二，而后面的元素都使用了偏向锁。 我们还打印了 list.get(25) 的对象头，其仍然处于偏向线程一的状态，释放偏向锁只会释放栈帧中的锁记录而不会修改对象头。 当然，如果是真正的发生了并发访问，必须要升级锁，批量重偏向和重偏向只是负担。为此，如果在一定时间内，计数器从批量重偏向的起点(20次)增加到了40次，触发新的阈值(默认为40)，此时 JVM 认为对该类的访问可能真正存在并发问题，该类不适合偏向锁，JVM 会自动关闭该类的偏向锁，同时会批量的对锁进行撤销。 是否可重偏向上述我们提到当触发冲偏向阈值时，JVM 是允许重偏向的，现在有个问题，例如在上面的示例中，线程二如何确定线程一是否释放偏向锁呢？如果线程一未仍然持有偏向锁，线程二可不能简单的进行重偏向。 首先可以想到的是，可以扫描对应线程栈帧，查看是否存在锁记录，事实上升级到轻量级锁就是这样做的。 但是这样效率不高，尤其是在 批量偏向 的语义下，如果没有一些批量操作，它为什么会被称为 “批量重偏向“ 呢。 你是否有观察到对象头中 epoch 字段，在与每个对象关联的 Class 信息中，也有一个 epoch 字段。 JVM 是这样做的：在每次触发批量重偏向时，自增 Class 中的 epoch，同时扫描所有状态为偏向锁的对象头，遍历偏向线程的栈帧，如果存在锁记录，则更新对象头 epoch 与 Class 中的同步。 现在，仅需要比较对象头 epoch 与 class 中的 epoch 是否相等即可判断。 偏向锁升级如果不考虑重偏向，当： 一个线程发现偏向 ID 不是自己 收到计算 HashCode 的指令 会触发锁升级。JVM 查看偏向线程栈帧中是否存在锁记录： 如果不存在：进入轻量级锁升级逻辑 如果存在：CAS 操作将锁记录设置为轻量级锁记录，然后geng’x（CAS 失败说明锁被释放，返回不存在的逻辑） 其他规则在前面我们说过Mark Word是复用的，这就意味着偏向锁中的线程ID会复写原先的对象哈希值等数据，这可怎么办呢？了解Java的朋友应该知道对象的哈希码只会被计算一次，然后被永久保存在对象头中，该部分数据是不允许丢失的，但哈希码的计算是延迟计算的，即等待需要时才会计算，这就给偏向锁增加了几条规则：1) 当对象的哈希值已经被计算了，该对象不允许进入偏向锁阶段，而是直接从无锁阶段升级为轻量级锁阶段；2）当对象正处于偏向阶段时，如果收到了计算哈希的请求，会立即撤回偏向锁，直接升级为重量锁，重量级锁中存在字段保存对象的哈希值。 值得一提的是，轻量级锁也是可重入的，仅仅只是比偏向锁多了些操作罢了，但偏向锁在引入重偏向或批量重偏向后也变的不是那么简单，在JDK15之后，官方决定移除偏向锁。 轻量级锁初衷偏向锁对于被偏向的线程来说，没有采用任何的同步方式，因此获取锁的成本几乎为零，但偏向锁只能消除单线程环境下不必要的并发同步语句，在真正的多线程环境下却无能为力，必须升级为轻量级锁，轻量级锁能够维护并发安全，同时具有一定的性能。 轻量级锁设计的思想是：研究者们发现即使处于多线程环境中，发生竞争的可能性也是很小的，一个线程可能很快甚至立即就能获取到锁，既然如此，一旦线程获取锁失败，则没必要让其陷入休眠，可以让线程多等等，因为线程很快就能获取锁。 既然不用让线程进入休眠，这意味着我们无须借助操作系统调度的功能(JVM不具备让休眠&#x2F;唤醒线程的功能，Java中的线程都是被1:1映射到操作系统的线程中，关于线程调度的操作需要依赖OS)，也就是说轻量级锁的所有功能都可以由JVM自己实现，这就避免了使用操作系统互斥量和调度线程的性能消耗。 CAS在介绍轻量级锁实现之前，有必要介绍CAS操作，因为JVM必须要自己实现一个锁以避免并发问题，而JVM肯定不能借助synchronized实现锁，否则就套娃了，因此必须要借助硬件的支持(可参考线程间的同步方式)，CAS是目前大多数主流CPU都提供的一种原语，正如它的全称(比较并交换; Compare And Swag)一样，CAS的C代码大概如下所示： int CompareAndSwap(int *ptr, int expected, int new) &amp;#123; int actual = *ptr; if (actual == expected) &amp;#123; *ptr = new; &amp;#125; return actual; &amp;#125; CAS的魅力在于它无须获得锁，而是直接进行尝试，如果原数据与期望值相同，则更新数据，否则不更新数据，更新数据失败后，线程可以重新尝试，这样说可能难以理解，假设有全局变量volatile int num = 1，假定多条线程都在访问该变量，其中有一条线程想要将num + 10，来看下面C代码，该线程可以这样做： int currentNum; do &amp;#123; currentNum = num; &amp;#125; while (CompareAndSwap(&amp;num, currentNum, currentNum + 10) != currentNum); 理解为什么这样做不会发生并发问题，如果真的发现并发问题，只可能在执行完第3行后线程被切换，来分析一下这个过程，假设初始时num &#x3D; 1，线程A执行完第三行后 currentNum &#x3D; 1，此时线程B强入，线程B修改num &#x3D; 520，然后回到线程A，线程执行原语CAS，CAS不允许被强入，CAS执行阶段发现 num(520) 与 currentNum(1) 不相等，此时线程明白该值已经被其他线程修改，变”脏“了，于是不更新num的值，然后返回 520，520 !&#x3D; 1，线程继续尝试，直到正确执行。CAS是一种乐观的并发策略，线程总是假设马上就能成功甚至立即可以成功而不会发生并发问题，测试发现，多个线程同一时间并发竞争某一资源时，只有一个能成功，而其余都将失败。 CAS使真正的无锁编程称为可能，在valHandle类中，CAS操作已经正式对用户开放了，未来可能真正将会进入无锁编程时代，但这里我们仅将CAS作为实现轻量级锁的一种方式。要注意，CAS也是有缺点的，例如CAS可能会导致线程饿死；例如CAS不断自旋可能会导致CPU飙升；又例如CAS存在”ABA“问题，即值从A变为B，又从B变为A，对于线程来说，该值好像从来没有变化，一直为A，解决这个问题的办法是引入版本号，但这无疑增加了复杂度。 具体实现现在，我们开始研究轻量级锁的具体实现，在偏向锁中，我们谈到一旦哈希值被计算，它必须要被保存下来，基于此，轻量级锁实现中，线程会复制一份原先的Mark Word存放在自己的栈帧中，然后再覆盖哈希值的数据。称复制品占用的空间为锁记录(Lock Record)空间。 那么对象又如何直到该锁记录所在位置呢？在对象的Mark Word中，记录着指向该行记录的指针，同时，行记录中存放着指向对象头的指针(这一点我不理解)，如下图所示： 现在来具体理解一下实现原理，当线程想要获取轻量级锁时，无外乎就两种情况： 锁的状态为偏向锁(开启偏向锁时)，但偏向的是其他线程或锁的状态为无锁状态(偏向锁不可用)。此时锁会升级为轻量级锁，JVM首先在当前线程栈帧中创建锁记录，然后利用CAS操作将对象中的Mark Word指针修改为执行锁记录的位置，如果修改成功则线程成功持有轻量级锁；否则，一旦CAS失败，上面讲过肯定存在另一个线程成功的强入，此时线程将自旋并且重试(进入情况2)。 锁的状态已经为轻量级锁。此时JVM会检查Mark Word中的指针是否指向当前栈帧，如果是则复制一份空的锁记录到栈帧中(计数作用)，然后直接放行(这也是为什么说synchronized是可重入的原因)，否则进行自旋不断尝试，若条件符合情况1，则重试CAS操作；若条件符合情况2，则重新判断Mark Word中的指针是否指向当前栈帧。 现在来考虑线程释放轻量级锁的操作，释放锁也存在两种情况： 轻量级锁未升级。当轻量级锁未升级时，此时为正常状态，线程利用CAS操作将原来的Mark Word复制回去，对象恢复偏向或无锁状态，其他线程可获取轻量级锁。 轻量级锁已升级。我们在之前讨论过CAS的缺点，当自旋过多或线程过多时，CAS反而降低效率，为此，JVM制定了一些规则来升级轻量级锁： 1）等待线程自旋次数超过一定次数时(默认为10次，可以添加参数-XX:PreBlockSpin=val来修改)，升级为重量级锁； 2）当正在等待的线程不只一个时，升级为重量级锁。 3）正在持有轻量级锁时，如果收到重新计算哈希值的请求，升级为重量级锁。 当升级时，JVM修改Mark Word中的数据，并且使所有等待线程陷入休眠，JVM并不会强制性要求持有轻量级锁线程释放。由于Mark Word数据已被修改，当轻量级锁释放时，指向CAS操作必然会失败，此时线程意识到锁已升级，此时它必须利用Mark Word中指向重量级锁的指针来唤醒正在休眠的线程。 重量级锁当锁升级为重量级锁时，此时必须依赖于操作系统实现，Java中封装了一层抽象，每一个对象与Class都有与之关联的监听器Monitor，重量级锁对象中指针便是指向了对应的Monitor对象。 Monitor利用操作系统的Mutex(互斥量)维护了一系列的变量，例如正在持有锁的线程ID、线程Mark Word等，其中最主要的是一个int类型的数量值，当该值为0时，意味着线程可以持有锁，此时线程登记自己的信息，递增该值；当线程发现线程ID是自己时，自增该变量，并继续持有锁；当该值不为0时，线程需要陷入休眠等待该值为0。而当线程释放锁时，需要自减该值，并唤醒等待队列中的全部线程，让线程非公平的竞争锁(依赖于具体OS的实现)。 熟悉并发的朋友们很快就能发现整个操作的逻辑十分类似于采用条件变量(可参考线程间的同步方式)，事实上Monitor就是采用条件变量实现的，而条件变量必要的三要素：互斥锁、休眠、唤醒都是基于操作系统实现的，此时的锁是重量级的。 在jdk1.6之前，synchronized语句块反编译出的字节码会用monitorenter和monitorexit包括代码块，monitorenter指令表示线程必须持有对象的锁才能进入代码块，monitorexit指令则是表示释放该锁。不过在jdk1.6之后，指令的语义已经变了，会根据不同的锁以生成不同的策略。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"事务底层原理","slug":"事务底层原理","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.987Z","comments":true,"path":"post/3e53.html","link":"","permalink":"http://example.com/post/3e53.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 事务底层原理(INNODB)前言事务必须满足ACID四个特性，即原子性、一致性、隔离性和持久性，隔离性由锁来保证，我们主要研究事务是如何保证原子性、一致性和持久性。 redo log为什么需要 redo logInnoDB 存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理，可将其视为基于磁盘的数据库系统（Disk-base Database），修改数据需要先将磁盘中的行记录读至内存，修改后再保存至内存持久化。 为了保证事务的持久性，每次执行一条SQL语句修改数据后就必须将修改后的值写入磁盘，而写入磁盘是非常缓慢的，在大型的程序下，频繁的写入磁盘会使得性能急速下降，由于这个原因，在Innodb引擎中，所有的操作都被设计在内存池中进行以提高效率，如果数据在内存池中，则直接在内存中修改，否则从磁盘读入内存中操作。 Innodb是多线程引擎，其中专门有一个后台线程master thread周期性的将缓冲池中的内容刷新到磁盘中，这样似乎便可以在保证持久性的同时又提高了效率，但这是不正确的，在这个周期内存在于内存池中的数据也是可能丢失的，无法保证数据的持久性，因此我们需要引入**预写日志(WAL)**策略，这里的日志就是redo log，即重做日志。 WAL是很容易理解的，即提交事务时，先将修改过的内容提交到磁盘的重做日志文件中进行持久化，然后再修改内存页面为脏页，释放内存页面占用，一旦没有任何事务占用页面，则等待被后台进程刷新至磁盘这样即使在等待的过程中内存数据因为数据库死机或其他原因而丢失，也可以通过重做日志中的记录来恢复该数据以保证数据的持久性。 还要注意的一点是，在未提交事务时，redo log 是存在于内存缓冲区中的，这样做的目的是为了提升效率，只有在特定条件如事务提交时，才将 redo log buffer 刷新到磁盘的redo log文件中。 例如，当我们执行修改语句时，我们先将磁盘中的行数据所在的页读取至内存池虚拟页中，此后便在内存池中对该页进行修改，修改前，首先将要修改的值以及事务 id 的等其他信息写入 redo log 缓冲区，之后再修改内存页中的数据，同时将该页标记为脏页。提交事务时，刷新redo log缓冲区到磁盘以持久化，master线程将内存中的脏页写回磁盘。 这样即时内存中脏页丢失，数据库还是可以通过已持久化的重做日志还恢复数据。 此时，可能会几点疑问？ master线程最终也还是要将所有脏页刷新回磁盘，这相比于每修改一次数据就刷新磁盘效率高在哪呢？ 重做日志可能会存在于缓存中，这样也有丢失的可能。 重做日志还是要写回磁盘，会不会降低效率？ 当脏页数据丢失时，数据库是如何通过重做日志恢复数据？ 关于第一点的问题，由于每修改一次数据就写回磁盘，写回磁盘的位置可能是随机的，如果对磁盘性能稍微了解的话就会知道随机写效率是极低的，在等待一定时间后，此时存在大量将写回磁盘的数据，master线程可能会对这些写回进行排序，使得顺序写回变得可能，完全顺序读写磁盘效率是相当于读写内存的，是非常高效的，即时是不完全的顺序，其效率也要高于随机写，这就是为什么master是周期性的写回。 关于第二点的问题，要知道重做日志缓提交后就被刷新回磁盘，也就是说如果日志缓冲丢失了，通常情况下事务处于未提交的状态，在未提交时抛出异常是合理的，当程序员发现错误发生在事务提交之前时，它就应该认识到这次事务是执行失败的，下次应该重新执行该事务。 你可能还会想：如果redo log写磁盘写一半而宕机了怎么办，此时事务已提交，但脏页未被刷新？注意此时事务虽已提交。但处于正在提交且未提交完成的状态，只有在 redo log 写完之后才会标记为提交成功。 不过在某些情况下，还是会遇到一些数据不一致的问题，我们会在文末探讨这些问题。 第三点、第四点我们下文会详细介绍。 重做日志结构重做日志结构共有51种之多，未来还会更多，这里简单说明 insert 与 delete 的重做日志结构，对于这两种操作的重做日志结构如下图所示： 他们有着通用的头部字段： type：重做日志的类型。 space：对于记录所在表空间的ID。 page_to：页偏移。 知道了 space 和 page_to 便可以确定该记录物理页以及该记录所在，后续恢复数据会利用这一点。 对于insert日志，占用内存较多，因为要存储新插入的值。 而对于delete日志，我们仅须通过 type 知道这是一条删除日志，无须数据字段。 重做日志文件结构在理解重做日志本身结构后，我们来看看重做日志是被如何组织的。 在 InnoDB 中，重做日志以块的形式存储，这通常是512字节，与磁盘一次性读写的大小相等，因此重做日志块的读写是一次原子操作，不需要额外的存储。 如果重做日志大小超过了512字节，那么它将被存储在两个块中，为了消除内部碎片，一个块可能和存储多个日志文件，但代价是需要更多的标记位以表示各个日志文件。 重做日志块在缓存中被组织成类似于数组的形式，我们称这个链表为重做日志缓冲区，即 redo log buffer，日志缓冲存在于内存中。 重做日志块允许同时存在多个重做日志，例如下图，有T1和T2两个日志，T1大小为762字节，在去掉头部和尾部20字节后，一个块仅能装下492字节，因此T1被分割装入第二块中。 头部字段可以表示该块是第几块，同时也存在字段LOG_BLOCK_HDR_DATA_LEN字段标识第一个重做日志在该块中的偏移量，例如块二中该字段被设置为270，这样数据库就知道T2的偏移量为270，而T1的尾部（或 T2 的头部）具有结束标志，数据库也知道T2（如果有的话）的偏移量是370。 重做日志文件结构只需要在redo log buffer的基础上加上一些文件头信息即可，如下图所示： 这些信息的具体大小如下，Log File Header是文件头，它包含文件大小、版本号、LSN等一些有用信息，CP1和CP2名称为checkpoint，它包含检查点信息，关于检查点信息我们后面再说。 在写入文件时，从redo log buffer头部开始依次读取所有重做日志写入磁盘，重做日志在磁盘中被存储的形式与在缓冲区中存储形式相同。 log group与循环写入一个日志组由多个日志文件组成，我们通常只使用一个日志文件组，而设置多余的日志文件组用于备份。 日志文件写回磁盘是循环写入的，什么意思呢？假设一个日志文件组有三个日志文件f1、f2和f3，我们从f1开始，顺序读取redo log buffer中的日志写入f1，当f1写满时写f2，f2写满时写f3，而f3满时则继续写f1。 log group中的多个文件在逻辑上被组织成连续的，尽管在实际的磁盘中他们不一定要连续。 写入同一个文件内的大部分记录都是被顺序组织的，因此重做日志的写入磁盘是非常快的。 日志何时写入磁盘？这个具体的规则是： 事务被提交时。 当log buffer中内存不够时，通常使用超过一半便触发写入磁盘动作。 写入遇到CheckPoint点时。 数据恢复：LSN标记LSN称为日志的逻辑序列号(log sequence number)，在innodb存储引擎中，LSN占用8个字节。LSN的值会随着日志的写入而逐渐增大。 LSN不仅存在于redo log中，还存在于实际数据页中，LSN是用于恢复数据的关键点。 简单来说，LSN就是用于标记的版本号，在数据库中，随着事务发生并且条目被写入日志文件，LSN 会不断增大，在 FP3 之前，上限为 0xFFFF FFFF FFFF，LSN每次增大一个重做日志的大小。 LSN在重做日志中和实际页中都会存在，这一点是很重要的。在页中的LSN表示最后一次的被刷新LSN号。 举个简单例子而言，假设初始时LSN为0，此时我们执行一条插入语句:insert into test value(0);，数据库会为其生成一条重做日志，设为T1，事务提交时，重做日志被持久化，同时数据库将插入数据所在的页0设置为脏页，此时页0与对应的重做日志LSN都为0。 再假设上图中的脏页已经被正确的刷新会磁盘了，那么磁盘中对应真实页的LSN即为0，这里认为磁盘中的页号也是0，这是与重做日志中的页号对应的。 我们假设T1大小为100byte，那么此时LSN号自增重做日志的大小，即 LSN &#x3D; 0 + 100 &#x3D; 100，现在假设我们执行一条修改语句，将 a 的值修改为 1，数据库从磁盘中读取数据到内存，为了方便，我们仍然认为读到虚拟内存中的页也为0，设此时为修改语句生成的重做日志为T2，那么此时的结构为： 这是正确的结果，此时重做日志中页0的LSN被更新为100，那如果内存中的脏页丢失了呢？数据库要如何恢复信息呢？ 如果此时数据库宕机而丢失了此时页0的信息，那么磁盘中页0的LSN为上一次的LSN，即0，数据a的值也是0，这是完全错误的，当数据库启动时，它会扫描重做日志试图恢复错误。 首先扫描T1，发现T1中的日志指向物理页0，并且发现 $T1中的LSN &lt;&#x3D; 对应页中的LSN$，于是数据库就会认为该LSN版本的数据是一致的，未出错。 数据库继续读取T2，T2中的日志也指向物理页0，并且发现 $T2中的LSN &gt; 对应页中的LSN$，数据库可以断定，该版本发生了错误，于是数据库读取T2中的页偏移以确定对应记录的位置，根据T2中的数据修改页0中的数据，此时设置 a &#x3D; 1，并更新LSN号，于是，数据库正确的从错误中恢复了，数据的持久性得以保证。 你大概已经明白了数据恢复主要流程，数据库主要通过比较LSN版本号以得知是否出错，如果出错则根据重做日志中的信息以恢复数据。 你可以在命令行键入mysql &gt; SHOW ENGINE INNODB STATUS\\G，找到有关于LOG的记录，其中Log Sequence Number即为当前LSN。 在我们的描述中，一旦数据库丢失数据，其必须要扫描所有的重做日志才能从错误中恢复过来，当重做日志文件非常大时，这需要相当久的耗时，为此，引入了CheckPoint技术。 CheckPoint 技术检查点的作用checkpoint主要2个作用： 保证数据库的一致性，这是指将脏数据写入到硬盘，保证内存和硬盘上的数据是一样的。 缩短实例恢复的时间，实例恢复要把实例异常关闭前没有写出到硬盘的脏数据通过日志进行恢复。如果脏块过多，实例恢复的时间也会很长，检查点的发生可以减少脏块的数量，从而提高实例恢复的时间。 工作原理前面提到过，脏页回在缓冲池中继续存在一段时间后才会被后台线程回收，如果此时我们要关闭数据库但内存中的脏页还未被刷新怎么办，难道我们还要等待其被刷新吗？但我们又如何知道内存何时被刷新呢？一旦我们直接强制性关机，岂不是无故的让数据库陷入错误，下一次启动时又需要大量的时间恢复？ 在某些情况下，我们需要强制性将内存中的脏页刷新回磁盘。 一旦我们主动刷新内存，将部分脏页刷回磁盘（某些脏页可能被事务引用，无法刷新），我们令当前内存中剩余脏页的最小的 LSN 为 MLSN，由于LSN号是递增的，那么我们就可以肯定所有LSN小于MLSN的版本都已经被正常刷新回磁盘持久化，那么下一次恢复时对于这一部分我们便不用去扫描了，这样就可以极大的节省恢复时间。 通常，Innodb 并不会扫描所有的页看看能不能刷回，这太慢了，innodb 维护了一个 flush_list，这是个 LRU 脏页链表，最新访问的在头部，LSN 对应也是最大的。 另外，检查点并非是按 LSN 顺序将脏页刷盘后最新的 LSN，例如考虑一个复杂的情景： 事务 A 修改页面 X LSN 为 100，对应日志 x1；然后修改页面 Y LSN 为 200，对应日志 y1；然后修改页面 X LSN 为 300，对应日志 x2。 此时模糊检查点发生，此时页面 Y -&gt; 200，X -&gt; 300，因此先将页 Y 刷回，并丢弃 200 及以前的日志。 这是错误的，这样的话 x1 就被丢弃了！ 因此，flushList 必须要按照脏页最小的 LSN 计算。因此个页应该要有两个 LSN，一个记录第一次 LSN 修改，另一个记录最新的 LSN。 这个最大的LSN就是检查点，顾名思义，即从这个点后开始检查，之前的点无须检查。 在特定条件下，检查点被触发，checkpoint 进程开始一个checkpoint事件，并记录下当前可顺序刷回的LSN最大的脏页，称为检查点，也叫CP RBA。 而后，checkpoint进程通知DBWn进程将所有checkpoint RBA之前的buffer cache里面的脏块写入磁盘，这时候页会被锁定，无法被事务修改。 确定脏块都被写入磁盘以后，checkpoint进程将checkpoint信息(LSN)写入&#x2F;更新数据文件和控制文件中。 在此我们还要引入一个概念，称为write_pos(write_pos和checkpoint信息被保存在日志文件头部的CP1和CP2字段中)，即当前写入点，那么数据库恢复时只需要恢复 $check$point 到 $ writepos $之间的重做日志即可。 例如当前写入LSN为13000，上一次检查点为10000，那么只需恢复10000到13000之间的信息即可。 检查点何时触发？在日志何时写入磁盘时我们曾介绍过3种方式，事实上前两种方式其实就是触发了检查点事件，但检查点事件却不只这两点，因此我才会将第三点写上去。 现在我们来具体的探讨一些检查点事件何时被触发。 MYSQL中的检查点分为两类，即： sharp checkpoint：激烈检查点，要求尽快将所有脏页都刷到磁盘上，对I&#x2F;O资源的占有优先级高。 fuzzy checkpoint(默认的方式)：模糊检查点，会根据系统负载及脏页数量适当平衡，不要求立即将所有脏页写入磁盘，可能会刷新部分脏页。 触发时机： 数据库正常关闭时，即参数 innodb_fast_shutdown&#x3D;0(默认地)时，需要执行sharp checkpoint。 redo log发生切换时(即切换日志)或者redo log快满的时候进行fuzzy checkpoint。 master thread每隔1秒或10秒定期进行fuzzy checkpoint。 innodb保证有重做日志文件足够多的空闲页(防止覆盖)，如果发现不足，需要移除LRU链表末尾的page，如果这些page是脏页，那么也需要fuzzy checkpoint。 innodb buffer pool中脏页比超过限度(通常是最大大小的一半)时也会触发fuzzy checkpoint。 关于redo log的性能redo log日志写回即时redo log是被顺序写回磁盘的，但只要是关于磁盘的IO，其性能仍然会下降。学到这里，你应该发现数据库的性能与磁盘性能有很大关系。 InnoDB下存在一个参数：innodb_flush_log_at_trx_commi，可取值为: 0&#x2F;1&#x2F;2。 innodb_flush_log_at_trx_commit&#x3D;0，表示每隔一秒把log buffer刷到文件系统中(os buffer)去，并且调用文件系统的“flush”操作将缓存刷新到磁盘上去。也就是说一秒之前的日志都保存在日志缓冲区，也就是内存上，如果机器宕掉，可能丢失1秒的事务数据。 innodb_flush_log_at_trx_commit&#x3D;1(默认)，表示在每次事务提交的时候，都把log buffer刷到文件系统中(os buffer)去，并且调用文件系统的“flush”操作将缓存刷新到磁盘上去。这样的话，数据库对IO的要求就非常高了，如果底层的硬件提供的IOPS比较差，那么MySQL数据库的并发很快就会由于硬件IO的问题而无法提升。 innodb_flush_log_at_trx_commit&#x3D;2，表示在每次事务提交的时候会把log buffer刷到文件系统中去，但并不会立即刷写到磁盘。如果只是MySQL数据库挂掉了，由于文件系统没有问题，那么对应的事务数据并没有丢失。只有在数据库所在的主机操作系统损坏或者突然掉电的情况下，数据库的事务数据可能丢失1秒之类的事务数据。这样的好处，减少了事务数据丢失的概率，而对底层硬件的IO要求也没有那么高(log buffer写到文件系统中，一般只是从log buffer的内存转移的文件系统的内存缓存中，对底层IO没有压力)。 但要知道，虽然修改参数可能带来性能的提升，但却丢失了数据的一致性与持久性。 修改语句性能前面提到过，如果要修改信息，如果信息不再内存中，必须要先读入磁盘，再磁盘中修改，最后写回磁盘，需要两次磁盘IO和一次内存操作，效率低下。 为此INNODB引入一种称为写缓存的技术，这是针对非唯一普通索引字段的删除与更新语句的优化，这里我简单的介绍一下原理。 唯一索引总是需要检查索引冲突。 具体的，修改某个记录时(假设页不在内存中，如果在内存中不会触发写缓存)，将这个修改操作记录在缓存中，等到下次读取该数据时，再将其合并更新，并且写入缓存。 你可以发现这样减少了一次磁盘IO，因为读取、写入和写回合并了，原先需要三次磁盘 IO，现在只需要两次。 但这也不是必然的，如果下一次读取即将到来，那么这个技术毫无意义，还会浪费空间，因为修改时读入内存，当下一次读取很快到来时，数据还未被刷新，读取也会读内存，此时也会节省一次磁盘读取。 更多信息可以自行查阅。 undo log为什么需要undo logredo log是为了保证事务的持久性和一致性，那么undo log便是为了保证事务的原子性，是为了事务回滚而设计的。 例如假如你执行插入语句，那么undo log中可能就会对应的记录一条删除语句，这样当该事务回滚时，就会执行undo log中的删除语句使得事务好像根本就没有被执行，即事务回滚成功。 undo log是一种逻辑日志，因此只是将数据库逻辑地恢复到原来的样子。所有修改都被逻辑地取消了，但是数据结构和页本身在回滚之后可能大不相同。例如已经插入的数据只是被逻辑的删除，真实数据仍然存在。这与数据区本身执行SQL语句有关，数据库正常的删除语句也是一种逻辑删除，这是因为数据库要提供MVVC多版本功能，即在并发访问下，一个事务对当前行上锁修改，另一个事务可以读取之前的版本。undo log也是实现MVVC的底层机制。 前置知识：了解SQL语句执行过程我们主要说明DELETE和UPDATE语句，SELECT和INSERT并不会有什么歧异。 向我们之前所说的，现在大多数数据库都提供MVVC功能，即使一个事务执行了删除操作数据库也不会立即删除，而是判定是否有其他事务在引用该记录，然后再删除，这个过程由后台Purge线程执行。 delete操作不会直接删除，而是将delete对象打上delete flag，标记为删除，等待purge线程周期性的尝试回收。 update分为两种情况：update的列是否是主键列。 如果不是主键列，update是直接进行的。 如果是主键列，update分两部执行，先删除该行(也是逻辑删除)，再插入一行目标行。 你可能会奇怪为什么为什么更新操作会有两种情况，道理是很简单的，非主键列直接修改是可以做到的，但主键列是在B+树上的，直接修改会使得B+树数据结构不符合，直接修改难以操作，逻辑复杂，因此采用先删除再插入的方式。 undo log存储结构innodb存储引擎对undo log的管理采用段的方式，其存在于rollback segment之中，rollback segment称为回滚段，每个回滚段中有1024个undo log segment，在每个undo log segment中进行undo log页的申请，所有undo log页被组织成链表的形式。 同redo log类似，undo log页也是可被重用的，即一个页可能存在两个事务对应的undo log页。 undo log日志结构与redo log不同，redo log是基于物理页信息的，而undo log是基于SQL语句的，具体的，我们将undo log分为两种，即 insert undo log 和 update undo log。 insert undo log主要针对于insert操作，而update undo log针对于delete和update两种操作，其具体结构如下图所示： 这里只需要知晓undo log表达的是一种反语句，即执行插入则undo log代表删除，执行主键上更新，undo log代表删除新值与插入旧值。 每个undo log以链表的形式被组织在不同undo page中，next字段即代表下一个undo log，而undo page又以链表的形式被组织。每个undo log记录了对应的事务id、记录表空间、偏移等基础信息，例如我们知道事务id，从前往后遍历链表找到所属事务 id 的 log (链表从头部插入，后插入的在前，回滚时从前往后查找即可)，即可回滚事务，当然这样查找效率比较低，更好的办法是每个事务记录一个回滚指针。 何时刷新回磁盘？如果你仔细看了redo log的内容，你至少应该清楚修改后的数据页会被标记为脏页，等待后台线程回收，在这之前，该数据页会先被redo log所记录。 回到问题，undo log何时被刷新会磁盘？答案是随后台线程。每一条语句都会产生 undo log，undo log page 被当作脏页，就像普通脏页那样被后台线程定期刷新回磁盘。 这里有个点就是undo log也需要redo log以保证其正确性。 在 STEAL 模式下，数据库允许检查点将未提交的事务页刷盘，因此在恢复时，数据库需要额外的操作： 检查所有未完成事务，从 undo log page 中取 undo log，对事务回滚。 事务回滚时，在内存中会回滚那些内存页，并重新标识这些页为脏页，并产生 redo log。 事务提交时事务提交后，undo log不能立即被删除，这是因为数据库要提供MVVC多版本控制，一些事务线程会通过undo log来推断出上一个版本，InnoDB会将undo log放入删除链表(也叫历史链表)中(先提交的undo log总是在尾端)，等待purge线程真正的删除它们。 例如下图删除链表，trx1表示事务1产生的undo log，它是最先提交的，因此在尾端。 Purge操作Purge周期的清理记录以及undo log，清理记录只需要检查删除标记位即可，清理undo log要稍微麻烦一点。 Purge线程必须保证一个undo log没有任何事务引用它才能删除这个日志，引用关系在undo page中对应的undo log中存在记录，因此可以通过查找undo page中的undo log查看对应是否存在引用。历史链表中并不包含此信息，仅仅包含指向undo page中对应log的指针，这样做是为了节省内存。 如图所示，在undo page1中，其中trx5表示正在被其他事务引用： 完整的图如下图所示： 你可能会想：从尾到头遍历删除链表，查找对应undo page中的信息，没有引用则删除。 这样做没有任何问题，但效率是非常低下的，要明白删除链表中的顺序其实并不是实际事务log存储的顺序，真正的undo log在事务未提交前就被写入undo page，而在提交后才被写入链表，这就导致了链表中的顺序实际上并不是undo page中log存放的数据，由于undo log可能被刷新回磁盘，如果根据链表遍历可能会产生大量随机读写，效率低效，InnoDB采用先读链表，在顺序读page的方式实现。 具体的，先读链表尾部trx1，在undo page1中查找，发现没有引用则删除trx1；此后继续在undo page1中顺序查找，下一个是trx3，删除trx3；继续顺序查找，接下来是trx5，发现存在引用，则放弃查找；回到链表尾部，此时尾部为trx2，则到undo page2中顺序查找…… 这样做会产生大量顺序读写，提高效率。 何时回滚？如何回滚？当程序员手动调用回滚时此时会回滚；或当事务未提交而发生错误时，此时也会回滚以保证原子性。 回滚时，根据事务 id 和回滚指针查找 undo log page 中的 undo log lists，顺序的执行undo log中的反语句以回滚信息。 MVCCMVCC，即多版本并发控制，简单地说就是读取时如果该行被写锁锁定，则可以读取之前的版本，即快照读，我们的讨论基于 RR 隔离级别。 MYSQL 的 MVCC 也是依赖于 undolog 实现的，具体的，每个行记录都有一些隐式的字段，例如： db_trx_id，当前操作该记录的事务ID。 db_roll_pointer，指向当前记录的 undolog page。 删除字段、隐式自增键等。 当开启快照读时，对于每个 SELECT 语句，INNODB 会生成一个 Read View（读视图），这个视图用以判断其他事务对当前事务的可见性，它通常有如下几个属性： trx_ids: 当前系统活跃 (即已开始但未提交) 事务版本号集合。 low_limit_id: 创建当前 read view 时 “当前系统最大事务 ID + 1”，注意是系统最大事务而不是活跃事务中最大事务。 up_limit_id: 创建当前 read view 时 “系统正处于活跃事务最小 ID。 creator_trx_id: 创建当前read view的事务版本号。 举个例子我开启的事务 ID 是 8，则 Read View 可能是：trx_ids: [4, 6, 8]，low_limit_id：25，up_limit_id：4，creator_trx_id：8，这表示当前正在进行的事务 ID 有 [4, 6, 8]，整个系统中最大的事务 ID 是 25 - 1 &#x3D; 24，这说明这个事务已经完成了，活跃事务的最小 ID 是 4。 知道这个有什么用呢？我们可以用来分析其他事务对当前事务是否可见，设当前事务 ID 为 MyId，正打算读取的行上的记录 ID 是 OtherId，如果： OtherId &lt; up_limit_id。如果其他事务 ID 小于 up_limit_id，说明这个事务肯定提交了，提交的事务对所有事务可见。 OtherId &#x3D;&#x3D; creator_trx_id。否则，如果这个事务 ID 就是自己 ID，则自己做的肯定可见，例如在一个事务中先更新再读取。 OtherId &gt;&#x3D; low_limit_id。如果其他事务 ID 大于等于系统最大事务 ID，说明这个事务是在快照创建之后生产的，即这个事务应该晚于当前事务，这种情况下肯定不可见。 否则，遍历 trx_ids，判断这个事务是否存在于 trx_ids 中，如果存在说明事务未提交，未提交的事务肯定不可见，否则会产生脏读；如果不存在 trx_ids 中，说明这个事务已经 commit 了，并且肯定是先于当前事务的(事务产生快照时活跃列表没有它)，这种情况下可以认为可见， 知道了可见与不可见有啥用？ 如果当前行标识的事务 ID 对当前事务不可见，则必须要通过 db_roll_pointer 找到 undolog page 进行回滚，找到上一个版本的记录，然后继续判断可不可见，这就是所谓的 MVVC。 举个例子，例如 A 先开启事务，ID 为 11，准备读取行记录 X，但还没有执行。 此时 B 开启事务，ID 为 12，修改行记录 X，B 顺利修改，这个时候 X 上的行记录隐式字段的事务ID被设置为 12，注意 B 事务未提交，仍在活跃。 A 终于开始准备读取 X 了，A 生成一个 ReadView，假设为：trx_ids: [11, 12]，low_limit_id：13，up_limit_id：11，creator_trx_id：8。 此时 A 发现 X 的事务 ID 是 12，11 &lt;&#x3D; 12 &lt; 13，无法判断，则继续遍历 trx_ids，最终找到了 12，则 A 认为有其他事务正在锁定当前记录 X，则通过 X 回滚指针回滚读取上一个版本，递归做相同判断。 读已提交和可重复读的区别在于：读以提交每次读取时总是会生成新的 ReadView，而可重复读只会在第一次读取时生成 ReadView。 bing log为什么需要bing log？binlog是一个二进制格式的文件，用于记录用户对数据库更新的SQL语句信息，更改数据库表和更改内容的SQL语句都会记录到binlog里。 bing log是一种逻辑日志，记录着SQL操作。例如执行插入语句，bing log可能会记录插入一条 XXX 记录;bing log不会记录查询操作，事实上undo和redo也不会记录。 那么bing log有什么用呢？不是有了 redo log 和 undo log吗？ undo log记录的是反语句，主要为了实现回滚操作，事务提交后undo log就可能会被删除。redo log的作用是为了保证内存中的数据的持久性，当内存中的脏页被刷新，redo log也就失效，会被覆盖写。redo 和 undo 都有一个问题，即它们都是短暂存在的。 而bing log记录着所有执行操作，并持久性的存在于磁盘中。bing log 主要用于查看数据库的历史变更记录、增量备份(可以比较相对于上一次备份增加那些内容，仅备份这些增加的内容)、时间回溯(恢复到指定时间点的状态)或数据库复制。 bing log在站在MYSQL服务层上的，其负责整个MYSQL安全备份与恢复，针对于所有的引擎。而redo和undo仅仅知识InnoDB提供的、针对于事务的日志，是完全不同的概念。 事务二段式提交(内部)MYSQL默认开启bing log，也建议开启bing log，不过当开启bing log后，在INNODB引擎下就会存在一些问题，即bing log和redo log不一致的问题。 举个简单的例子，在原来的状态中，事务提交后redo log被刷新回磁盘，此时bing log还未写入磁盘，数据库突然宕机，恢复时，由于redo log写入，数据不会有任何问题，但原来的bing log还未被写入！此时数据库状态与bing log不一致，我们违反了数据库的一致性！ 必须在bing log也被正确写回后才算事务提交成功。bing log写回失败必须要做某些处理！ 二段式提交就是为了解决redo log和bing log写回不一致的问题。 在二段式提交中，分为两个阶段： prepare过程 commit过程 当事务提交时，会立即陷入第一个阶段，即prepare阶段。 prepare过程： 设置该事务对应undo state&#x3D;TRX_UNDO_PREPARED，表示正式进入prepare过程。 将redo日志刷新回磁盘，修改内存数据页。 而后会陷入第二阶段。 commit过程： 将事务产生的binlog写回磁盘，当这个动作被完成时，事务被确认已提交，即使后面的动作未完成。 将undo写入删除链表中，等待purge删除。 考虑问题，当redo log写回磁盘失败时，此时数据仍未变脏，事务ACID特性未被破坏，该事务执行失败，回到最初的样子；当bing log写回磁盘失败时，数据页已变脏，必须借助undo log回滚事务，当undo log丢失时，根据redo log重建undo log。 这样，我们便解决了一系列的问题，事务的ACD特性(本文章为设计隔离性)得到保证。 深入数据一致性：Double Write 技术如果你学过文件系统，你就会知道上述三大 log 其实并不足以保证一致性，在文件系统中，一次文件修改不仅需要修改文件内容，还需要修改 inode 中的文件元数据，而修改元数据和修改文件内容也必须要是原子的。 在 Mysql 中也会存在写入不完整的问题，由于内存页为 16k，而磁盘页通常是 4k，磁盘能保证的原子写入只有一个扇区大小 512b，这就会导致一些数据不一致问题，并且是 redo log 无法解决的问题。 我们提到，一个内存页存在许多元数据，例如 LSN 就是其中之一，我们以 LSN 举个例子，例如当我们将内存页刷回的时候，一个内存页会被分成 4 部分刷回物理磁盘，假设此时带有 LSN 那部分页成功刷回，而其他页因为因为突然宕机而丢失了，这个时候会发生什么情况呢？ Innodb 开始进行数据恢复，但是他发现这个页的 LSN 和 redo log 是一致的，于是确信这个页是正常的……. 当然你可能会想，那我在页的 tail 设置个合法位，检测一下合不合法不就好了？ 的确可以，但是页不合法该怎么办呢？重做是不行的，因为重做日志并没有包含页的元数据，如果页的元数据丢失了，重做日志是无法解决问题的。 Mysql 中页的尾部有个 File Trialer 字段，用以检测是否合法 所以针对内存页的写入，需要引入双写技术，简单来说就是先搞个备份。 在刷新脏页时，需要经历如下步骤： 将脏页 memcpy 追加到 Double Write Buffer 中，Double Write Buffer 总大小通常是 2MB，即 16 个内存页。 Double Write Buffer 会以 1MB 为单位的顺序写入到物理磁盘共享表空间中，一旦写入完成，立即调用 fsnyc 离散的同步这 1MB 数据到磁盘中。 这样一旦数据库恢复时检测到物理磁盘中某个页不合法时，可以在共享表空间中查看页的副本，如果页的副本是合法的，直接覆盖即可。当然 Double Write 的写入也可能会出现问题，如果页的副本是不合法的，则会丢弃页的副本，但是这里磁盘页肯定是合法的，因为 DoubleWrite 数据出问题，则数据肯定未能同步磁盘，磁盘中的页未被修改，仍然是之前的旧页，这个时候运用 redo log 恢复即可。 前文也说到，重做日志块被设计成 512 kb，从而保证重做日志块的写入肯定是原子的，所以无需担心重做日志的合法性。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"分布式系统中的分区问题","slug":"分布式系统中的分区问题","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.987Z","comments":true,"path":"post/336a.html","link":"","permalink":"http://example.com/post/336a.html","excerpt":"","text":"分布式系统中的分区什么是分区？ 对于非常大的数据集，或非常高的吞吐量，仅仅进行复制是不够的：我们需要将数据进行分区，也称为分片。 简单而言，将一个大的数据集分为多个小的数据集，将这些小的数据集散布在更多的节点上，每一个小的数据集都作为一个独立的数据库进行处理，使得系统压力均匀的散布在多个节点上。 例如将数据库中的一张表按照主键范围或其他方式分割成多张表，这就是分区。 分区的问题？ 如何将请求导向正确的分区？ 如何避免偏斜，即避免将大量数据集中导向同一个分区。 当节点增加或减少时，如何优雅的调整分区在节点上的分布。 分区的优点？ 分区主要是为了可伸缩性，大数据集可以分布在多个磁盘上，并且查询负载可以分布在多个处理器上，因此减少了单个节点的压力，增加了整个系统的吞吐量。 大型、复杂的查询可能会跨越多个节点并行处理，加快速度。 分区与复制分区通常与复制结合使用，使得每个分区的副本存储在多个节点上，即使每条记录属于同一个分区，但是这个分区仍有可以分布在不同的节点上，提高容错。 节点通常被认为是一台主机，一个节点可以有多个分区，如果使用主从复制模型，每个分区领导者被分配给一个节点，追随者被分配个其他节点，每个节点可能是某些分区的领导者，同时是其他分区的追随者。 键值数据的分区分区目标是将数据和查询负载均匀分布在各个节点上。 如果分区不公平，例如大量数据集中导向同一个分区，这被称为偏斜（skew），数据偏斜的存在使分区效率下降很多。 在极端的情况下，所有的负载可能压在一个分区上，其余所有节点都是空闲的，瓶颈落在这一个繁忙的节点上。 不均衡导致的高负载的分区被称为热点（hot spot）。 怎么避免热点？避免热点最简单的方法是将记录随机分配给节点，但这缺点是读特定的值时，不知道在哪个节点上，必须并行查所有的节点。 以下我们来探讨一下常见的分区方式。 根据键的范围分区一种分区的方法是为每个分区指定一块连续的键范围（从最小值到最大值），类似纸质的百科全书、类似于数据库主键切分。 根据键的范围分区优点是查询稳定高效，由于所有分区按照键排序，无论是定值查询或者是范围查询，都可以在$log(N)$的时间内定位，无须遍历整个分区（前提是查询请求必须是主键）。 缺点也是很明显的，由于不是随机分布的，分区可能无法很好的均匀分布在各个节点中，这就可能造成偏斜与热点问题。例如某种数据库是按照时间为主键(以天为单位)分区的，那么当天产生的请求可能会全部路由到同一个分区中。 根据键的散列分区另一种分区方式是根据键的散列分区，目前很多分布式数据存储使用散列函数来分区。 一个好的散列函数可以将偏斜的数据均匀分布。 根据键的散列分区优点是擅长在分区之间公平地分配键，并且定值查询非常高效。但是要注意，散列分区可以有效的消除数据偏斜与热点问题，但无法完全避免，相同的键仍然会产生相同的哈希，在极端情况下，所有的读写操作都是针对同一个键的，所有的请求都会被路由到同一个分区。 针对这种极端情况的解决办法是在主键后面添加一位随机数。 缺点是失去了高效执行范围查询的能力，范围查询要么不支持，要么需要查询所有分区。 分区与次级索引上述分区都是主键的分区，如何在分区引入二级索引？ 基于文档的二级索引进行分区在这种方式下，每个分区自己内部维护自己的二级索引，例如下图中 color 为次级索引： 这样做的优点是应对次级索引变化简单，每个分区各自维护自己的二级索引，在本地维护速度会相当快。 缺点是查询时必须查询所有的分区，并且要进行去重合并，这会浪费大量的时间。 事实上由于二级索引很少用到，为维持高效性，目前大多数解决方案都是基于文档的方式。 基于关键词的二级索引进行分区在这种情况下，我们维护一个全局的二级索引表，这张全局的表也应该采用分区的方式存储，这种分区叫做关键词分区，查询或修改二级索引都需要额外导向全局二级索引表， 这样做的优点是查询只需查一次全局的二级索引表，无须查询所有分区。 缺点是维护代价较高，每次维护都需要一次额外的对二级索引表的网络 IO，在网络拥挤时代价显得更为严重。 分区再平衡随着时间的推移，数据库会有各种变化： 查询吞吐量增加，所以您想要添加更多的 CPU 来处理负载。 数据集大小增加，所以您想添加更多的磁盘和 RAM 来存储它。 机器出现故障，其他机器需要接管故障机器的责任。 所有这些更改增加或移除一个或多个节点，而节点变化会导致分区拓扑发生变化，数据和请求可能会从一个节点移动到另一个节点。 将分区（负载）从集群中的一个节点向另一个节点移动的过程称为 再平衡（rebalancing）。 同样的，将一个请求从一个节点导向另一个节点的过程也成为 再平衡（rebalancing）。 无论使用哪种分区方案，再平衡通常都要满足一些最低要求： 再平衡之后，负载（数据存储，读取和写入请求）应该在集群中的节点之间公平地共享。 再平衡发生时，数据库应该继续接受读取和写入。 节点之间只移动必须的数据，以便快速再平衡，并减少网络和磁盘I&#x2F;O负载。 反面教材：hash mod N如果使用基于散列的分区方法，并且分区与节点的映射关系为 $hash \\ mod \\ N, N&#x3D;节点总数$，那么一旦 N 发生变化，绝大多数分区可能都会发生变化。 考虑以下例子： 3个机器节点，10个数据 的哈希值分别为1,2,3,4,…,10。使用的哈希函数为：$m&#x3D;hash(o) \\ mod \\ 3$ 机器0 上保存的数据有：3，6，9 机器1 上保存的数据有：1，4，7，10 机器2 上保存的数据有：2，5，8 当增加一台机器后，此时n &#x3D; 4，使用的哈希函数为：$m&#x3D;hash(o) \\ mod \\ 4$，各个机器上存储的数据分别为： 机器0 上保存的数据有：4，8 机器1 上保存的数据有：1，5，9 机器2 上保存的数据有：2，6，10 机器3 上保存的数据有：3，7 只有数据1和数据2没有移动，所以当集群中数据量很大时，采用这种哈希函数，在节点数量动态变化的情况下会造成大量的数据迁移，导致网络通信压力的剧增，严重情况，还可能导致数据库宕机。 一致性哈希算法所以我们需要一种哈希算法使得再平衡发生时，不会产生大量的数据迁移，一致性哈希算法是一种解决方案，一致性哈希算法并不是一个具体的哈希算法，而是一种抽象的描述。 在上述简单哈希中，我们仅仅只对数据进行哈希，然后模 N 得到节点编号。在一致性哈希算法中，我们不仅对数据进行哈希，还会对节点进行哈希，并且会将哈希值抽象看作在一个环上。 首先对数据对象进行哈希，假设哈希的结果 $0&lt;&#x3D;hash&lt;&#x3D;Integer.MAX_VALUE$，将结果抽象的看成一个环。 这里采用哈希算法，o1 映射到 m1，o2 映射到 m2，以此类推。 现在，我们可以为节点也分配一个唯一的主键，通过该键同样进行哈希映射，假设现在节点 c1 映射到 t1 上，节点 c2 映射到 t2 上，以此类推。 现在我们如何判定数据对象属于哪一个节点呢？在一致性哈希算法中，数据对象属于该对象在环中所遇到的下一个节点（通常为顺时针），例如上述 o1 属于 c3，o4 与 o3 属于 c2，o2 属于 m2。 现在如果新增或删除一个节点，只会影响最多环上两个节点之间的数据，例如删除节点 c1 时，只会影响 c1 和 c2 之间的节点，现在 o2 被重定位至 c3 中。 但即使是采用一致性哈希算法，也无法避免数据偏斜问题，极端情况下，所有数据对象都被哈希聚集到环上的一端，所有的对象都被导向同一个分区。 简单的解决方案是采用更好的哈希算法，让数据均匀分布。 但这可能无法满足，另一种解决的方案是加入更多的节点，让节点在环上均匀分布，如果没有足够多的节点，我们可以让一个节点在环上存在多个哈希值，这种方案被称为虚拟节点。 但是要注意，虚拟节点并不是越多越好的，当虚拟节点较多时，新增一个物理节点相当于新增了多个节点，可能仍然会导致大量数据进行迁移，得不偿失。 某些时候，人为规定节点对应哈希，使节点在环上均匀分布可能是更好的选择。 对于请求而言，简单的方法是在环上进行二分查找，找到第一个 hash 比当前数据 hash 大的节点，然后导向它，这非常高效。 另一种办法是利用路由表或是服务注册功能，以 O1 的时间进行查找。 多一层抽象：分区 - 节点 多对一一致性哈希算法是一种很优秀的解决方案，但实现较为复杂，这里还有一种简单高效的解决方案：创建比节点更多的分区，并为每个节点分配多个分区，即额外加一层抽象。 注意：在之前的分析中，为了简便，我们认为分区 - 节点 是 1 对 1 的，所以我们之前淡化了分区与节点的关系（但绝不是必须的，分区 - 节点 仍然可以多对一，不过是多加层抽象罢了）。 在这里，分区 - 节点是多对一的，因此这里的哈希是指 分区 - 节点 之间的哈希，而不是 数据 - 分区 之间的哈希，请务必不要混淆。 哈希算法仍然是取模，例如假设本来具有 4 个节点，$m &#x3D; hash \\ mod \\ 4$，现在新增一个节点 Node4，哈希算法变为 $m &#x3D; hash \\ mod \\ 5$，那么只需要将 $hash \\ mod \\ 5 &#x3D; 4$ 的分区分给 Node4 即可。这样只有 4 个数据分区需要移动。 这种方法的优点是简单高效，只有部分分区在节点中移动，键所在的分区也不会改变，唯一改变的是分区所在的节点。 Riak ，Elasticsearch ，Couchbase 和 Voldemort 中使用了这种再平衡的方法。 缺点是，必须要遍历所有的分区，计算散列，并将其分配给新节点。 请求路由服务发现(service discovery) 确定客户发出请求时，知道要连接哪个节点进行读取。 概括来说，这个问题有几种不同的方案（如图6-7所示）: 允许客户联系任何节点（例如，通过循环策略的负载均衡（Round-Robin Load Balancer））。如果该节点恰巧拥有请求的分区，则它可以直接处理该请求；否则，它将请求转发到适当的节点，接收回复并传递给客户端。 首先将所有来自客户端的请求发送到路由层，它决定了应该处理请求的节点，并相应地转发。此路由层本身不处理任何请求；它仅负责分区的负载均衡。 要求客户端知道分区和节点的分配。在这种情况下，客户端可以直接连接到适当的节点，而不需要任何中介。 关键问题： 如何了解分区-节点之间的分配关系变化？ 解决方法：所有参与者达成共识。 分布式系统中有达成共识的协议，但很难被正确实现。 常见实现 ZooKeeper： 依赖于一个独立的协调服务，比如ZooKeeper来跟踪集群元数据 每个节点在ZooKeeper中注册自己，ZooKeeper维护分区到节点的可靠映射。 其他参与者（如路由层或分区感知客户端）可以在ZooKeeper中订阅此信息。 只要分区分配发生了改变，或者集群中添加或删除了一个节点，ZooKeeper就会通知路由层使路由信息保持最新状态。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"分布式系统中的复制问题","slug":"分布式系统中的复制问题","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.987Z","comments":true,"path":"post/b542.html","link":"","permalink":"http://example.com/post/b542.html","excerpt":"","text":"分布式系统中的复制主从复制 存储数据库副本的每个节点称为 副本（replica）。 多副本的问题：如何确保数据都落在了所有的副本上。 每次对数据库的写入都要传播到所有副本上，否则副本就会有不一样的数据。 常见的解决方案：基于领导者的复制（主从复制）。 主从复制工作原理 副本之一被指定为领导者（leader，也被称作主库） 客户端写数据时，要把请求发送给领导者； 领导者把新输入写入本地存储。 其他副本被称为追随者（followers，也被称作只读副本、从库、热备） 每当领导者将新数据写入本地存储时，他会把数据变更发送给所有的追随者，称之为复制日志或变更。 每个追随者从领导者拉取日志，并相应更新其本地数据库副本，方法是按照领导者处理的相同顺序应用所有写入。 当客户想要从数据库中读取数据时，它可以向领导者或追随者查询。 但只有领导者才能接受写操作，从客户端的角度来看从库都是只读的。 新增从库有时会增加一个新的从库，通常会经历如下步骤： 在某个时刻获取主库的一致性快照，大多数数据库都具有这个功能，因为它是备份必需的。 将快照复制到新的从库节点。 从库连接到主库，拉取从快照开始到快照复制完成时所发生的所有数据变更。这要求快照与主库复制日志中的位置精确关联。该位置有不同的名称：例如，PostgreSQL将其称为 日志序列号（log sequence number, LSN），MySQL将其称为 二进制日志坐标（binlog coordinates）。 当从库处理完快照之后积压的数据变更，我们说它 赶上（caught up） 了主库。现在它可以继续处理主库产生的数据变化了。 处理节点宕机我们的目标：即使个别节点失效，也要能保持整个系统运行，并尽可能控制节点停机带来的影响，即保障分区容错性，即 CAP 理论中的 “P”。 从库失效：追赶恢复 从库可以从日志知道，在发生故障前处理的最后一个事务。 所以从库可以连接到主库，并拉取断开连接后的所有数据变更。 应用完成所有变更之后，它就赶上了主库，继续接收数据变更流。 主库失效：故障切换 故障切换：需要把一个从库提升为新的主库，重新配置客户端，其他从库需要开始拉取来自新主库的变更。 故障切换可以手动或者自动进行。 故障切换是个经典的问题，例如，可能会有如下场景发生： 主库接收到了新的数据，但主库只更新了少量的从库，然后主库宕机，现在只有少量节点是最新的数据，而绝大多数节点都是陈旧的数据，现在如何选取新的主库？是相信民主，选择多数节点的一方，还是相信科学，选择较新数据的一方？ 可能主库短暂的断开连接，而此时从库认为主库宕机，选举出新的主库，这是旧的主库重新恢复连接，此时可能会出现两个主库的情况，这种情况被称为 “脑裂”。 这是经典的一致性与共识问题，现在较为成熟并且广被接受的解决办法是 Raft 算法，我们会好好学习学习它的。 复制日志的实现基于主从库的复制，底层工作有几种不同的复制方式。 基于语句的复制在最简单的情况下，主库记录下它执行的每个写入请求（语句（statement））并将该语句日志发送给其从库，从库执行语句而 “复制” 主库。 问题： 任何调用 非确定性函数（nondeterministic） 的语句，可能会在每个副本上生成不同的值。比如 NOW(), RAND()。 如果语句使用了自增列（auto increment），或者依赖于数据库中的现有数据（例如，UPDATE … WHERE &lt;某些条件&gt;），则必须在每个副本上按照完全相同的顺序执行它们，否则可能会产生不同的效果。影响并发。 有副作用的语句（例如，触发器，存储过程，用户定义的函数）可能会在每个副本上产生不同的副作用，除非副作用是绝对确定的。 传输预写式日志（WAL）写操作通常追加到日志中： 对于日志结构存储引擎（SSTables 和 LSM 树），日志是主要存储位置。日志段在后台压缩，并进行垃圾回收。 覆盖单个磁盘块的 B 树，每次修改会先写入预写式日志（Write Ahead Log, WAL），以便崩溃后索引可以恢复到一个一致的状态。 所以，日志都是包含所有数据库写入的仅追加字节序列。可以使用完全相同的日志在另一个节点上构建副本：主库把日志发送给从库。 PostgreSQL和Oracle等使用这种复制方法。 缺点： 复制与存储引擎紧密耦合。 不可能使主库和从库上运行不同版本的数据库软件。 运维时如果升级软件版本，有可能会要求停机。 逻辑日志复制（基于行）采用逻辑日志，可以把复制与存储逻辑分离，例如 Mysql 中的 bing-log。 关系型数据库通常以行作为粒度描述数据库写入的记录序列： 对于插入的行，日志包含所有列的新值； 对于删除的行，日志包含足够的信息来唯一标识已删除的行。通常是主键，或者所有列的旧值。 对于更新的行，日志包含足够的信息来唯一标识更新的行，以及所有列（至少是更新列）的新值。 优点： 逻辑日志与存储引擎分离，方便向后兼容。可以让领导者和跟随者运行不同版本的数据库软件。 对于外部应用，逻辑日志也更容易解析。比如复制到数据仓库，或者自定义索引和缓存。被称为数据变更捕获。 基于触发器的复制 上述复制都是数据库自己实现的。也可以自定义复制方法：数据库提供了触发器和存储过程。 允许数据库变更时，自动执行应用的程序代码。 开销更大，更容易出错。但更灵活。 复制延迟问题 主从异步同步会有延迟：导致同时对主库和从库的查询，结果可能不同。 因为从库会赶上主库，所以上述效应被称为「最终一致性」。 复制延迟可能超过几秒或者几分钟，下文是 3 个经典的例子。 读己之写如果用户把数据提交到了主库，但是主从有延迟，用户马上看数据的时候请求的从库，会感觉到数据丢失。 此时需要「读写一致性」，也成为读己之写一致性。 解决技术： 读用户可能已经修改过的内容时，都从主库读；比如读个人资料都从主库读，读别人的资料可以读从库。 客户端记住最近一次写入的版本号（或时间戳），客户端查询时，连同版本号（或时间戳）一起发送，从库提供查询时，必须保证对应数据的版本必须大于等于客户提供的版本；否则从另外的从库读，或者等待从库追赶上来。 如果副本在多个数据中心，则比较复杂。任何需要从领导者提供服务的请求，都必须路由到包含主库的数据中心。 单调读用户可能会遇到 时光倒流。 第一次请求到从库看到了评论，第二次请求到另外一个从库发现评论消失。 单调读保证了这种异常不会发生。 方法： 确保每个用户总是从同一副本来读取。比如基于用户 ID 的散列来选择副本，而不是随机选。但是如果该副本失败，则可能需要路由到另一个副本。 一致前缀读一系列事件可能出现前后顺序不一致问题。比如回答可能在提问之前发生。 这是分区（分片）数据库或多主数据库中的一个特殊问题：不同分区之间独立，不存在全局写入顺序。 需要「一致前缀读」。 解决方法： 任何因果相关的写入都写入相同的分区。 复制延迟的解决方案 可以使用事务。事务（transaction） 存在的原因：数据库通过事务提供强大的保证，所以应用程序可以更加简单。通过使用事务，只有当主库写入了所有从库，请求才算完成，但这代价太高了，因此复制延迟本质几乎没办法解决，只能通过不同的解决方案去解决不同的场景，例如上诉三种经典问题。 单节点事务存在了很长时间，但是分布式数据库中，许多系统放弃了事务，因为事务的代价太高。 多主复制 单个领导者的复制架构是个常见的方法，但也有其他架构。 基于领导者复制的主要缺点：只有一个主库，所有的写入都要通过它。 多个领导者的复制：允许多个节点接受写入，复制仍然是转发给所有其他节点。每个领导者也是其他领导者的追随者。 多主复制的应用场景 单个数据中心内部使用多个主库没有太大意义，通常多主复制用于多个数据中心中。 多个数据中心 多领导配置允许每个数据中心都有自己的主库。 每个数据中心内部使用常规的主从复制； 数据中心之间，每个数据中心的主库都会将其更改复制到其他数据中心的主库中。 运维多个数据中心时，单主和多主的适应情况比较： 性能 单主配置中，每个写入都得穿过互联网，进入主库所在的数据中心。会增大写入时间。 多主配置中，每个写操作都可以在本地数据中心进行处理，与其他数据中心异步复制。感觉到性能更好。 容忍数据中心停机 单主配置中，如果主库所在的数据中心发生故障，必须让另一个数据中心的追随者成为主领导者。 多主配置中，每个数据中心都可以独立于其他数据中心继续运行。若发生故障的数据中心归队，复制会自动赶上。 容忍网络问题 数据中心之间的网络需要通过公共互联网，不如数据中心之内的本地网络可靠。 单主配置对网络连接问题非常敏感，因为写是同步的。 异步复制的多主配置更好地承受网络问题。 多主复制的缺点 两个数据中心可能会修改相同的内容，写冲突必须解决。 多主复制比较危险，应尽可能避免。 需要离线操作的客户端多主复制的另一适用场景：应用程序在断网后仍然需要继续工作。 在这种情况下，每个设备都有一个充当领导者的本地数据库（它接受写请求），并且在所有设备上的日历副本之间同步时，存在异步的多主复制过程。复制延迟可能是几小时甚至几天，具体取决于何时可以访问互联网。 每个设备相当于一个“数据中心” 协同编辑协作式编辑不能视为数据库复制问题，但是与离线编辑有许多相似。 一个用户编辑文档时，所做的更改将立即应用到其本地副本（web 或者客户端），并异步复制到服务器和编辑同一文档的任何其他用户。 如果想要不发生编辑冲突，则应用程序需要先将文档锁定，然后用户才能进行编辑；如果另一用户想编辑，必须等待第一个用户提交修改并释放锁定。这种协作模式相当于主从复制模型下在主节点上执行事务操作。 但是，为了加速写作，可编辑的粒度需要非常小（例如单个按键，甚至全程无锁）。 这会面临所有多主复制都存在的挑战，即如何解决写入冲突。 处理写入冲突多领导者复制的最大问题是可能发生写冲突，因此需要解决冲突。 假如两个用户同时修改标题： 在这种情况中，两个标题被分别写入不同数据中心，在这一刻数据写入是成功的，但当领导者之间的复制开始时，它们就会检测到冲突，这种冲突并不是立即被检测出来的，而是具有一定的延迟，这是多主复制中的特殊的写入冲突。 收敛至一致的状态在多主配置中，正如我们所讲，冲突检测是具有延迟性的，当检测到冲突时，请求已经完成，冲突无法避免。因此数据库只能以收敛（convergent） 的方式解决冲突，即选取一个最终的值，使得所有副本上值都相同。 实现冲突合并解决有多种途径： 给每个写入一个唯一的ID（例如，一个时间戳，一个长的随机数，一个UUID或者一个键和值的哈希），挑选最高ID的写入作为胜利者，并丢弃其他写入。 为每个副本（数据中心、或领导者）分配一个唯一的ID，ID 编号更高的写入具有更高的优先级。 上述两种方式都意味着数据丢失，我们可以使用某种方式将这些值合并在一起，例如，按字母顺序排序，然后连接它们。 用一种可保留所有信息的显式数据结构来记录冲突，并编写解决冲突的应用程序代码（也许通过提示用户的方式）。 多主复制拓扑复制拓扑（replication topology）描述写入从一个节点传播到另一个节点的通信路径。 只有两个领导者时，只有一个合理的拓扑：互相写入。 当有两个以上的领导，拓扑很多样： 环形拓扑。实现简单，但问题也多，例如容错性不高，会出现重复复制问题。防止无限复制循环的办法是：每个节点都有唯一的标识符，在复制日志中，每个写入都标记了所有已经过的节点的标识符。 星形拓扑。实现相对简单，不会出现重复复制问题，但容错性也不高。 全部到全部拓扑。实现复杂，容错性高，但消息可能会混乱。例如，网络问题导致消息顺序错乱： 在这里写入时添加时间戳是不够的的。 解决办法是下文将提到的版本向量技术。 无主复制 一些数据库放弃主库的概念，允许任何副本直接接收来自客户端的写入。 一些无主配置中，客户端直接写入到几个副本中； 另一些情况下，一个协调者节点代表客户端进行写入。 当节点故障时写入数据库无主复制中，故障切换不存在。 这里存在一个问题：如果一个副本故障或下线，重启后提供的数据是落后的。 解决办法是：客户端同时请求多个副本，根据版本号确定最新值。 读修复和反熵这里的问题是：故障节点重新上线，怎么追上错过的写入？ 读修复（Read repair） 客户端检测到陈旧的值，客户端将新值写回到该副本。 适合读频繁的值。 反熵过程（Anti-entropy process） 数据库的后台进程，不断查找副本之间的数据差异，把缺少的数据进行复制。 反熵过程不会以任何特定的顺序复制写入，复制数据之前可能有显著的延迟。 读写的法定人数在上面讲到，为使用户读取到的数据为最新版本，用户必须读取多个副本以确定最新值，问题是，读取多少个比较合适呢？同样的，客户写入数据时，写入多少个副本合适呢？ 我们将读取的副本数设为 r，写入的副本数设为 w，那么如果有 n 个副本，每个写入必须由 w 节点确认才能被认为是成功的，并且我们必须至少为每个读取查询 r 个节点。 计算公式：$$w+r&gt;n$$w 与 r 必须满足此公式，为验证此公式的正确性，假设客户像 w 个副本写入最新值，那么目前有 w 个副本是最新值，n - w 个副本是陈旧值。 现在客户请求数据，客户必须请求至少 r 个副本的数据，根据公式，$ r &gt; n - w $，而所有副本中只有 n - w 个陈旧副本，也就是说用户必定能获取到最新的数据。当用户获取最新数据后，可以采取读修复更新陈旧的副本。 法定人数一致性的局限性但是，即使在 $w + r&gt; n$ 的情况下，也可能存在返回陈旧值的边缘情况。 两个写入同时发生，不清楚哪一个先发生，此时副本可能会误选陈旧值。 不要把 w 和 r 当做绝对的保证，应该看做是概率，强有力的保证需要事务和共识。 另外，w 与 r 的选取也必须要慎重考虑，如果 w 过大，那么客户的写入必须要等待大量副本的成功响应；r 过大，客户的读取必须同时读取大量的副本，如果此时某个副本发送故障。而如果 $w + r &#x3D; n + 1$，如果任意一个副本故障都可能无法保证最终一致性。 检测并发写入无主复制，允许多个客户端同时写入相同的 key，会发生写冲突，这与多主复制中的写冲突不同，多主复制中的写冲突检测是有延迟的，这里说的并发写入通常可以立即检测出冲突，虽然冲突的类型不同，但解决的思想却是类似的。 如果两个客户在某一时刻(不一定非要是同时发生的)对一个 key 写入不同的值，由于网络，写入副本的值是不确定的，如下图所示： 最后写入胜利（丢弃并发写入）只需要存储最 “最近” 的值，允许 “更旧” 的值被覆盖和抛弃。 需要有一种明确的方式来确定哪个写是“最近的”，并且每个写入最终都被复制到每个副本，那么复制最终会收敛到相同的值。 例如，可以为每个写入附加一个时间戳，挑选最 “最近” 的最大时间戳，并丢弃具有较早时间戳的任何写入。 这种方式其实是我们上文所讲的最终收敛一致性。 其缺点是：以持久性为代价：如果同一个Key有多个并发写入，即使它们报告给客户端的都是成功（因为它们被写入 w 个副本），也只有一个写入将存活，而其他写入将被静默丢弃。 如果丢失数据不可接受，那么最后写入胜利是个很烂的选择。 “此前发生”的关系和并发 只要有两个操作A和B，就有三种可能性：A在B之前发生，或者B在A之前发生，或者A和B并发。 我们需要的是一个算法来告诉我们两个操作是否是并发的。 如果一个操作发生在另一个操作之前，则后面的操作应该覆盖较早的操作，但是如果这些操作是并发的，则存在需要解决的冲突。 捕获”此前发生”关系我们需要一个算法，可以确定两个操作是否是并发的，还是先后关系， 例如两个客户端同时向一个购物车添加项目，注意服务端版本号和客户端版本号： 操作依赖关系： 客户端永远不会完全掌握服务器上的数据，因为总是有另一个操作同时进行，但是，旧版本的值最终会被覆盖，并且不会丢失任何写入。 服务器可以通过查看版本号来确定两个操作是否是并发的，算法的原理： 服务器为每个键保留一个版本号，每次写入键时都增加版本号，并将新版本号与写入的值一起存储。 当客户端读取键时，服务器将返回所有未覆盖的值以及最新的版本号。 客户端写入键时，必须包含之前读取的版本号，并且必须将之前读取的所有值合并在一起。 当服务器接收到具有特定版本号的写入时，它可以覆盖该版本号或更低版本的所有值（因为它知道它们已经被合并到新的值中），但是它必须用更高的版本号来保存所有值（因为这些值与随后的写入是并发的）。 当一个写入包含前一次读取的版本号时，它会告诉我们的写入是基于之前的哪一种状态。 理论上检测到”此前发生”关系，后发生的请求可以覆盖前面的请求，但本例中记录了同时写入的值，由于最终只有一个结果，这就需要合并同时写入的值。 合并同时写入的值优点：没有数据被无声地丢弃 缺点：客户端需要额外工作：客户端必须通过合并并发写入的值来擦屁股。 Riak 称这些并发值为兄弟。 合并兄弟值： 与多领导者复制的冲突解决相同的问题。 最简单的是根据版本号或者时间戳最后写入胜利，但会丢失数据。 对于购物车来说，合理的合并方法是集合求并集。 但是如果从购物车中删除东西，那么求并集会出错：一个购物车删除，求并集后，会重新出现在并集终值中。 所以删除操作不能简单删除，需要留下有合适版本号的标记，被称为墓碑。 版本向量多个副本，但是没有领导者，该怎么办？ 每个副本、每个主键都定义一个版本号。 每个副本在处理写入时增加自己的版本号，并且跟踪从其他副本中看到的版本号。 这个信息指出了要覆盖哪些值，以及保留哪些值作为兄弟。 什么是版本向量 所有副本的版本号集合称为版本向量（version vector）。 版本向量允许数据库区分覆盖写入和并发写入。 使用版本向量可以轻易的检测出冲突，但如何收敛至一致的状态仍然是不确定的。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"大型网站设计架构","slug":"大型网站设计架构","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:15:05.483Z","comments":true,"path":"post/6f8a.html","link":"","permalink":"http://example.com/post/6f8a.html","excerpt":"","text":"大型网站设计架构 读 大型网站设计架构 核心原理与案例分析 思考体会 一个好的网站架构需要考虑哪些东西： 性能。性能是评判网站架构最核心的标准，这会直观的反应到用户的实际体验上，如果不能带给用户良好的体验，那么一切都是空谈。 可用性。故障无处不在：硬件故障、程序 BUG、自然灾害……高可用意味着你的网站在大多数情况下（即使某台服务器出现故障）都能正常提供服务，一个高可用的大型网站至少要保证”两个九”，即一年中 99% 的时间都是可以正常访问的。 伸缩性。伸缩性是指网站的资源（例如服务器数量）能够随时调整，一个良好的伸缩性是指当一个网站资源增加时，其性能也会得到线性增长。 扩展性。扩展性指的是功能扩展，任何一个产品都需要不断升级迭代，推出新的功能，一个良好的扩展性意味着网站设计业务之间耦合度低，新增业务对已有业务不会造成太大的影响。否则，任何一次升级可能都需要程序员加班加点检查各处的依赖，整个网站臃肿不堪，产品迭代效率缓慢，在市场上只能是处于被淘汰的那一方。 安全性。一个大型网站必然会遭受到各种各样的攻击，如果一个网站随时会被攻击瘫痪，试问谁会使用这个网站？ 网站架构的系统层次如下图所示： 想要设计一个良好的架构，必须要考虑到图中几点层次架构： 前端架构：展现给客户，由游览器渲染。 应用层架构：供前端访问的业务服务。 服务层架构：基础服务，如一些中间件等；或抽离出的可复用的基础服务，如 SSO 登录模块。 存储层架构：持久化服务，如数据库。 后台架构：离线任务，如定时任务、搜索任务、数据仓库等。 数据采集与监控：统一的解决方案，采集数据、监控告警。 安全架构：保护网站免遭攻击及数据泄露。 高性能评价标准用户最直观的感受就是 RT 响应时间，即请求一个页面、接口到收到答复并处理（渲染）的时间，任何一个网站在上线前都必须将 RT P99 控制在一个可接受的范围内。 对于程序员而言，关注的可能更多是 QPS（每秒查询数）、TPS（每秒事务数）、最大并发数量、性能计数器（进程数、CPU利用率、内存使用等）等指标。 通常我们会通过发压机对不同并发数目下判断系统的总体承受能力。 并发数发压并不仅仅只是开 N 个线程不停发起请求，每个线程两次请求之间应该还会有些间隔，这个间隔被称为思考时间。 QPS 指每秒查询数，通常仅仅针对 Get 请求；TPS 指每秒事务数，不单单针对查询，是 QPS 的超集。 性能优化性能优化可以考虑从前端优化、后端优化、以及存储优化。 前端优化 CDN 加速。使用内容分发网络存储静态资源，开启 CDN 并不需要修改大量源代码，而是通过配置源站域名 CNAME，将源站域名指向 CDN 加速域名，由 CDN 全局负载均衡调度一个最优的 CDN 服务器给用户，用户直接请求 CDN 代理服务器。 在某些前后端同源的项目下，请求后台接口同样会走 CDN 服务器代理，但动态资源不需要缓存，可以约定 Content-Type 类型决定是否需要缓存。 反向代理。使用 Nginx 或其他高性能反向代理服务器进行代理，降低单个服务器压力，缺点是反向代理服务器压力可能会比较大。 资源压缩。可以将传输内容、页面资源等资源压缩，减少网络传输时间。 资源缓存。游览器也可以缓存某些资源。 减少 HTTP 请求。HTTP 1.0 版本是无状态的，任何一次请求都需要打开额外的链接，可以考虑将多个请求合并。 后端优化 使用缓存。缓存可以减少对数据库或其他存储服务的压力，但是单台服务器上的缓存可能会存在各种各样的问题，例如：带有状态、内存不足等，因此可以考虑使用分布式缓存集群，如 MemCache、Redis 等。 使用集群。使用集群可以降低单台服务器的压力，使系统整体负载能力增强，并且多台廉价服务器比一台昂贵的高性能服务器划算得多。 异步。某些后台任务可以使用 MQ 完成异步操作，后台提交任务后可以立即响应前端，例如下单后扣减数据库成功后需要做一些其他操作、发送消息通知等。 代码优化。针对特定语言进行特定优化。 存储层优化 机械硬盘 VS 固态硬盘（SSD）。机械硬盘通过磁头转动读取信息，顺序读取会比随机读取快上几百倍。固态硬盘没有机械装置，数据被记忆在硅晶体中，可以像内存一样做到随机读取。 B+ 树 VS LSM 树。B+ 树以稳定高效的读取速率得到人们的青睐，但 B+ 树在读取或写入时对不同的页面可能会产生大量的随机读写；LSM 是一种顺序的日志合并树，写入读取总是顺序的，当数据较多时会将多个段合并以去除重复数据（类比 AOF 重写），写入非常快，但读取可能不断遍历段以读取值，稳定性不如 B+ 树。在 SSD 技术日益成熟的情况下，也许 B+ 树还会继续大放光彩。 RAID（冗余廉价磁盘阵列） VS HDFS（分布式文件系统）。RAID 是利用多个磁盘形成条带并发写入获得性能，HDFS 可以看作是在服务器集群层面上类似实现了 RAID 功能。HDFS 将文件分割为多个 block，写入会并发写入多个块，而读取也会并发读取然后合并。NameNode 中存储了文件块的一些元数据，NameNode 也负责分配 block，做注册中心、负载均衡使用。 高可用高可用设计高可用意味着技术任意一台服务器宕机，网站需要保持可用性。CAP 理论告诉我们：P（分区容忍性）是必须要保证的，而 C（数据一致性）和 A（可用性）只能保证一个。 通俗的介绍一下 CAP 理论： 一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有些节点之间不连通了，整个网络就分成了几块区域。数据就散布在了这些不连通的区域中。这就叫分区。 当你一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就访问不到这个数据了。这时分区就是无法容忍的。 提高分区容忍性的办法就是一个数据项复制到多个节点上，那么出现分区之后，这一数据项就可能分布到各个区里，容忍性就提高了。 然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点上面的数据可能是不一致的。要保证一致，每次写操作就都要等待全部节点写成功，如果某个节点宕机，写操作就会无限等待，这又会带来可用性的问题。 如果不考虑可用性，数据一致性又得不到保障。 总的来说就是，数据存在的节点越多，分区容忍性越高，但要复制更新的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据所需要的时间就越长，可用性就会降低。这就是 CAP 理论。 例如现在比较流行的 Raft 算法是 AP 的，一旦有半数以上节点宕机，数据就无法正确写入，导致不可用；但 Raft 算法不要求数据同步到所有节点，仅仅需要同步到半数以上节点，因此可用性在大多数时候能够得到保证。Raft 算法是当下最流行的一致性与共识的解决方案。 一个高可用的网站必须包含如下几种措施： 数据备份。备份是最让人安心的，备份分为冷备和热备，冷备是指定期将数据归档、备份；热备是指实时进行数据同步。在大型网站中，冷备与热备都是必要的，现在大多数存储层服务如 Mysql 都提供解决方案。 服务集群。使用集群即使一台服务器宕机其他服务器也能正常工作。使用集群的前提是服务必须是无状态的，如果某台服务器带有状态，例如保存了用户的购物车，当负载均衡调度其他服务器后，其他服务器并没有保存相关信息。解决方案通常有： 使用 Cookie 或 JWT 让用户保存信息。 利用 Hash 算法绑定服务器，例如一致性哈希算法。 使用分布式缓存（中心化）。 故障检测、自动恢复。集群中任意服务器宕机后，要能够检测到故障，并自动进行转移。常用的解决方案有心跳检测、服务器定时推送健康状态，一旦检测到不可用，如果是主从集群，则会自动进行选举；如果是服务集群，则负载均衡调度器将其从列表中移除。 服务切分。切分的思想在于避免一个服务出现问题而影响全局，例如淘宝曾经秒杀服务就曾引起整个淘宝业务不可用。纵向切分指按照业务模块将系统分割成不同的业务，不同的业务分离部署，具有不同的优先级；横向切分指将服务分层，如应用层、服务层、存储层。 异步调用。使用 MQ 进行异步调用可以保证尽管消费者宕机，消息也不会丢失。如果有多个消费者，也可以避免一个消费者宕机从而导致所有消费者都无法处理。 服务降级。分为主动降级和被动降级，主动降级是指提前关闭某些功能，例如淘宝双十一时，提前关闭一些功能以让出服务器资源；被动降级是指当服务不可用时，主动关闭服务防止更多压力达到服务器上或进行降级服务，例如某图片服务器宕机，降级策略会选择将本地一些预留的图片返回。被动降级通常只是暂时的，可以指定一个降级窗口期。 数据监控。最好不要等到故障后再来恢复，一个好的网站应该要能够预知到故障发送并提前做出处理。数据监控包括服务端监控与用户数据监控，服务端监控包括监控服务器性能负载，并实时告警；用户数据监听包括收集用户行为、游览器日志收集等，对危险的用户让其进行验证才能够操作。 网站发布除了服务器的故障之外，发布过程中也可能会导致一些问题，如合并冲突、误操作线上数据，因此一个自动化的发布流程也是非常重要的。发布过程中，任意一环都必须要严格遵循，就像火车一样，必须要到达某个站点，每一站都需要检查，不合格的项目下车，最终火车到达终点时，项目也就正常发布了。 一个经典发布过程通常包括： 开发环境程序员自测。 开发分支合入测试分支，冲突检测、代码检测。 测试分支自动化集成测试（例如 Go 的单元测试、Java 的单元测试）。 测试环境自动部署，安全测试、QA 测试，卡点确认。 测试分支合入主干分支，冲突检测、代码检测。 主干分支自动化集成测试。 线上预览环境自动部署，线上预览环境测试，卡点确认。 创建 release 发版分支（或标记 Tag），禁止代码合入。 线上环境发布。 线上发布时常用的发布方式为 灰度发布（金丝雀发布），即新版本流量与旧版本流量并行，持续观察，持续增加新版本流量占比，最终完全发布。 当然也可以在前端设置一个开关，让用户自行选择体验新旧版本，代价是比较复杂，前端需要维护两套 API。 可伸缩可伸缩意味着服务器资源可以伸缩调整，同时系统整体处理整体随着线性变化。 通常通过集群方式完成，前面也讲过，应用服务器需设置成无状态的，然后由负载均衡统一调度。 负载均衡方式 HTTP 重定向。客户端请求负载均衡服务器，服务器根据负载均衡算法返回 302 临时重定向状态码诱导用户重新发起请求，好处是无需响应资源，负载均衡服务器压力不算大，缺点是客户需要发起两次 HTTP 请求，实践中用的不多。 DNS 域名解析。可以通过为一个域名配置多个 IP 来完成负载均衡的目的。通常应用服务器可能经常会发生变化，因此 DNS 配置也会经常改变，所以在实践中，可能还会加一层抽象，即 DNS -&gt; 反向代理服务器 -&gt; 应用服务器。 反向代理。可以配置反向代理服务器进行负载均衡，如 Nginx 可以完成这一目的。 IP&#x2F;TCP 层负载均衡。上述负载均衡是运行在 HTTP 层面的，一般称为 7 层负载均衡。IP&#x2F;TCP 负载均衡一般称为 4 层负载均衡，指当请求到达主机时，通过修改 IP 或 端口进行转发，可以类比 NAT 转发，四层负载均衡通常在内核层完成，速度较快。 ​ 链路层负载均衡（三级负载均衡）。指仅修改 MAC 地址，而不修改 IP、PORT 进行负载均衡。这种方式需要利用到逻辑链路捆绑技术，将多个物理网络逻辑捆绑成一个局域网链路，通过 MAC 地址便可寻址。而由于源 IP 没有改变，所以服务器的响应会直接答复客户，而不会经过 LVS 负载均衡代理。 一致性哈希算法对于某些带状态的集群服务器，必须要将请求导入到特定的服务器上，否则将无法正常服务，例如带有 session 状态的应用服务器，按 Key 分区的缓存服务器等等…… 这时如果新增一台服务器，很可能会导致原先请求落在其他服务器上，典型的哈希算法 index = hash % n 会导致 n / (n + 1) 错误率发生。 此时可以使用一致性哈希算法，可参考: 分布式系统中的分区问题，一致性哈希算法只会导致少量的请求或数据迁移。 但是在某些时候，少量的数据迁移可能也会导致性能问题，尤其是对于数据库而言。 例如如果对数据库进行了分片操作，将一个表中的数据拆分到多个数据库中去，现在需要新增一个数据库服务器，就算使用了一致性哈希算法，我们也需要去遍历一个数据库中的表的全部数据，重新计算哈希并确定是否需要迁移。 这种遍历、计算、迁移操作是十分费时的，而且还需要锁住表。如果一致性哈希中虚拟节点较多的话，需要遍历的表可能会更多。 想要避免部分数据迁移的话，办法是在加一层抽象，提前规划好未来可能最多的服务器数目，然后创建分区，在数据库中可以体现为 schema，分区的数量要不能小于未来最多的服务器数目，然后一个数据库可以保存多个分区。 由于多了一层抽象，需要一个额外的注册中心来记录分区所在的数据库，由于分区数目是固定的，从行记录到分区可以简单的采用取余算法路由，分区到数据库需要查注册中心，最后前往对应数据库搜索对应分区，拿到数据。 这样当我们新增一个数据库时，可以将分区作为一个整体进行批量迁移，可以直接同步数据快照，这比数据部分迁移快几百倍，数据库通常也自带 schema 同步功能。然后仅需修改注册中心的记录即可。 这是市面上绝大多数分布式数据库的做法。 分布式数据库虽然提供较高的伸缩性以及不错的性能，但却无法进行 Join 操作、也无法保障事务，通常需要在业务有意识的避免事务操作。 可扩展六大设计原则中最重要的一点原则是 开闭原则，指对扩展开放而对修改关闭，这意味着当我们需要修改功能或新增功能时，因尽可能的通过扩展的形式嵌入，而尽可能的不修改或是少量修改之前的代码。不要大量修改旧的源代码永远是一句忠告，你并不知道这可能会引起什么样的后果。 六大设计原则：开闭原则、接口隔离原则、单一职责原则、里氏替换原则、依赖倒置原则、迪米特法则。 因此网站必须要设计成可扩展的，而可扩展的最核心的要素就是低耦合，只有业务与业务之间耦合程度低，扩展功能才会显得相对容易。 想要完成这个目的最重要的就是拆分与通信： 拆分 纵向拆分（竖切）：想象一刀纵向切割，然后切割出多个业务子模块。 横向拆分（横切）：想象一刀横向切割，切分出多个层级，下层可供上层复用。 拆分之后横向的服务（一行）之间往往不会互相影响，无论是新增功能还是扩展功能都不会对同层的服务造成太大的影响。而纵向的服务之间存在相互调用，因此升级扩展需要谨慎些，但只要保持接口不变，各层之间还是不会造成太大的影响。 试想，如果是未拆分、高耦合的业务，功能修改、维护起来是非常麻烦的，这通常体现在： 编译、部署困难。构建一个巨型应用耗时多。 分支复杂。多个团队共同维护一个分支，可能会造成大量冲突。 底层服务压力大。如果未进行横向切分，各个服务均调用存储层，很容易导致数据库崩掉。 扩展功能复杂。可能一不小心就踩雷了。 因此拆分是必要的，而拆分带来的坏处就是维护负载、通信负载，抛开维护成本，网络通信将成为系统的主要性能瓶颈。 选择一个好的 RPC 通信协议十分重要。 如果可以异步响应，使用 MQ 会是一个好的选择，MQ 不仅降低了延迟（异步），生产者也无需关注消费者，二者完全没有耦合，非常容易扩展。 除此之外，选择一个好的开发框架也十分重要，一个好的开发框架可以很容易的让你扩展一些功能。 安全性常见网站应用攻击 XSS 攻击（跨站脚本攻击）。此类攻击通常表现为攻击者诱导用户点进某一链接，而此链接中内嵌了一段 JS 代码，导致用户游览器加载并执行脚本。其原理为 HTML 是一种超文本标记语言，通过将一些字符特殊地对待来区别文本和标记，如果动态页面中插入的内容含有一段JavaScript脚本时，这些脚本程序就将会在用户浏览器中执行。 例如如果你在发布文章时在文章中写了一段 JS 代码，你的文章被渲染时可能就会加载这段 JS 恶意程序。 为了避免 XSS 攻击，消毒几乎最有效的办法，将用户输入的特殊字符进行转义存储，例如 &lt; 被转移为 &amp;lt; 等。 注入攻击。注入攻击分为 SQL 注入和 OS 注入，这二者原理是一样的。举个简单的 OS 注入的例子，某网站接受用户上传文件并进行 MD5 校验，程序代码为 os.systen(&quot;md5 &quot; + file_name)，如果用户上传的文件名为 $(rm -rf .)，那么实际执行的命令就会变成 md5 $(rm -rf .)，这回导致服务器被删库。 因此在执行命令时一定要小心判断，将用户的参数进行参数绑定，当成一个字符串处理，Shell 脚本中单引号可以无视特殊字符。 CSRF 跨域攻击。CSRF 利用的是游览器自带的 Cookie 的机制，攻击者迫使用户访问攻击者的服务器，由于游览器自带 Cookie 访问，这样攻击者就得到的用户的 Cookie 信息，十分危险。 解决方案通常有：添加 Reference 头部字段、使用 Token 而不是 Cookie、要求用户进行验证、开启同源策略，不允许跨站访问（即使前后端分离部署，也可以通过路径进行反向代理）。 数据安全数据加密除了使用 HTTPS 等安全的协议对数据传输加密外，在数据库中对敏感数据也应该加盐散列存储。 除此之外，尽量不要将错误内容回显给用户，以防止信息泄露。 除了数据泄露之外，一个安全的网站还应该做到信息过滤与反垃圾，传统的过滤方式为加 N 层过滤器，根据不同的规则进行匹配，但是这么做可能会导致后续规则膨胀，难以管理。 最新的垃圾识别技术是采用机器学习进行数据分类，根据历史已有的数据集进行训练，提取出特征，进行判断。 举个简单的例子，根据历史的数据而言，文本“加入我们”出现在垃圾邮件的概率为 20%，出现在非垃圾邮件中的概率为 5%，这就是一个简单的分类模型，然后对检测邮件提取特征文本，例如提取到 “加入我们” 这个特征值，再结合其他特征值以及相关概率进行判断，判断其是否是垃圾邮件。 机器学习可能会存在误判，但比基于规则的过滤方式高效的多，而且比较全面。 秒杀系统架构设计秒杀场景的冲击在于： 突然骤增的流量、服务器负载增加、带宽增加 对现有网站造成冲击 超买超卖问题 秒杀系统架构设计可以归纳为如下几点： 秒杀系统独立部署，避免对其他业务造成冲击 页面静态化，如评论、点赞量等数据冻结，下单地址使用默认地址或允许之后修改，不去请求其他服务，防止造成影响，静态页面使用 CDN 加速。 主动降级，提前关闭一些非核心功能。 下单按钮关闭，等到秒杀开始时开放，开放后禁止用户连续点击。 为防止用户使用爬虫下单，每次下单都需要带上一个随机数参数，此随机数通过请求服务器生成，服务器禁止一些不存在的随机数请求。服务器可以预先缓存一些随机数，从随机数池中分发。 提前返回结果，告知秒杀结束，例如如果只有 10 个秒杀名额，在请求进入订单处理系统之前，先经过一个拦截器，拦截器进行简单计数，如果已经存在 100 个请求了，则直接返回秒杀结束，避免大量请求打到服务器、数据库中。 预减缓存、内存标记、异步处理。Redis 等缓存服务器性能比数据库高得多，并且也提供原子操作，可以提前缓存库存数目，请求到达服务器时，先预减缓存，如果缓存中库存不足，则直接返回，并在位图中打上标记，下次首先根据位图判断库存是否充足。 这个逻辑核心在于秒杀最终成功的人只占一小部分，而大多数人秒杀会失败。使用缓存和内存标记可以防止大量请求走到下一步读数据库的逻辑。 如果用户取消支付，需要对 Redis 进行补偿并解除内存标记。 异步削峰。可以考虑将下单请求交由 MQ 处理，后端开放查询接口供前端轮询，前端不断轮询并显示 “排队中”，后端可以利用 MQ 进行削峰处理，降低压力。 用户标记。一旦用户下单成功，则禁止用户再次下单；当然也可以禁止用户同一时间下单多次，例如使用 Redis 标记用户，并配置一个过期时间。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"数据库锁知识","slug":"数据库锁知识","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.987Z","comments":true,"path":"post/a748.html","link":"","permalink":"http://example.com/post/a748.html","excerpt":"","text":"数据库锁知识(INNODB)库锁库锁主要分为两类： FTWRL（Flush tables with read lock），将数据库设置为只读状态，当客户端异常断开后，该锁自动释放，官方推荐使用的库锁。 设置global全局变量，即set global readonly=true，同样是将数据库设置为只读状态，但无论何时，数据库绝不主动释放锁，即时客户端异常断开连接。 Flush tables with read lock 具备更安全的异常处理机制，因此建议使用Flush tables with read lock而不是修改全局变量。 表锁MDL锁MDL锁，是一种表锁，也称元数据锁(metadata lock)，元数据锁是server层的锁，MYSQL下的所有引擎几乎都提供表级锁定，表级锁定分为表共享读锁（S锁）与表独占写锁（X锁）。 在我们执行DDL语句时，诸如创建表、修改表数据等语句，我们都需要申请表锁以防止DDL语句之间出现的并发问题，只有S锁与S锁是共享的，其余锁都是互斥的，这种锁不需要我们显示的申请，当我们执行DDL语句时会自动申请锁。 当然我们也可以显示的申请表锁： LOCK TABLE table_name READ; 使用读锁锁表，会阻塞其他事务修改表数据，而对读表共享。 LOCK TABLE table_name WRITE; 使用写锁锁表，会阻塞其他事务读和写。 MDL锁主要用于解决多条DDL语句之间的并发安全问题，但除了DDL与DDL之间的问题，DDL与DML语句之间也会出现并发问题，因此INNODB下，还会存在一种隐式的上锁方式。 意向锁事实上，为解决DDL和DML之间的冲突问题，在INNODB下，数据库还会为每一条DML语句隐式地加上表级锁，这并不需要我们显示的指定。 来看看数据库为什么这么做，我们假设事务A执行一条DDL语句ALTER TABLE test DROP COLUMN id;，而事务B正在执行两条DML语句SELECT * FROM，如果对数据库比较了解，你应该很快的就会发现其中存在一些并发安全问题： 事务A 事务B BEGIN BEGIN SELECT * FROM test; … ALTER TABLE test DROP COLUMN id; SELECT * FROM test; COMMIT COMMIT 这就产生了冲突现象，事务A执行的两条查询语句不一致，违背了事务的一致性，而为了解决这个问题，MYSQL引入了意向锁，官方将这种锁分为意向共享锁(IS锁)和意向排他锁(IX锁)，意向锁是由DML操作产生的，请注意区分与上文所说的S锁与X锁，意向共享锁表明当前表上存在某行记录持有行共享锁(区别表S锁)，意向排他锁表明当前表上存在某行记录持有行排他锁(区别表X锁)。 每执行一条DML语句都要申请意向锁，意向锁的类型是由行锁的类型决定的，例如SELECT语句会申请行共享锁，同时也会申请意向共享锁，UPDATE会申请意向排他锁，同一个表内的DML语句不会冲突，这意味着意向锁都是兼容的，要注意意向锁是由DML语句产生的，而DDL语句不会申请意向锁。 如上文说所，DDL语句申请的只是普通的X锁或S锁，但它必须根据规则要等待IX锁或IS锁释放。 表锁兼容性规则如下图所示： 现在可以正常执行了，事务B必须要等到事务A提交后才可执行： 事务A 事务B BEGIN BEGIN SELECT * FROM test;(申请IX锁) … ALTER TABLE test DROP COLUMN id;(申请X锁，需要等待IX释放) SELECT * FROM test;(重入) COMMIT(释放IX锁) COMMIT(释放X锁) 这种隐式的上锁是在MYSQL5.5之后才引入的，在之前的版本中，执行DML操作并不会对表上锁，因此执行DDL操作不仅需要申请X锁，还需要遍历表中的每一行记录，判定是否存在行锁，如果的确存在，则放弃操作。因此在以前的版本中，是不支持在线DDL的，要想执行DDL操作就必须停止关于该表的一切活动，除此之外，执行DDL操作需要遍历所有行，这也是非常低效的。 有了这种隐式MDL锁之后，解决了DML与DDL操作之间的冲突，在线DDL变得可能，同时无须遍历所有行，只需要申请表锁即可。 所以说，这种隐式的表锁，解决了DML与DDL操作之间的冲突，使得数据库可以支持在线DDL，同时增加了执行DDL的效率。 注意一个包含关系，IX、IS、X、S锁均属于MDL锁。 在线DDL的效率问题尽管在MYSQL5.5后提出隐式MDL锁后，在线DDL操作变得可能，但我们不得不来思考它的效率问题，考虑下图： 有三个事务，第一个事务执行DQL语句同时申请IS锁；第二个事务执行DDL语句同时申请X锁，X锁是排他的，因此必须等待事务一IS锁的释放，事务二被堵塞；事务三同样执行DQL语句，但由于写锁的优先级高于读锁，事务三不得不排在事务二的后面，事务三被堵塞(不只是数据库中，绝大多数场景下都是写锁优先)；如果后面有N个DQL语句，那么这N个语句都会被堵塞，而如果没有事务二，由于读是共享的，所有事务都不会堵塞，在线DDL使得整体效率变得异常低下。 这种现象产生的原因主要是使用了隐式MDL锁和写锁优先原则，因此我们很难根治这种现象，只能去缓解，MYSQL5.6版本后提出锁升降级机制。 锁升降级机制在上述示例中，事务二以后的事务都必须等待事务二执行完毕，而事务二是一种DDL操作，DDL操作涉及到文件读写，会写REDO LOG并发起磁盘IO，这是非常缓慢的，既然无法改变写者优先的原则，MYSQL试图加快DDL操作的执行以减少后续事务的等待，但DDL操作本身已经很难再做改变了，MYSQL想到了一种曲线救国的方式——让它暂时放弃对写锁持有！ 具体的流程为： 事务开始，申请表级写锁； 降级为表级读锁，使得后续DQL操作不被堵塞(DML仍被堵塞); 执行具体更改。 升级为写锁； 事务提交，释放锁； 当DDL事务由写锁降级时，后续的DQL操作得以运行，提高了效率。 要理解这一升一降，当事务开始时，DDL操作由写锁降级为读锁时，由于读锁与写锁排斥，可以保证DDL更改表数据时不会有任何其他写表操作，避免了并发问题；当事务提交时，读锁升级为写锁，又可以保证同一时刻没有其他读表操作，即避免了读写不一致问题。 但假如有过多的读者，使得该锁无法从读锁升级为写锁，就可能存在饿死该DDL操作的问题，这是为了提高性能而带来的弊端。 行锁行锁是对针对某一行记录上锁，是更细粒度的一种锁，在MYSQL中，只有INNODB执行行锁，而其他的引擎不支持行锁。 INNODB下实现了两种标准的行级锁(区别表锁中的S锁与X锁，这里的锁是行锁！)： 共享锁(S锁)，允许事务读一行数据。 排他锁(X锁)，允许事务修改或删除一行数据。 行锁在INNODB下是基于索引实现的，当索引未命中时，任何操作都将全表匹配查询，行锁会退化为表锁，数据库会先锁表，再执行全表检索。 因此要注意所有的行锁都是在索引上的。 四种隔离级别 读未提交(Read uncommitted)。即事务可以读取其他事务还未提交的数据，事务完全是透明的，这种级别下连脏读都无法避免。 读已提交(Read committed)。这种隔离级别下，事务可以通过MVVC读取数据而无须等待X锁的释放，但事务总是读取最新版本的记录，例如事务A正在修改某行数据，事务B读取两次，第一次读取发现A正在修改，数据被上锁，因此读取上一个版本的数据，此时A事务修改完毕并提交，事务B开始第二次读取，它总是会尝试读取最新版本的数据，于是事务B第二次读取了事务A修改后的数据，事务B两次读取不一致，发生了不可重复读问题。 可重复读(Repeatable read)。INNDOB下默认的级别，与读已提交类似，唯一的区别是这种隔离级别下，在一个事务内，总是会读取一致的记录版本，一开始读什么，后面就读什么，不会发生不可重复读问题。起初存在幻读问题，后来引入Next Key Lock解决了这个问题。 可串行化(Serializable)。禁止MVVC功能，不会出现问题，但效率低。 隔离级别 脏读 不可重复读 幻读（Phantom Read） 读未提交（Read uncommitted） 可能 可能 可能 读已提交（Read committed） 不可能 可能 可能(引入临建锁解决) 可重复读（Repeatable read） 不可能 不可能 不可能 可串行化（Serializable） 不可能 不可能 不可能 行锁的分类INNODB下有三种行锁，根据不同的条件使用不同的锁。 为了统一，我们执行如下SQL语句，建立test表： drop table if exists test; create table test( a int, b int, primary key(a), key(b) )engine=InnoDB charset=utf8; insert into test select 1, 1; insert into test select 3, 1; insert into test select 5, 3; insert into test select 7, 6; insert into test select 10, 8; a(主索引) b(普通索引) 1 1 3 1 5 3 7 6 10 8 行记录锁（Record Locks）记录锁锁住唯一索引上的行记录，请注意这里是锁住记录而不是锁住索引，这意味着你无法绕开索引去访问记录。 行记录锁何时生效？仅当查询列是唯一索引等值查询时(等值查询就是where xxx &#x3D; xxx)，next key lock会降级为行记录锁。 为什么查询列是唯一索引等值查询时，可以使用行记录锁呢？其实很简单，由于唯一索引列仅对应唯一的行记录，当我们执行等值查询时，已经确保了我们只会访问这一条行记录，因此对该记录上锁，使得其他操作无法无法影响该记录，并且插入新记录的操作会由于主键冲突而被拒绝，幻读问题也不会产生，并发安全得以保证。 要注意MYSQL默认条件下是使用next key lock的，而仅仅在条件满足时降级为行记录锁。而使用Record Lock的冲要条件是查询的记录是唯一的。 其他条件下难道不可以使用行记录锁吗？答案是不可以！其他任意条件，我们都无法满足行记录锁的重要条件。 如果不是等值查询，那么必然会出现多个结果，在RR级别下，我们来看一个范围查询，考虑事务A与事务B： 事务A 事务B BEGIN; BEGIN; SELECT * FROM test WHERE a &gt;&#x3D; 1 FOR UPDATE;(上X锁，禁止读取快照) … … INSERT INTO test SELECT 101, 5; SELECT * FROM test WHERE a &gt;&#x3D; 1 FOR UPDATE; … COMMIT; COMMIT; 试想，如果仅锁住一条记录，事务A前后两次将读出不同的结果，第二次读取将多一条记录，即幻读现象！因此，我们必须要锁住一个范围。 再考虑非唯一索引下的等值查询，想想为什么这种情况下不能加行记录锁。 其实也很简单，回到我们之前说的，行记录锁锁的是一条记录而不是索引值，例如语句SELECT * FROM test WHERE b = 1 FOR UPDATE;，该语句对应的是两条记录，行记录锁只能锁住现有记录，但是不能阻止增加其他记录，产生幻读！这是冲突的，因此无法使用行记录锁。 所以我们必须要有个范围锁，这就是间隙锁！ 在源码实现中，行记录锁是通过 哈希+位图 实现的，首先通过 表空间+数据所在页号 定位到哈希表，通过记录的 heap_no 字段查询哈希表中的 bitmap，若 1 则表示锁住。 间隙锁(Gap Lock)间隙锁锁住的是一个范围，但不会锁住记录本身，即锁条件值而非锁记录数据，这是与行记录锁相反的。在非唯一索引的等值查询下，间隙锁锁住的是前后两端的间隙；而在范围查询下，间隙锁将锁住一个范围。 例如执行语句 BEGIN; SELECT * FROM test WHERE b = 3 FOR UPDATE; 将会导致 b &#x3D; 3 前后间隙被锁住，如图： 此时 (3, 1) ~ (5, 3) 和 (5, 3) ~ (7, 6) 之间的间隙被锁住，如果我们在上诉事务未提交下执行如下语句： INSERT INTO test(a, b) SELECT 4, 0; INSERT INTO test(a, b) SELECT 100, 1; INSERT INTO test(a, b) SELECT 101, 2; INSERT INTO test(a, b) SELECT 102, 3; INSERT INTO test(a, b) SELECT 103, 4; INSERT INTO test(a, b) SELECT 104, 6; 会发现只有第一条和最后一条执行成功，其他语句都被堵塞，这意味着 b &#x3D; [1, 6) 区间的数据都被堵塞，上锁的规则我们在 Next Key Lock 中讲述，这个例子可以看出间隙锁仅仅只锁了 b，前后位置也是基于 b 的排序顺序来的，而没有锁 a，因为 a &#x3D; 4 的记录被执行。 结合 MySql 存储结构可知，Gap Lock 应当是在非聚集索引上上锁，形象的来说就是锁住 B+ 树上两片叶子之间的距离，任何妄想破坏二者之间距离的行为都将被堵塞。 而对于范围查询，例如：SELECT * FROM test WHERE b &gt; 1 FOR UPDATE 这条语句只会锁住 b &#x3D; (1, 正无穷) 处的范围，并不会锁住 b &#x3D; 1 或 前一条数据的间隙，这个应该比较好理解。 现在来看一个严峻的问题，如果大家了解的话，应该都知道间隙锁的范围是左闭右开的，但在我们的实验中，我们发现锁的范围是 b &#x3D; [1, 6)，刚好和左开右闭相反？难道官网说错了？ 其实并没有，6 作为开区间这个是由于一个优化，我们马上就会说到；而 1 是闭区间这个说法其实有问题的，如下图： 上图是关于索引 b 的 B+ 树， 仔细观察，插入的 (100, 1) 其实是在 (3, 1) ~ (5, 3) 之间的，由此可见 间隙锁锁的不是索引值，而是索引所在的位置，这点非常重要。 例如，插入一条 (a &#x3D; -2, b &#x3D; 1) 的数据将会被成功插入，因为 -a &lt; 3，这条数据将会在 (a &#x3D; 3, b &#x3D; 1) 的左边，由此也可以证明上诉结论。 其实我们可以发现间隙锁的实现应该是通过比较行记录实现的，例如上述锁住的区间是 ({1, 3}, {6, 7}]，刚好是一个左开右闭的区间，那这样大于 {1, 3} 和 小于等于 {6, 7} 的记录将被锁住，在这个例子中，{1, 100} 显然大于 {1, 3}，因此被锁，而 {1, -2} 小于 {1, 3}，所以可以正常插入。 临键锁(Next Key Lock)临键锁与间隙锁仅在RR(可重复读)隔离级别下生效，目的是为了解决幻读问题，而RC级别下连不可重复读都无法解决，更别说幻读问题了。 临建锁是行记录锁和间隙锁的结合，间隙锁锁的是一个范围，而临建锁会对这个范围内存在的记录值加行记录锁。 临建锁的规则： 先按照间隙锁的规则进行上锁，对查询前后的区间上左开右闭的范围锁。 如果闭区间不在查询范围内，那么闭区间退化成开区间，优化性能。 扫描这个范围，对范围内存在的记录上行记录锁。 根据第二点规则，可以解释上文为什么 b &#x3D; 6 为什么会成开区间，这是因为我们的查询是 b &#x3D; 3，6 不在查询范围内，因此退化。 而在整个范围内，只有 (a &#x3D; 5, b &#x3D; 3) 这条记录在范围内，其他都不在范围内，因此 (a &#x3D; 5, b &#x3D; 3) 这条记录会被加上行记录锁。 执行use performance_schema; SELECT * FROM data_locks; 查看锁信息： 发现 a &#x3D; 5 确实被加上了行记录锁。 那么为什么要加这个行记录锁呢？由于间隙锁锁住的仅仅只是内存位置之间的间隙，虽然不能插入删除，但是是可以对已存在的叶子进行修改的，这并不会改变叶子之间的距离（间隙），所以这需要额外上锁来组织这种行为，以防止不可重复读问题。 也许你会想，MVCC 版本快照不是解决了不可重复度问题吗？对，这没错，在 RR 级别下，的确是 MVCC 版本快照防止不可重复读问题，但是别忘了，我们的例子中 SELECT 语句可是加了 FOR UPDATE 的，这意味着我们希望它们锁上而不是通过读取版本快照！ AUTO-INC Locking自增长锁，在InnoDB引擎中，每个表都会维护一个表级别的自增长计数器，当对表进行插入的时候，会通过以下的命令来获取当前的自增长的值。 SELECT MAX(auto_inc_col) FROM user FOR UPDATE; 插入操作会在这个基础上加1得到即将要插入的自增长id，然后在一个事务内设置id。 为了提高插入性能，自增长的锁不会等到事务提交之后才释放，而是在相关插入sql语句完成后立刻就释放，这也导致了一些事务回滚之后，id不连续。 由于自增长会申请写锁，尽管不用等到事务结束，但仍然降低了数据库的性能，5.1.2版本后InnoDB支持互斥量的方式来实现自增长，通过互斥量可以对内存中的计数器进行累加操作，比AUTO-INC Locking(表锁)要快些。 全文完。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"深入解析分段与分页","slug":"深入解析分段与分页","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.992Z","comments":true,"path":"post/f096.html","link":"","permalink":"http://example.com/post/f096.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 分段、分页引言什么是碎片？碎片分为内部碎片与外部碎片，都是指浪费而不能使用的空间。 内部碎片是指已分配但未被使用的地址空间。例如在64位空间内，你只使用 7 字节但由于内存对齐不得不为你分配8字节空间，这就产生了1字节内部碎片。 外部碎片是指未分配且未使用的地址空间。例如，你申请4字节的Int类型，再申请8字节的long类型，为了内存对齐，其中4字节无法装入8字节类型，这就产生了4字节的外部碎片，如下图所示。 内部碎片是已被分配的空间，是操作系统不可利用的空间；外部碎片是未被分配的，是可分配的，但该空间过小(碎片的含义)无法装入资源，导致不可利用，但外部碎片是可解决的，可以将多个外部碎片紧凑成一个大的空闲空间，但这需要大量成本。 段式模型的前身：基址加界限寄存器(动态重定位)要想理解分段与分页，必须先谈谈早期的虚拟内存模型。 在经历了纯物理地址后，科学家们期望解决这种内存模型难以统一的问题，于是虚拟内存技术孕育而生，但困扰科学家们的是，如何将虚拟地址转换成物理地址。 早期的科学家们很容易的想到将整个程序作为一个整体，并为每个进程分配一个基址寄存器和界限寄存器，基址寄存器存放该虚拟地址在实际物理地址的起点，而界限寄存器则用以判定程序是否访问非法地址。 通过这种方式，实际的地址很好计算:$$实际地址 &#x3D; 虚拟地址 + 基址$$但是，这种方式仍然将进程的全部地址空间加载内存中，虽然解决了地址翻译问题，但仍然产生了大量的内部碎片，如下图中该进程栈堆区很小，于是在栈堆区之间产生了内部碎片。 从图中可以看出，如果我们将整个地址空间放入物理内存，那么栈和堆之间的空间并没有被进程使用，却依然占用了实际的物理内存。因此，简单的通过基址寄存器和界限寄存器实现的虚拟内存很浪费。 另外，我们必须要确保内存足够放得下进程的虚拟地址空间，但通常主存成本是比较昂贵的，不如磁盘廉价，这种方式通常不支持大的虚拟地址，如果剩余物理内存无法提供连续区域来放置完整的地址空间，进程便无法运行。例如现在32位的进程空间通常是4GB，主存根本就装不下几个进程。 关键问题是：怎样支持大虚拟地址空间，同时栈和堆之间（可能）有大量空闲空间？在之前的例子里，地址空间非常小，所以这种浪费并不明显。但设想一个32位（4GB）的地址空间，通常的程序只会使用几兆的内存，但却需要一次性的将整个地址空间都放在内存中。 我们需要更复杂的机制以利用物理内存，避免内部碎片，早期的科学家们想出了分段这种思想。 分段式管理分段思想分段思想其实就是将基址加界限的概念泛化，现在，我们为代码、堆和栈段分别维护一个段基址加段界限寄存器，这样我们不必要每次都强制的装入整个进程空间，每个基址寄存器存放该段在物理地址的实际空间，界限寄存器仍然用于保护地址空间。 现在对于程序未使用的段空间，我们没必要为其分配了，因为每个段之间的耦合度降低了，一个空闲的段并不会影响其他的段，等到需要用时，段可以动态生长，但一旦超过段长，仍然会触发异常。 操作系统也可以离散的分配空间，例如堆和栈不必是连续的空间（基质寄存器不同），即各个段之间物理内存中的地址不一定是连续的，这也能大大的提高对物理地址的利用率。 从某种层面上说，由于段是动态生长的，未使用的空间将不会进行分配，此时可以认为段不会产生内部碎片。 但是，剩下的空间也必须预留给这个段，以支持段的生长，如果将段长分的小一点，那么内部碎片最大不超过这个段的大小，合理的设置段大小可以有效避免内部碎片。 当然，如果内存空间没有限制，操作系统可以动态的去修改段表中的段长。 此外，由物理地址不必是连续的，一些地址可以在运行时额外分配一个段，增添了灵活性。 分段地址转换分段地址转换与基址加界限的思想大同小异，在分段思想中，程序可能具有多个段，操作系统通过一个段表来维护各段信息： 段表的地址是操作系统维护的，段表项主要维护段长和段基址，段基址指该段在物理内存中的起始地址，那么该段中的虚拟地址对于实际的地址即为 段基址 + 段内偏移。 分段系统的逻辑地址结构是由段号（段名）和段内地址（段内偏移量）所组成。 例如，若系统是按字节寻址，用32个二进制位表示逻辑地址，如果段号和段内地址各占16位，那么它的虚拟逻辑地址结构图如下所示。 那么我们读取前16位作为段号，后16位作为段内偏移，操作系统通过计算 addr &#x3D; 段号 * 段表项大小 + 段表地址得出对应的段表项地址，通过查询该段表项得出段基址，通过计算 段基址 + 段内偏移得出物理地址。 你可能发现了，在虚拟地址中，每个段的起始地址都是固定的，每个段的总大小都是固定的，其大小为：$$size &#x3D; 2^p字节，p &#x3D; 段内地址的位数$$如下图所示，注意展示的是虚拟地址的空间： 此外，栈地址是反向增长的，因此段表中必须维护一个比特位，描述是否为栈段。 段的另一个优点：很好的支持共享随着分段机制的不断改进，系统设计人员很快意识到，通过再多一点的硬件支持，就能实现新的效率提升。具体来说，要节省内存，有时候在地址空间之间共享（share）某些内存段是有用的。尤其是，代码共享很常见，今天的系统仍然在使用。 为了支持共享，需要一些额外的硬件支持，这就是保护位（protection bit）。基本为每个段增加了几个位，标识程序是否能够读写该段，或执行其中的代码。通过将代码段标记为只读，同样的代码可以被多个进程共享，而不用担心破坏隔离。 为什么页不行？页的分配是随机的，一个页通常只有 4kb，例如如果需要共享的数据有 64kb，则需要分配16 个页，这些页可能是不连续的，因此无法很好的支持共享。如果将多个页组成一个逻辑页，这已经就是分段的思想了（段页式）。 因此我们常说，段式管理是符合用户逻辑的，是利于保护和共享的。 虚拟地址翻译太慢？我们每次翻译一个虚拟地址都需要去找寻段表中的段表项，相当于多义词地址访问，这太慢了！解决方案是为计算机设置一个小型的硬件设备，将虚拟地址直接映射到物理地址，而不必再访问段表。这种设备称为转换检测缓冲区 （Translation Lookaside Buffer，TLB），有时又称为快表。 快表是一个小的高速缓存，现代操作系统无论是分段还是分页中都利用了这种软件技术，有关于快表地址翻译的问题我们将在专门针对地址翻译的文中讲解。 段的缺点：过多的外部碎片分段可以避免产生内部碎片，但由于分段是离散的在主存内找到空闲的槽块并插入，问题是物理内存很快充满了许多空闲空间的小洞，因而很难分配给新的段，或扩大已有的段 —— 大量外部碎片。 例如4kb的空间装入3kb的段，产生的1kb的空间无法在装入任何段，产生碎片的主要原因是因为分段使用的大小是不确定的。 当然前面也提到过，外部碎片可通过紧凑的方式以合成较大的空闲空间，但这需要大量成本，操作系统难以维护。 这种情况下，分页式管理应运而生。 分页式管理分页思想对于分段式的管理，一段时间后主存上将会遍布大大小小的外部碎片，操作系统难以进行维护，分段的思想是将内存空间分割成不同长度的分片，由于长度不是固定的，产生外部碎片是必然的，之前提到的将整个程序一起装入的方法虽然不会产生外部碎片，但会产生巨大的内部碎片，我们需要更细粒度的划分，以减少内部碎片的产生，解决这一问题的办法是将空间分割成较小的、固定长度的分片，这就是分页式管理。 分页式管理将程序资源划分为固定大小的页，将每一个虚拟页映射到物理页之中，由于每个页是固定大小的，操作系统可以整齐的分配物理内存空间，避免产生了外部碎片，例如一个页大小是4kb，而主存是40kb，操作系统稍加管理便能确保无论何时都能整齐的装入10个页面。 要注意到页在物理内存中也不是连续存在的，进程未使用的页也没必要为其分配内存，通过这种方式我们就解决了由分段产生大量外部碎片的问题，同时由于页较小，只有在已使用的页才会产生少量的内存碎片，这也是可以接受的，目前来看，分页是一个良好的解决办法。 分页地址转换正如同分段一样，分页地址转换也需要基址+页内偏移来完成，在分段中采用段表来存储段基址，而在分页中则采用页表来存储页基址，页基址表示页在实际内存中的起始地址，那么实际的地址：$$addr &#x3D; 页基址 + 页内偏移$$页表是由操作系统维护的，操作系统知道页表的起始位置，页表项的大小是固定的，在32位地址空间中，通常是8字节，这64比特中不仅存储了页基址，还存放着一些其他重要的数据，如：有效位、可读位、脏位等。 虚拟地址是由页表号 + 页内偏移组成的，这与分段中的虚拟地址类似，我们来进行一个简单的计算以得出32位程序中页表号所占用的位数，其中一个页表的大小通常是4kb，那么：$$虚拟地址的总空间大小&#x3D;2^{32}&#x3D;4GB\\页表项的个数&#x3D;\\frac{4GB}{4kb}&#x3D;2^{20}\\4kb&#x3D;2^12byte$$要能表示220个页表项，我们必须分配20位地址，剩余12位代表页内偏移，即下图中p&#x3D;12，n&#x3D;32，我们通常称虚拟页号为VPN，而称页偏移量为VPO，如下图所示： 为什么直接取VPO就代表了页偏移量？这也是很好理解的，因为：页偏移量 &#x3D; 虚拟地址 - 页起始地址，而页起始地址其实是固定的，即当VPO位全为0时，为对应页的起始地址 ，此时 虚拟地址 - 页起始地址 即为VPO表示数值。 现在操作系统取出虚拟地址，我们设其为vAddr，便可以通过如下步骤翻译成物理地址： 获取VPN与VPO，即VPN = vAddr &amp; 0XFFFFF000;VPO = vAddr &amp; 0X00000FFF; 获取页表项地址，$页表项地址 &#x3D; 页表起始地址 + VPN × 页表大小$; 从该页表项内取出页基址，即实际物理起始地址PPN(注意这里仅有20位，需要左移动12位才是真正的地址); 将PPN与VPO连接起来，即$真实地址 &#x3D; (PPN &lt;&lt; 12) \\ | \\ VPO$ 实际的页表项还包含其他一些信息，如下图便是酷睿I7操作系统中的页表项： 分页的缺点：页表过大怎么办？正如我们上面所计算的，对于32位操作系统而言，假定页大小为4kb，我们得出大概需要220个页表项，而每个页表项大小通常是8字节，这意味着页表的大小将是$2^20 × 8byte &#x3D; 4Mb$，这大的令人发指，然而大多数程序可能仅使用几mb的大小，页表的大小甚至比整个进程所需的所有资源还大，我们必须想办法解决这个问题，但前提是，我们仍然要支持进程的虚拟大地址空间，尽管进程可能用不上这么多。 你可能会想到，对于进程未使用的空间，操作系统不为其分配页表项以节省空间。 的确，这确实解决问题的办法，但关键在于，操作系统根本不可能做到真正意义上的不分配页表项，操作系统必须要确保每一个虚拟地址都具有意义。这句话也许优点拗口，让我们来看一个例子： 我们假设地址空间是三位的，前两位代表页号，后一位代表页偏移，那么进程虚拟地址共有8个，进程空间大小为8字节：$$\\begin{cases}000&amp;页号为0,偏移为0的地址\\001&amp;页号为0,偏移为1的地址\\010&amp;页号为1,偏移为0的地址\\011&amp;页号为1,偏移为1的地址\\100&amp;页号为2,偏移为0的地址\\101&amp;页号为2,偏移为1的地址\\110&amp;页号为3,偏移为0的地址\\111&amp;页号为3,偏移为1的地址\\\\end{cases}$$ 那么我们必须准备四个页表项，存放页0 ~ 3的物理起始地址，现在该进程没有使用页0与页1，我们假设操作系统没有维护0 ~ 1的页表项，现在对于页表而言，页号3是该页表的第一个偏移量，这不对，页号3无法被正确访问！ 即时你想出某个办法使得页3能被正确翻译，但假设此时进程收到访问地址为000的指令呢？这是可能的，由程序在运行时生成的。现在整个系统都将陷入苦恼，根本没有任何关于地址000的信息。现在你可能理解了，操作系统必须要确保每一个虚拟地址都具有意义，当该虚拟地址未被使用时，也必须有一些信息来标识该地址未被进程使用，属于非法地址。 所以直接的方法是不管用的，解决这一问题的办法是在加一层抽象。 多级页表在多级页表中，上一级页表存放的是对应的下一级页表的起始地址，并至少存在一个有效位标识以标识下一级页表是否存在。 看一个例子，仍然假设3位地址的操作系统，第一位表示一级页表，第二位表示二级页表，第三位表示页偏移：$$\\begin{cases}000&amp;一级页表页号为0，二级页表页号为0，偏移为0的地址\\001&amp;一级页表页号为0，二级页表页号为0，偏移为1的地址\\010&amp;一级页表页号为0，二级页表页号为1，偏移为0的地址\\011&amp;一级页表页号为0，二级页表页号为1，偏移为1的地址\\100&amp;一级页表页号为1，二级页表页号为0，偏移为0的地址\\101&amp;一级页表页号为1，二级页表页号为0，偏移为1的地址\\110&amp;一级页表页号为1，二级页表页号为1，偏移为0的地址\\111&amp;一级页表页号为1，二级页表页号为1，偏移为1的地址\\\\end{cases}$$我们有一个一级页表，一级页表有两项，一级页表项至少存在一个有效位，如果确实有效则还要保存下一级页表的起始地址。 我们仍然假设000;001;010;011这些地址进程未使用，现在假设进程访问地址010，MMU(地址翻译单元)取出一级页号 0，并访问一级页表偏移为0的页表项，此时操作系统发现该使用位设置为0(未使用)，则无须访问二级页表，并立即返回，告知进程该地址非法，抛出异常或终止进程。 现在一级页表中页号为0对应的二级页表无须再加载进来了，我们仅需要一级页表的两个表项和一级页表页号为1的两个二级表项，共四个页表表项，这个例子中我们所需页表表项没有改变，这是因为我们假设的页表太小了，在实际中，一旦一级页表使用未设置为0，可以有几千个二级页表项不被加载进来，极大的减小页表大小。 事实上，多级页表中每一级页表都可以设置的被恰好装进一个页，这样将不会产生任何内部碎片或外部碎片。 例如在酷睿i7中采用4级页表，每个页表9位，每一级占9位，每个页表项8字节，那么每一级页表大小是$2^{9} × 8byte &#x3D; 4kb$，刚好是一个页的大小。 考虑一个极端的例子，如上图 VPN 为 36 位，我们极端的假设程序一点空间都不使用，那么采用上图的 4 级页表只需要装载一个大小为 4kb 的一级页表而已，而如果没有多级页表的机制，我们需要装载全部的页表项，总大小为 $2^{36} \\ × \\ 8byte &#x3D; 512GB$！ 应该指出，多级页表是有成本的。在TLB未命中时，需要从内存加载多次，才能从页表中获取正确的地址转换信息（一次用于页目录，其他用于PTE本身）。因此，多级表是一个时间—空间折中（time-space trade-off）的小例子。我们想要更小的表（并得到了），但不是没代价。尽管在常见情况下（TLB命中），性能显然是相同的，但TLB未命中时，则会因较小的表而导致较高的成本。 另一个明显的缺点是复杂性。无论是硬件还是操作系统来处理页表查找（在TLB未命中时），这样做无疑都比简单的线性页表查找更复杂。通常我们愿意增加复杂性以提高性能或降低管理费用。在多级表的情况下，为了节省宝贵的内存，我们使页表查找更加复杂。 段页式存储应该想到，在加一层抽象时，我们不仅仅可以加页，还可以加段，多年前，Multics的创造者（特别是Jack Dennis）在构建Multics虚拟内存系统时，偶然发现了这样的想法。具体来说，Dennis想到将分页和分段相结合，以减少页表的内存开销。 现在，我们仍然将应用程序分段，但我们对于每一个段实施页式管理，结合分段的思想，很容易可以理解为什么为什么这种想法可以减少内存开销：由于每个段都是被使用的（未使用的段不会分配空间），那么对每个段分页，至少可以保证页的使用率不会很低。 举个例子，假设程序分为代码段、堆段、栈段，4GB的虚拟空间，程序仅仅使用了15kb，其中代码段7kb，栈段4kb，堆段4kb，那么实际物理空间占用情况如图所示： 我们来思考段页式的地址转换，这需要我们结合分段与分页，此时段描述符(段表项)不再存放段基址和段长了，而是存放该段对应页表的地址，段长页存放页表的长度： 下图地址向上增长： 那么此时的虚拟地址也应该表示为 段号 + 页号 + 偏移量： 我们执行如下算法： 1)根据段号找到段描述符。 2)检查该段的页表是否在内存中。如果在，则找到它的位置；如果不在，则 产生一个段错误。如果访问违反了段的保护要求就发出一个越界错误（陷阱）。 3)检查所请求虚拟页面的页表项，如果该页面不在内存中则产生一个缺页中断，如果在内存就从页表项中取出这个页面在内存中的起始地址。 4)把偏移量加到页面的起始地址上，得到要访问的字在内存中的地址。 段页式管理还使得操作系统对于某些保护或共享片段非常好管理，我们可以将一整个共享代码作为一段而不必如分页中标记页内哪些代码是共享的，此外可以发现这种管理还消除了分页管理中可能存在的少许内部碎片，同时又如分页一般，不含有任何外部碎片，易于管理，真是一个巧妙的思想。 总结段式管理： 优点：经过巧妙的设计，可以有效的减少内部碎片，可以提高了对物理内存的利用率；将应用按逻辑分段，人们可以编写不同类型的代码，可以方便的进行共享或保护。 缺点：会产生大量的外部碎片，使得操作系统难以分配空闲空间。 页式管理： 优点：消除了外部碎片，提高了对物理内存的利用率，利于操作系统管理空闲空间。 缺点：仍然会产生内部碎片，尽管每个页碎片不超过页的大小；页表过大，占用大量空间，可以采用多级页表思想解决。 段页式管理： 优点：同时具备段式和页式的所有优点。 缺点：需要更多的硬件支持；当TLB未命中，需要更多的时间访问内存。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"类加载机制","slug":"类加载机制","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.992Z","comments":true,"path":"post/8aae.html","link":"","permalink":"http://example.com/post/8aae.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 类加载机制前言 前端编译后，.java文件已经变成了字节码存储在.class文件中，问题是，运行时虚拟机是如何将一个静态文件读入JVM中作为运行时数据的一部分呢？这就是本文章的中心 —— 类加载机制。 类加载的过程有哪些步骤呢？—— 家(加载) 宴(验证) 贝(准备) 斯(解析) 化(初始化)! 加载过程加载加载过程主要完成三件事情： 通过类的全限定名来获取定义此类的二进制字节流(这包括了父类以及父接口)。 将这个类字节流代表的静态存储结构转为方法区的运行时数据结构。 在堆中生成一个代表此类的java.lang.Class对象，作为访问方法区这些数据结构的入口。 总的来说，就是在JVM运行时方法区中开辟一系列空间，以存储类的相关的类信息(方法、字段、类名等)，而类的相关信息是从 .class 文件读入的，JVM允许我们自己扩展加载器类以从不同位置读取 .class 文件，例如可以从网络中读取 .class 文件，亦或是从 ZIP 文件中读取，这提供了极大的灵活性，也为后来 JAR 包的发展奠定了基础。 如果需要自定义类加载器，我们只需继承系统的类加载器，并且重写 findClass 方法即可，请注意我们通常仅仅只能控制获取 .class 流的获取途径，步骤 2、3 还是需要交给系统类加载器完成，这也是为什么我们只需重写 findClass 的原因： package com.happysnaker; import java.io.File; import java.io.FileInputStream; import java.lang.reflect.Field; import java.lang.reflect.Method; import java.util.ArrayList; import java.util.List; /** * @author Happysnaker * @description * @date 2021/10/23 * @email happysnaker@foxmail.com */ public class Temp &amp;#123; public static void main(String[] args) throws ClassNotFoundException &amp;#123; Class&lt;?> dp = new MyClassLoader(\"C://Tools.class\").loadClass(\"com.happysnaker.Tools\"); System.out.println(\"类的名字是: \" + dp.getSimpleName()); Field[] fields = dp.getFields(); for (Field field : fields) &amp;#123; System.out.println(\"该类有字段: \" + field.getName()); &amp;#125; Method[] methods = dp.getMethods(); for (Method method : methods) &amp;#123; System.out.println(\"该有类方法: \" + method.getName()); &amp;#125; &amp;#125; &amp;#125; class MyClassLoader extends ClassLoader &amp;#123; //加载的文件路径 String path; public MyClassLoader(String path) &amp;#123; this.path = path; &amp;#125; //name 是类的全限定名称 @Override protected Class&lt;?> findClass(String name) throws ClassNotFoundException &amp;#123; File file = new File(path); List&lt;Byte> bytes = new ArrayList&lt;>(); //读取 .class 文件的二进制流 try (FileInputStream in = new FileInputStream(file)) &amp;#123; int b = 0; while ((b = in.read()) != -1) &amp;#123; bytes.add((byte) b); &amp;#125; &amp;#125; catch (Exception e) &amp;#123; e.printStackTrace(); &amp;#125; byte[] b = new byte[bytes.size()]; for (int i = 0; i &lt; b.length; i++) &amp;#123; b[i] = bytes.get(i); &amp;#125; //依赖系统类加载器帮我们完成其他操作 return super.defineClass(name, b, 0, b.length); &amp;#125; /** * 重写 loadClass 打破双亲委派模型 * @param name * @param resolve * @return * @throws ClassNotFoundException */ /** * 重写 loadClass 打破双亲委派模型 * @param name * @param resolve * @return * @throws ClassNotFoundException */ @Override protected Class&lt;?> loadClass(String name, boolean resolve) throws ClassNotFoundException &amp;#123; if (name.indexOf(\"java.\") != -1) &amp;#123; return super.loadClass(name, resolve); &amp;#125; System.out.println(\"使用自定义类加载器加载！\"); return findClass(name); &amp;#125; &amp;#125; 输出： 使用自定义类加载器加载！ 类的名字是: Tools 该类有字段: val 注意，所有包名以 java 开头的都会经过安全检查，这里我们加载的类继承了 Object，Object 类应该由父加载器加载，因此我们检查任何以 java. 开头的包名，将其交给父类加载器加载。 要注意经过加载过程后，仅仅只是类的方法、字段、类名等元数据被加载至方法区中，真正的实例还没有被加载出来，有必要区分 类加载过程 与 加载实例 的区别，一个类通常只会被加载一次，加载后类元数据就已经存放在JVM方法区中了，后续便可以直接引用。后面讲类加载模型时还会提到类加载器。 验证Java是相对安全的语言，原因之一就是因为每个类在被加载前都经过相对严格的验证。此阶段主要确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机的自身安全。 文件格式验证： 验证字节码是否以魔术 0xCAFEBABE 开头(标识Java类文件)。 编译、运行版本是否可接受。 …… 元数据验证： 这个类是否存在父类，如果不存在则一定不合法。 这个类是否继承了由 final 标识的类。 这个类是否覆写了父类的 final 方法。 …… 字节码验证： 字节码是否合法。 字节码是否配对。 …… 符号引用验证： 根据字符串描述的全限定名是否能找到对应的类。 是否引用了符号引用类中的 private 等不可访问方法。 凡是有一个不合法的地方，JVM都会无情的拒绝加载并且抛出异常，我们在解析过程会介绍一下什么是符号引用。 准备准备阶段JVM将为类变量分配内存，并将其初始化为默认值，这个阶段将正式在JVM堆中为对象实例开辟内存。 这里仅仅是为类字段分配内存，并赋默认值，这说明字段 a、bint a = 123; String b = &quot;123&quot;;;在这一阶段会被赋值为 0 和 null，当然这是有例外的，例如fianl int a = 123，此时 a 的值会被赋值 123，所有不可变常量在这一阶段将会被正常赋值，并且后续无法修改。 解析解析阶段JVM将常量池中的符号引用转换为直接引用，解析的主要目的是为了解析类或接口。 这句话可能很难理解，我们一步一步来理解，首先，符号引用是什么？ 符号引用与虚拟机实现的布局无关，引用的目标并不一定要已经加载到内存中，只要能唯一的标识目标即可。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。 直接引用可以是指向目标的指针，相对偏移量或是一个能间接定位到目标的句柄。如果有了直接引用，那引用的目标必定已经在内存中存在 举个栗子： class T &amp;#123; private String a = new String(); &amp;#125; 这里 a 引用了一个 String 对象(注意解析阶段并不真正分配对象，这是初始化阶段做的事)，但问题是，JVM根本不知道 String 类的具体信息(它只认识基本类型)，这导致JVM根本无法对 String 分配实例。 如果正常来说，JVM应该要知道 String 类信息在方法区的具体位置，这就是对 String 类信息的直接引用，知道了该直接引用，准备阶段就可以真正分配一个 String 实例。但此时 JVM 根本不知道 String 类在方法区中的具体位置，，因此 JVM为 String 类信息分配一个符号引用 java.lang.String，该符号引用唯一的标识了 String 类，起到一个过渡的作用。该符号引用被放置在类的常量池中。 解析阶段就是将符号引用转换为内存中的直接引用，通过上述例子你应该可以发现，符号引用仅仅只是针对于类和接口的元数据信息，解析阶段不会在这一过程去真正的分配对象实例。 解析有如下几种： 类或接口的解析： 如果要解析的类不是数组类型，则将符号引用的全限定名传递给当前类的类加载器去加载。注意这里的加载仅仅只是类加载机制中的第一步，并不是整个加载过程，解析阶段仅仅只需要解析出类的元数据信息所在的位置，而并不需要去加载类的实例。如果该类已经被加载了，那么类加载器会直接返回直接引用，否则，会经历我们上面所说的加载过程。 如果是数组类型，则按照第一点去加载数组的元素类型(如果是基本类型，则转换成包装类型)。 类字段解析（例如int a = Test.a，这里引用了 Test 的字段 a）： 先对字段所处的类进行解析，在该类的方法区中查找字段，如果存在字段并且可访问，则返回这个字段的直接引用。 否则，如果该类实现了接口，则按照继承关系从下向上搜索父接口，如果存在字段并且可访问，则返回这个字段的直接引用。 否则，如果该类不是Obeject，则按照继承关系从下向上搜索父类，如果存在字段并且可访问，则返回这个字段的直接引用。 否则，解析失败。 在这一步骤中，如果父接口或者父类未被解析，则会递归的去解析父接口或者父类。 类方法解析： 与类字段解析类似。 接口方法解析： 与类字段解析类似。 初始化阶段经过解析阶段后，所有必备的信息都已经准备好了，例如代码private String a = new String();，现在JVM已经知道了 String 类信息在方法区的直接引用，JVM可以根据 String 类的信息去加载 String 对象实例了(不会经过加载步骤，类只会被加载一次)。 这一阶段 JVM 会按照顺序(这意味着父类的变量初始化肯定先于子类)收集所有的变量赋值方法以及静态语句块的方法，合并为 &lt;clinit&gt;() 方法，然后一起执行，此时一个类实例就算正式分配完成。 要注意初始化阶段可能发送在解析阶段之前，这是为了支持 Java 语言的动态绑定特性，这意味类可能提前返回而此时还未真正分配完成，volatile可以禁止此类指令重排，这也是为什么单例模式双重验证需要加 volatile 关键字。 双亲委派模型 在加载过程我们讲到可以从不同的地方加载二进制流，这虽然提高了灵活性，但如果不加以限制，也会带来糟糕的后果，例如，我们可以自定义加载器加载一个不知名的 Object 类，这下完蛋了，所有类到底要继承哪个 Object 呢？这不被 JVM 所允许! 为了解决这种问题，官方提出了这种双亲委派的加载模型，其工作原理是： 如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的类加载器都是如此。 因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成这个加载请求（它的搜索范围中没有找到所需的类）时，子加载器才会尝试自己去加载。 使用这种模型后，即使我们自定义加载器去加载 Object 类，也会被委派给系统类加载器，系统类加载器则会加载默认的 Object 类，这样即可解决歧异。 从 Java 虚拟机的角度来讲，只存在以下两种不同的类加载器： 启动类加载器（Bootstrap ClassLoader），使用 C++ 实现，是虚拟机自身的一部分 所有其它类的加载器，继承自抽象类 java.lang.ClassLoader，使用Java实现，覆写 findClass 方法。 从 Java 开发人员的角度看，类加载器可以划分得更细致一些： 启动类加载器（Bootstrap ClassLoader）：这个类加载器负责将存放在 \\lib 目录中的，或者被 -Xbootclasspath 参数所指定的路径中的，并且是虚拟机识别的（仅按照文件名识别，如 rt.jar，名字不符合的类库即使放在 lib 目录中也不会被加载）类库加载到虚拟机内存中。启动类加载器无法被 Java 程序直接引用，用户在编写自定义类加载器时，如果需要把加载请求委派给启动类加载器，直接使用 null 代替即可。 扩展类加载器（Extension ClassLoader，继承于启动类加载器）：这个类加载器是由 ExtClassLoader（sun.misc.Launcher$ExtClassLoader）实现的。它负责将 &#x2F;lib&#x2F;ext 或者被 java.ext.dir 系统变量所指定路径中的所有类库加载到内存中，开发者可以直接使用扩展类加载器。 应用程序类加载器（Application ClassLoader，继承于应用程序类加载器）：这个类加载器是由 AppClassLoader（sun.misc.Launcher$AppClassLoader）实现的。由于这个类加载器是 ClassLoader 中的 getSystemClassLoader() 方法的返回值，因此一般称为系统类加载器。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 在 Java 9 之后，为了支持模块之间的类加载，类加载器被重新划分： 引导或启动类加载器：定义核心Java SE和JDK模块。 平台类加载器：定义部分Java SE和JDK模块。 应用或系统类加载器：定义CLASSPATH上的类和模块路径中的模块。 现在都是 jar 包的形式，jar 包仍然是处于我们的类路径下，扩展类路径几乎用不上了，因此扩展类加载器相当于被移除了，同时，jdk9 之后将 Java SE 和 JDK 模块进行了更细致的划分，例如 jdbc 由平台类加载器加载而非引导类加载器加载，有关于 jdbc 知识请参考我的另一篇文章 [SPI 与 jdbc](.&#x2F;SPI 机制以及 jdbc 打破双亲委派.md)，这篇文章将会基于 jdk11 讲解。 这些知识点其实都是很重要的，毕竟我们平时应该也不会使用 jdk8 进行开发，现在都已经更新到 jdk18了，但奈何 jdk 迭代过快，并且 jdk8 最为经典，绝大多书籍仍然是基于 jdk8 进行讲解的。 我们自己编写的类是由应用程序类加载器加载的，应用程序类加载器首先会递归向上查询，如果启动类加载器和扩展类加载器均不能加载，则由应用程序类加载器默认加载。 来看看 ClassLoader 中 loadClass 的源码实现： protected Class&lt;?> loadClass(String name, boolean resolve) throws ClassNotFoundException &amp;#123; synchronized (getClassLoadingLock(name)) &amp;#123; // First, check if the class has already been loaded //第一，检查该类是否已经被加载过了 Class&lt;?> c = findLoadedClass(name); //如果为被加载，则加载，否则直接返回 if (c == null) &amp;#123; long t0 = System.nanoTime(); try &amp;#123; //如果 parent == null，说明该类就是启动类加载器，则尝试自己加载，否则交由父类加载 if (parent != null) &amp;#123; c = parent.loadClass(name, false); &amp;#125; else &amp;#123; c = findBootstrapClassOrNull(name); &amp;#125; &amp;#125; catch (ClassNotFoundException e) &amp;#123; // ClassNotFoundException thrown if class not found // from the non-null parent class loader &amp;#125; //如果父类仍然无法加载，则尝试自己加载 if (c == null) &amp;#123; // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); //这是自己加载的核心代码，我们通常只需要覆写 findClass 方法即可 c = findClass(name); // this is the defining class loader; record the stats PerfCounter.getParentDelegationTime().addTime(t1 - t0); PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); PerfCounter.getFindClasses().increment(); &amp;#125; &amp;#125; if (resolve) &amp;#123; resolveClass(c); &amp;#125; return c; &amp;#125; &amp;#125; 源码理解起来十分简单，为了不破坏双亲委派，只推荐重写 findClass 方法(模板方法设计模式)。 双亲委派模型可以被打破吗？ 例如 JDBC 连接可能会使用其他的 Drive 类，而 JDBC 肯定算是基础类了，正常是由启动器去加载 home 路径下的 Driver，而连接可能会使用用户指定的 Driver 类，这就必须破坏双亲委派模型。 当然可以，最暴力的方法就是直接覆写 loadClass 方法，这当然有效。不过在 defineClass 代码中，JVM 仍然会检查全限定名是否以 java 开头，如果是的话，仍然会交给启动类。 参考我们上面自定义的类加载器，所有类都继承了 java.lang.Object，如果不检查 java 开头的包名将会报错。 再就是通过线程上下文加载器(ContextClassLoader)去加载，大部分 SPI 都是利用线程上下文加载器去加载的，ContextClassLoader有 set 和 get 方法可以对加载器进行设置，如果线程创建时还未设置，则从父进程继承而来。 package com.happysnaker; import javax.management.loading.MLet; public class Temp &amp;#123; public static void main(String[] args) throws ClassNotFoundException, InterruptedException &amp;#123; var t1 = Thread.currentThread().getContextClassLoader(); System.out.println(t1); //默认是应用文加载器 //设置成自定义加载器 Thread.currentThread().setContextClassLoader(new MyClassLoader()); var t2 = Thread.currentThread().getContextClassLoader(); System.out.println(t2); //打印自定义加载器 var thread = new Thread(new Runnable() &amp;#123; @Override public void run() &amp;#123; //从父线程继承，默认是自定义加载器 var t3 = Thread.currentThread().getContextClassLoader(); System.out.println(t3); Thread.currentThread().setContextClassLoader(new MLet()); &amp;#125; &amp;#125;); thread.start(); &amp;#125; &amp;#125; class MyClassLoader extends ClassLoader &amp;#123; &amp;#125; 在多数SPI加载过程中，子类设置线程上下文加载器，一步一步传递给高层，最终高层获取到了子类的加载器，进行加载，即逆向打通了双亲委派模型，现在高层用的是子类的加载器了。 不过本质仍然是改写 loadClass 方法。 线程上下文类加载器的适用场景： 当高层提供了统一接口让低层去实现，同时又要是在高层加载（或实例化）低层的类时，必须通过线程上下文类加载器来帮助高层的ClassLoader找到并加载该类。 当使用本类托管类加载，然而加载本类的ClassLoader未知时，为了隔离不同的调用者，可以取调用者各自的线程上下文类加载器代为托管。 SPI机制简介SPI的全名为Service Provider Interface，主要是应用于厂商自定义组件或插件中。在java.util.ServiceLoader的文档里有比较详细的介绍。简单的总结下java SPI机制的思想：我们系统里抽象的各个模块，往往有很多不同的实现方案，比如日志模块、xml解析模块、jdbc模块等方案。面向的对象的设计里，我们一般推荐模块之间基于接口编程，模块之间不对实现类进行硬编码。一旦代码里涉及具体的实现类，就违反了可拔插的原则，如果需要替换一种实现，就需要修改代码。为了实现在模块装配的时候能不在程序里动态指明，这就需要一种服务发现机制。 Java SPI就是提供这样的一个机制：为某个接口寻找服务实现的机制。有点类似IOC的思想，就是将装配的控制权移到程序之外，在模块化设计中这个机制尤其重要。SPI具体约定Java SPI的具体约定为：当服务的提供者提供了服务接口的一种实现之后，在jar包的META-INF&#x2F;services&#x2F;目录里同时创建一个以服务接口命名的文件。该文件里就是实现该服务接口的具体实现类。而当外部程序装配这个模块的时候，就能通过该jar包META-INF&#x2F;services&#x2F;里的配置文件找到具体的实现类名，并装载实例化，完成模块的注入。基于这样一个约定就能很好的找到服务接口的实现类，而不需要再代码里制定。jdk提供服务实现查找的一个工具类：java.util.ServiceLoader。 在下一篇博客中我将讲解 SPI 机制以及 jdbc 如何破坏双亲委派模型。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"线程池原理","slug":"线程池原理","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.992Z","comments":true,"path":"post/291a.html","link":"","permalink":"http://example.com/post/291a.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记 线程池原理池化技术我们平时使用线程时，都是额外创建一个线程(Thread)去执行任务(run方法)，run 方法执行完毕后就会销毁线程，频繁的创建和销毁无疑增加了开销，而池化技术则可以帮我们很好的管理线程。 使用线程池后，使用线程池后，线程执行完一个 run 方法不再是无脑销毁，而是根据需要可能会留在池中，进而继续执行下次任务，降低资源消耗。并且，使用线程池还可以让我们更方便的管理，例如我们可以根据系统资源指定最大线程数，根据需要延时执行任务；又例如，线程池会帮我们统计已经运行了多少个任务、最多同时运行了几个任务等，便于我们排错，简言之，线程池具有如下好处： 避免频繁创建销毁，降低资源消耗，提高任务响应速度。 显示指定参数，便于管理线程。 线程池会记录一些信息，便于管理、排错。 线程池管理的是线程，我们提交给线程池的是任务(run 方法，线程池中称为命令)，线程池根据参数配置以及当前情况，决定是新建线程还是用已有的线程去执行任务，这一点是学习线程池的前提。 本文 JDK 版本 11 参数 corePoolSize：要保留在池中的线程数，即线程池中最少拥有的线程数(不考虑懒加载)，即使这些线程都是空闲的，也不会被回收，除非显式的设置了 allowCoreThreadTimeOut &#x3D; true，这些线程被称为核心线程。 maximumPoolSize：池中允许的最大线程数。 keepAliveTime： 当线程数大于核心数时，这是多余空闲线程在终止前等待新任务的最长时间，线程池只会回收非核心线程(默认情况下)。 unit：keepAliveTime参数的时间单位。 workQueue：用于在执行任务之前保存任务的队列，这个队列将只保存execute方法提交的Runnable任务。当核心线程都在工作时，新任务被加进该队列进行缓存，等待核心线程空闲。如果队列已满并且当前线程数小于 maximumPoolSize，则会直接创建一个新的线程执行任务。 threadFactory：执行程序创建新线程时使用的工厂。 handler：执行被阻塞时使用的处理程序，因为达到了线程边界和队列容量，即线程数达到了 maximumPoolSize，并且 workQueue 容量也满，此时线程池处于饱和状态，拒绝该任务。 原理执行流程 发现线程池有一个思想是：能用核心线程处理就用核心线程处理，核心线程满了就加入等待队列等等核心线程处理完毕，要是队列已满，迫不得已才创建新线程处理。 像前面两种堵塞队列都是有界的，因此存在添加队列失败的情况。 线程池状态 private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0)); private static final int COUNT_BITS = Integer.SIZE - 3; private static final int COUNT_MASK = (1 &lt;&lt; COUNT_BITS) - 1; // runState is stored in the high-order bits private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; private static final int STOP = 1 &lt;&lt; COUNT_BITS; private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; // Packing and unpacking ctl private static int runStateOf(int c) &amp;#123; return c &amp; ~COUNT_MASK; &amp;#125; private static int workerCountOf(int c) &amp;#123; return c &amp; COUNT_MASK; &amp;#125; private static int ctlOf(int rs, int wc) &amp;#123; return rs | wc; &amp;#125; private static boolean runStateLessThan(int c, int s) &amp;#123;return c &lt; s; &amp;#125; private static boolean runStateAtLeast(int c, int s) &amp;#123;return c >= s;&amp;#125; private static boolean isRunning(int c) &amp;#123; return c &lt; SHUTDOWN; &amp;#125; RUNNING：能接受新提交的任务，并且也能处理阻塞队列中的任务，即存在核心线程空闲。 SHUTDOWN：指调用了 shutdown() 方法，不再接受新提交的任务，但却可以继续处理既有的任务以及阻塞队列中已保存的任务。 STOP：指调用了 shutdownNow() 方法，不再接受新提交的任务，同时抛弃阻塞队列里的所有任务并中断所有正在执行任务。 TIDYING： 所有任务都执行完毕，workerCount 有效线程数为 0。 TERMINATED：终止状态，当执行 terminated() 后会更新为这个状态。 研究源码发现，大哥李(线程池类编写者，并发大神)定义了一个原子数 ctl，这个数前 3 位保存线程池的 5 大状态，后 29 位保存 workerCount，即当前有效线程数。以及一系列方法来判断当前线程状态以及获取有效线程数量。 Workerprivate final class Worker extends AbstractQueuedSynchronizer implements Runnable &amp;#123; /** 当前 Worker 的线程 */ final Thread thread; /** 任务，可能为空 */ Runnable firstTask; /** 任务计数器，即该 Worker 执行了几个任务 */ volatile long completedTasks; Worker(Runnable firstTask) &amp;#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &amp;#125; public void run() &amp;#123; runWorker(this); &amp;#125; // 省略 AQS 方法 &amp;#125; Worker 类在线程池中就是我们所说的线程，线程池管理线程，事实上就是管理一个一个的 Worker，在这个 Worker 内管理了一个线程类，注意看 Worker 本身就是实现了 Runnable，该线程类实例 thread 是调用我们传入的线程工厂以 Worker 本身创建的，因此 thread.start() 会调用 Worker 的 run 方法。 Worker 还实现了 AQS 类，主要目的有 2 个： 将锁的粒度细化到每个 Worker。如果多个 Worker 使用同一个锁，那么一个 Worker Running 持有锁的时候，其他 Worker 就无法执行，这显然是不合理的。 使用不可重入锁。因为 Worker 可能调用控制线程池的方法，这显然是不合理的，我们不希望它重新获取锁。 执行任务，线程复用如何做到线程复用？这如下两个问题： 如何让一个线程运行多个任务？ 线程执行 run 方法后就会进入中止状态，如何复用？ 我们来回答这两个问题： 第一个问题：这简单，将多个任务看作是一个任务即可，在线程池中，线程会依次从队列中取出任务执行。 第二个问题：答案是我们无法让线程死而复生，如果你理解了第一个问题的答案，你应该会想到既然无法让线程死而复生，就干脆不要让他死，没错，使用 while 循环让线程一直活下去！ 嗯？while 循环太消耗资源？对，没错，所以线程池的参数是堵塞队列而不是其他队列，当队列为空时线程会堵塞，依赖于堵塞队列的底层实现（例如 ArrayBlockingQueue 使用条件变量），线程可能陷入休眠，释放 CPU，节省资源。 当一个 Worker 被添加至线程池中，线程中会执行如下代码(addWorker 方法中，后面会说)： Thread t = Worker.thread; t.start(); 而我们都知道 thread.start() 其实内部会调用 run 方法，上面讲过 thread.start() 会调用 Worker 的 run 方法，即 runWorker(this);，现在来看看这个关键代码（省略部分）： final void runWorker(Worker w) &amp;#123; Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &amp;#123; // 线程不死，无限循环，可以人为干预中断 // getTask 方法从堵塞队列中取任务，如果线程数小于核心线程数，会直接分配 task，因此这里的 task 初始可能不为空 while (task != null || (task = getTask()) != null) &amp;#123; w.lock(); if (线程池是终止状态) 中断线程 try &amp;#123; task.run(); // 执行任务 &amp;#125; catch (Throwable ex) &amp;#123; throw ex; &amp;#125; finally &amp;#123; task = null; w.completedTasks++; // 记录完成任务数 w.unlock(); &amp;#125; &amp;#125; completedAbruptly = false; &amp;#125; finally &amp;#123; // 线程跳出循环，即将死亡，将这个 Worker 移出线程池 processWorkerExit(w, completedAbruptly); &amp;#125; &amp;#125; 这短短 28 行代码就是 Worker 工作的核心代码，是不是很神奇？ 你可能会问，线程如何跳出循环？例如，我们传递了 keepAliveTime，我们期望非核心线程超时能够停止。 当 getTask() &#x3D;&#x3D; null 时会跳出循环，来看看大哥李的注释文档： 即，如下情况返回 null，终止 Worker 循环： 超过 maximumPoolSize，这个参数可能会被用户可能动态减小。 线程池处于终止状态（STOP）。 线程池处于关闭状态（SHOTDOWN），并且队列为空。 如果 workerCount &gt; corePoolSiz，此时存在非核心线程，因此当线程运行时间超过 keepAliveTime 视为超时，返回 null（注意没有标记哪个线程是非核心线程，谁先来并且符合超时条件就会暂停谁）；如果用户设置 allowCoreThreadTimeOut &#x3D; true，则核心线程同样处理，否则，允许核心线程永久存在。 至此，我们基本搞明白了 Worker 工作原理，还要注意，虽然我们一直在说核心线程和非核心线程，但事实上并没有任何字段标记 Worker 是否是核心的，所有 Worker 都是一样的，只是会根据核心线程数和最大线程数的关系去逻辑的认为谁是核心线程谁是非核心线程，例如当 workerCount &lt;&#x3D; corePoolSiz，认为所有的线程都是核心线程；而当 当 workerCount &gt; corePoolSiz，谁先进入 getTask 判断并且符合超时条件就会暂停谁，那么我们就认为这是非核心线程。 现在我们来看看 Worker 何时开始工作。 Worker 何时开始工作我们从用户代码开始探究： ThreadPoolExecutor executor = (ThreadPoolExecutor) Executors.newCachedThreadPool(); executor.execute(()->&amp;#123; System.out.println(Thread.currentThread()); &amp;#125;); execute 函数public void execute(Runnable command) &amp;#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); // 如果此时有效线程数小于核心线程数的话，addWorker 第二个参数为 true if (workerCountOf(c) &lt; corePoolSize) &amp;#123; if (addWorker(command, true)) return; c = ctl.get(); &amp;#125; // 否则，核心线程数已满，如果当前处于 RUNNING，说明核心线程能够处理队列中的任务 // 添加任务到等待队列 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &amp;#123; int recheck = ctl.get(); // 如果添加队列成功，再次判断一下线程池状态，如果线程池终止的话，拒绝 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); // 如果此时的工作线程为 0 else if (workerCountOf(recheck) == 0) addWorker(null, false); &amp;#125; // 队列添加失败时，注意这里参数，第二个是 false // 如果 addWorker 失败返回 false，则拒绝处理 else if (!addWorker(command, false)) reject(command); &amp;#125; 发现还有很大一部分逻辑隐藏在 addWorker 函数中。 addWorker 函数private boolean addWorker(Runnable firstTask, boolean core) &amp;#123; retry: for (int c = ctl.get();;) &amp;#123; if (健壮性检查) return false; for (;;) &amp;#123; // 注意第二个参数，如果 true 则和 corePoolSize 比较，否则和 maximumPoolSize 比较 if (workerCountOf(c) >= ((core ? corePoolSize : maximumPoolSize) &amp; COUNT_MASK)) return false; // CAS 尝试增加线程数，增加成功后则跳出两层循环，使用 CAS 防止并发问题 if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl // 如果线程可能处于关闭状态(大于等于)，则重新开始外层循环，外层循环会进行健壮性检查，如果线程池确实关闭，会返回 false if (runStateAtLeast(c, SHUTDOWN)) continue retry; // 这个语句是再次进入外层循环的意识 // else CAS failed due to workerCount change; retry inner loop &amp;#125; &amp;#125; // 此时线程数已经成功增加 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &amp;#123; // 构造工人 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &amp;#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &amp;#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int c = ctl.get(); // 如果线程池是 RUNNING状态 // 或者是小于 STOP 状态（SHUTDOWN）并且 firstTask 为 null if (isRunning(c)||(runStateLessThan(c, STOP) &amp;&amp; firstTask == null)) &amp;#123; // 添加到线程池 workers 中，这是个 HashSet&lt;Worker> workers.add(w); workerAdded = true; int s = workers.size(); if (s > largestPoolSize) largestPoolSize = s; &amp;#125; &amp;#125; finally &amp;#123; mainLock.unlock(); &amp;#125; // 如果成功添加，执行 start，注意这就是我们上面说的Worker工作启动 if (workerAdded) &amp;#123; t.start(); workerStarted = true; &amp;#125; &amp;#125; &amp;#125; finally &amp;#123; if (! workerStarted) addWorkerFailed(w); &amp;#125; return workerStarted; &amp;#125; 可能会有点懵，但我们根据 execute 引用的 addWorker 来依次判断一下： addWorker(commend, true)：当线程数小于核心线程数时调用，core &#x3D; true，因此在 addWorker 中会与 corePoolSize 重新比较，防止并发情况下线程数已经大于 corePoolSize，在第二个循环中上锁判断，正常来说当线程数小于核心线程数时，线程状态是 RUNNING，因此会正常创建 Worker 并运作 Worker。 addWorker(null, false)：在 execute 中，这个调用是在任务已经添加到队列中，但突然工作线程为 0 时(并发问题)调用，此时工作线程为 0，因此我们至少要添加一个 Worker，而由于我们的命令 Task 已经添加至堵塞队列了，所以这里的 task &#x3D; null，Worker 会自动从队列中获取任务。 addWorker(commend, false)：这个没啥说的，就是第二个参数变了，此在 addWorker 中会与 maximumPoolSize 重新比较，这里的 Worker 应该是非核心线程。 从结果上说，addWorker 就是添加了一个 Worker，不过函数中多了很多 CAS 操作防止并发问题。 那么整个添加运行过程就讲完了，流程确实与我们流程图画的一致，不过是多了些并发问题判断。 下面说说关闭。 Worker 关闭线程的 stop 方法已经被废弃了，因为直接 stop 线程可能会导致某些锁未释放等 BUG 出现。 取而代之的是 interrupt 方法，即设置中断标志，当线程检查到中断时会抛出中断异常，从而我门可以捕获，进行一些操作，例如释放锁。 注意中断并不能是线程立即退出，当线程在休眠时则无能为力，因为中断标志是需要线程主动轮询的。 shutdownshoutdown 方法首先设置线程为 SHUTDOWN 状态，然后主要调用了 interruptIdleWorkers(false) 方法，我们来看看这个方法： private void interruptIdleWorkers(boolean onlyOne) &amp;#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &amp;#123; for (Worker w : workers) &amp;#123; Thread t = w.thread; // 尝试获取 worker 的锁 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &amp;#123; try &amp;#123; // 获取成功了，中断线程 t.interrupt(); &amp;#125; catch (SecurityException ignore) &amp;#123; &amp;#125; finally &amp;#123; w.unlock(); &amp;#125; &amp;#125; if (onlyOne) break; &amp;#125; &amp;#125; finally &amp;#123; mainLock.unlock(); &amp;#125; &amp;#125; 这个方法逻辑很简单，用 CAS 操作尝试获取每个 worker 的锁，获取成功了说明它们不在运行中，则设置中断；否则，worker 正在运行，无法获取锁，让其继续运行下去。 由于线程状态为 SHUTDOWM，根据 getTask() 的函数返回，如果还有 Worker 存活，他会不停执行任务直到队列为空，因此 SHUTDOWM 方法不会停止正在运行的任务并且会继续运行队列中存在的任务。 shutdownNow这个函数会设置线程状态为 STOP，然后调用 interruptWorkers 方法中断所有线程。 /** * Interrupts all threads, even if active. Ignores SecurityExceptions * (in which case some threads may remain uninterrupted). */ private void interruptWorkers() &amp;#123; // assert mainLock.isHeldByCurrentThread(); for (Worker w : workers) w.interruptIfStarted(); &amp;#125; 注意看大哥李的注释，翻译是 中断所有线程，即使是活动线程。忽略 SecurityExceptions（在这种情况下，某些线程可能保持不间断），发现该方法忽略了 SecurityExceptions 异常，因此如果存在 SecurityExceptions，可能会导致部分线程未被中断，面试要考！ 具体源码就不看了。 线程池工厂通过线程池工厂便捷的创建线程池，常用的是： newFixedThreadPool 该方法核心线程数和最大线程数相等，因此没有业余线程，而核心线程不会消息，因此它是一个固定线程数量的线程池。 newCachedThreadPool 该方法核心线程数为 0，也就是说如果没有任务，则不会存在任何线程在线程池中。由于队列是 Sync，这个队列的特性是无容量的，即如果没有消费者正在 take，添加永远都会失败，因此每个任务会启动一个新的线程去运行，所以我们说这是一个可根据实际任务情况调整线程个数的线程池。 newSingleThreadExecutor 这将使用单个线程串行的执行每个任务，是一个一个线程数量为 1 的线程池。 除此之外，还有对线程池的扩展，例如 newScheduledThreadPool 可以返回一个可延迟执行的线程池，等等。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"线程间同步方式","slug":"线程间同步方式","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.992Z","comments":true,"path":"post/b310.html","link":"","permalink":"http://example.com/post/b310.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 线程间同步方式引言不同线程间对临界区资源的访问可能会引起常见的并发问题，我们希望线程原子式的执行一系列指令，但由于单处理器上的中断，我们必须想一些其他办法以同步各线程，本文就来介绍一些线程间的同步方式。 互斥锁互斥锁(又名互斥量)，强调的是资源的访问互斥：互斥锁是用在多线程多任务互斥的，当一个线程占用了某一个资源，那么别的线程就无法访问，直到这个线程unlock，其他的线程才开始可以利用这个资源。 int pthread_mutex_lock(pthread_mutex_t *mutex); int pthread_mutex_trylock(pthread_mutex_t *mutex); int pthread_mutex_unlock(pthread_mutex_t *mutex); 注意理解trylock函数，这与普通的lock不一样，普通的lock函数在资源被锁住时会被堵塞，直到锁被释放。 trylock函数是非阻塞调用模式，也就是说如果互斥量没被锁住，trylock函数将把互斥量加锁，并获得对共享资源的访问权限; 如果互斥量被锁住了，trylock函数将不会阻塞等待而直接返回EBUSY，表示共享资源处于忙状态，这样就可以避免死锁或饿死等一些极端情况发生。 探究底层，实现一个锁实现一个锁必须需要硬件的支持，因为我们必须要保证锁也是并发安全的，这就需要硬件支持以保证锁内部是原子实现的。 很容易想到维护一个全局变量flag，当该变量为0时，允许线程加锁，并设置flag为1；否则，线程必须挂起等待，直到flag为0. typedef struct lock_t &amp;#123; int flag; &amp;#125;lock_t; void init(lock_t &amp;mutex) &amp;#123; mutex->flag = 0; &amp;#125; void lock(lock_t &amp;mutex) &amp;#123; while (mutex->flag == 1) &amp;#123;;&amp;#125; //自旋等待变量为0才可进入 mutex->flag = 1; &amp;#125; void unlock(lock_t &amp;mutex) &amp;#123; mutex->flag = 0; &amp;#125; 这是基于软件的初步实现，初始化变量为0，线程自旋等待变量为0才可进入，这看上去似乎并没有什么毛病，但是仔细思考，这是有问题的： 当线程恰好通过while判定时陷入中断，此时并未设置flag为1，另一个线程闯入，此时flag仍然为0，通过while判定进入临界区，此时中断，回到原线程，原线程继续执行，也进入临界区，这就造成了同步问题。 在while循环中，仅仅设置mutex-&gt;flag &#x3D;&#x3D; 1是不够的，尽管他是一个原语，我们必须有更多的代码，同时，当我们引入更多代码时，我们必须保证这些代码也是原子的，这就意味着我们需要硬件的支持。 我们思考上面代码为什么会失败？原因是当退出while循环时，在这一时刻flag仍然为0，这就给了其他线程抢入临界区的机会。 解决办法也很直观 —— 在退出while时，借助硬件支持保证flag被设置为1。 测试并加锁(TAS)我们编写如下函数： int TestAndSet(int *old_ptr, int new) &amp;#123; int old = *old_ptr; *old_ptr = new; return old; &amp;#125; 同时重新设置while循环： void lock(lock_t &amp;mutex) &amp;#123; while (TestAndSet(mutex->flag, 1) == 1) &amp;#123;;&amp;#125; //自旋等待变量为0才可进入 mutex->flag = 1; &amp;#125; 这里，我们借助硬件，保证TestAndSet函数是原子执行的，现在锁可以正确的使用了。当flag为0时，我们通过while测试时已经将flag设置为1了，其他线程已经无法进入临界区；如果flag &#x3D; 1，我们还是将其设置为1(局限性)，并没有改变其值。 TAS的局限性在于它几乎只能用于二值锁的实现，诸如信号量的实现便无能为力了，但优点在于简单高效。 比较并交换(CAS)我们编写如下函数： int CompareAndSwap(int *ptr, int expected, int new) &amp;#123; int actual = *ptr; if (actual == expected) &amp;#123; *ptr = new; &amp;#125; return actual; &amp;#125; 同样的，硬件也应该支持CAS原语以保证CAS内部也是安全的，现在重新设置while： void lock(lock_t &amp;mutex) &amp;#123; while (CompareAndSwap(mutex->flag， 0， 1) == 1) &amp;#123;;&amp;#125; //自旋等待变量为0才可进入 mutex->flag = 1; &amp;#125; 现在锁可以正确的使用了，当flag为0时，我们通过while测试时已经将flag设置为1了，其他线程已经无法进入临界区。 此外你可能发现CAS所需要更多的寄存器，在将来研究synchronozation时，你会发现它的妙处。 另一个问题，过多的自旋？你可能发现了，尽管一个线程未能获得锁，其仍然在不断while循环以占用CPU资源，一个办法就是当线程未能获得锁，进入休眠以释放CPU资源(条件变量)，当一个线程释放锁时，唤醒一个正在休眠的线程。不过这样也有缺点，进入休眠与唤醒一个锁也是需要时间的，当一个线程很快就能释放锁时，多等等是比陷入休眠更好的选择。 Linux下采用两阶段锁，第一阶段线程自旋一定时间或次数等待锁的释放，当达到一定时间或一定次数时，进入第二阶段，此时线程进入休眠。 回到互斥锁互斥锁提供了并发安全的基本保证，互斥锁用于保证对临界区资源的安全访问，但何时需要访问资源并不是互斥锁应该考虑的事情，这可能是条件变量该考虑的事情。 如果线程频繁的加锁和解锁，效率是非常低效的，这也是我们必须要考虑到的一个点。 信号量理解信号量信号量并不用来传送资源，而是用来保护共享资源，理解这一点是很重要的，信号量 s 的表示的含义为同时允许访问资源的最大线程数量，它是一个全局变量。 信号量 s 是具有非负整数值的全局变量，由两种特殊的原子操作来实现，这两种原子操作称为 P 和 V ： P(s)：如果 s 的值大于零，就给它减1，然后立即返回，进程继续执行。；如果它的值为零，就挂起该进程的执行，等待 s 重新变为非零值。 V(s)：V操作将 s 的值加1，如果有任何进程在等在 s 值变为非0，那么V操作会重启这些等待进程中的其中一个(随机地)，然后由该进程执行P操作将 s 重新置为0，而其他等待进程将会继续等待。 在进程中也可以使用信号量，对于信号量的理解进程中与线程中并无太大差异，都是用来保护资源，关于更多信号量的理解参见这篇文章: JavaLearningNotes&#x2F;进程间通信方式。 有名信号量有名信号量以文件的形式存在，即时是不同进程间的线程也可以访问该信号量，因此可以用于不同进程间的多线程间的互斥与同步。 创建打开有名信号量 sem_t *sem_open(const char *name, int oflag); sem_t *sem_open(const char *name, int oflag, mode_t mode, unsigned int value); //成功返回信号量指针；失败返回SEM_FAILED，设置errno name是文件路径名，value设置为信号量的初始值。 关闭信号量，进程终止时，会调用它 int sem_close(sem_t *sem); //成功返回0；失败返回-1，设置errno 删除信号量，立即删除信号量名字，当其他进程都关闭它时，销毁它 int sem_unlink(const char *name); 等待信号量，测试信号量的值，如果其值小于或等于0，那么就等待（阻塞）；一旦其值变为大于0就将它减1，并返回 int sem_wait(sem_t *sem); int sem_trywait(sem_t *sem); //成功返回0；失败返回-1，设置errno 当信号量的值为0时，sem_trywait立即返回，设置errno为EAGAIN。如果被某个信号中断，sem_wait会过早地返回，设置errno为EINTR 发出信号量，给它的值加1，然后唤醒正在等待该信号量的进程或线程 int sem_post(sem_t *sem); 成功返回0；失败返回-1，不会改变它的值，设置errno，该函数是异步信号安全的，可以在信号处理程序里调用它 无名信号量无名信号量存在于进程内的虚拟空间中，对于其他进程是不可见的，因此无名信号量用于一个进程体内各线程间的互斥和同步,使用如下API： （1）sem_init 功能：用于创建一个信号量，并初始化信号量的值。 函数原型： int sem_init (sem_t* sem, int pshared, unsigned int value); 函数传入值： sem:信号量。pshared:决定信号量能否在几个进程间共享。由于目前LINUX还没有实现进程间共享信息量，所以这个值只能取0。 （2）其他函数 int sem_wait (sem_t* sem); int sem_trywait (sem_t* sem); int sem_post (sem_t* sem); int sem_getvalue (sem_t* sem); int sem_destroy (sem_t* sem); 功能： sem_wait和sem_trywait相当于P操作，它们都能将信号量的值减一，两者的区别在于若信号量的值小于零时，sem_wait将会阻塞进程，而sem_trywait则会立即返回。 sem_post相当于V操作，它将信号量的值加一，同时发出唤醒的信号给等待的线程。 sem_getvalue 得到信号量的值。 sem_destroy 摧毁信号量。 如果某个基于内存的信号量是在不同进程间同步的，该信号灯必须存放在共享内存区中，这要只要该共享内存区存在，该信号灯就存在。 总结无名信号量存在于内存中，有名信号量是存在于磁盘上的，因此无名信号量的速度更快，但只适用于一个独立进程内的各线程；有名信号量可以速度欠缺，但可以使不同进程间的线程同步，这是通过共享内存实现的，共享内存是进程间的一种通信方式。 你可能发现了，当信号量的值s为1时，信号量的作用于互斥锁的作用是一样的，互斥锁只能允许一个线程进入临界区，而信号量允许更多的线程进入临界区，这取决于信号量的值为多少。 条件变量什么是条件变量？在互斥锁中，线程等待flag为0才能进入临界区；信号量中P操作也要等待s不为0……在多线程中，一个线程等待某个条件是很常见的，互斥锁实现一节中，我们采用自旋来实现，但这效率非常低效，是否有一个更专门、更高效的方式实现条件的等待？ 它就是条件变量！条件变量(condition variable)是利用线程间共享的全局变量进行同步的一种机制，主要包括两个动作：一个线程等待某个条件为真，而将自己挂起；另一个线程设置条件为真，并通知等待的线程继续。 由于某个条件是全局变量，因此条件变量常使用互斥锁以保护(这是必须的，是被强制要求的)。 条件变量与互斥量一起使用时，允许线程以无竞争的方式等待特定的条件发生。 线程可以使用条件变量来等待某个条件为真，注意理解并不是等待条件变量为真，条件变量(cond)是在多线程程序中用来实现”等待–&gt;唤醒”逻辑常用的方法，用于维护一个条件(这与条件变量是不同的概念)，线程用条件变量的用以等待条件成立，并不是说等待条件变量为真或为假，而是利用条件变量去等待某条件。条件变量是一个显式的队列，当条件不满足时，线程将自己加入等待队列，同时释放持有的互斥锁；当一个线程改变条件时，可以唤醒一个或多个等待线程(注意此时条件不一定为真)。 在条件变量上有两种基本操作： 等待（wait）：一个线程处于等待队列中休眠，此时线程不会占用互斥量，当线程被唤醒后，重新获得互斥锁(可能是多个线程竞争)，并重新获得互斥量。 通知（signal&#x2F;notify）：当条件更改时，另一个线程发送通知以唤醒等待队列中的线程。 相关函数1. 初始化条件变量采用的数据类型是pthread_cond_t,，在使用之前必须要进行初始化,，这包括两种方式: 静态: 直接设置条件变量cond为常量PTHREAD_COND_INITIALIZER。 动态: pthread_cond_init函数, 是释放动态条件变量的内存空间之前, 要用pthread_cond_destroy对其进行清理。 int pthread_cond_init(pthread_cond_t *restrict cond, pthread_condattr_t *restrict attr); int pthread_cond_destroy(pthread_cond_t *cond); //成功则返回0, 出错则返回错误编号. 注意：条件变量占用的空间并未被释放。 cond：要初始化的条件变量；attr：一般为NULL。 2. 等待条件int pthread_cond_wait(pthread_cond_t *restrict cond, pthread_mutex_t *restric mutex); int pthread_cond_timedwait(pthread_cond_t *restrict cond, pthread_mutex_t *restrict mutex, const struct timespec *restrict timeout); //成功则返回0, 出错则返回错误编号. 这两个函数分别是阻塞等待和超时等待，堵塞等到进入等待队列休眠直到条件修改而被唤醒；超时等待在休眠一定时间后自动醒来。 进入等待时线程释放互斥锁，而在被唤醒时线程重新获得锁。 3. 通知条件int pthread_cond_signal(pthread_cond_t *cond); int pthread_cond_broadcast(pthread_cond_t *cond); //成功则返回0, 出错则返回错误编号. 这两个函数用于通知线程条件已被修改，调用这两个函数向线程或条件发送信号。 用法与思考条件变量用法模板： pthread_cond_t cond; //条件变量 mutex_t mutex; //互斥锁 int flag; //条件 //A线程 void threadA() &amp;#123; Pthread_mutex_lock(&amp;mutex); //保护临界资源，因为线程会修改全局条件flag while (flag == 1) //等待某条件成立 Pthread_cond_wait(&amp;cond, &amp;mutex); //不成立则加入队列休眠，并释放锁 ....dosomthing // 条件成立 ....change flag //条件被修改 Pthread_cond_signal(&amp;cond); //发送信号通知条件被修改 Pthread_mutex_unlock(&amp;mutex); //发送信号后尽量快速释放锁，因为被唤醒的线程会尝试获得锁 &amp;#125; //B线程 void threadB() &amp;#123; Pthread_mutex_lock(&amp;mutex); //保护临界资源 while (flag == 0) //等待某条件成立 Pthread_cond_wait(&amp;cond, &amp;mutex); //不成立则加入队列休眠，并释放锁 ....dosomthing // 条件成立 ....change flag //条件被修改 Pthread_cond_signal(&amp;cond); //放松信号后尽量快速释放锁，因为被唤醒的线程会尝试获得锁 Pthread_mutex_unlock(&amp;mutex); &amp;#125; 通过上面的一个例子，应该很好理解条件变量与条件的区别，条件变量是一个逻辑，它并不是while循环里的bool语句，我相信很多初学者都有这么一个误区，即条件变量就是线程需要等待的条件。条件是条件，线程等待条件而不是等待条件变量，条件变量使得线程更高效的等待条件成立，是一组等待 — 唤醒 的逻辑。 注意这里仍然要使用while循环等待条件，你可能会认为明明已经上锁了别的线程无法强入。事实上当线程A陷入休眠时会释放锁，而当其被唤醒时，会尝试获得锁，而正在其尝试获得锁时，另一个线程B现在尝试获得锁，并且抢到锁进入临界区，然后修改条件，使得线程A的条件不再成立，线程B返回，此时线程A终于获得锁了，并进入临界区，但此时线程A的条件根本已经不成立，他不该进入临界区！ 此外，被唤醒也不代表条件成立了，线程陷入休眠时可能会因为超时而返回，这种情况下条件并不会成立；此外上述代码线程B修改flag &#x3D; 3，并且唤醒线程A，这里线程A的条件根本不符合，所以必须重复判定条件(这是糟糕的情况)。互斥锁和条件变量的例子告诉我们：在等待条件时，总是使用while而不是if！ 陷入休眠的线程必须释放锁也是有意义的，如果不释放锁，其他线程根本无法修改条件，休眠的线程永远都不会醒过来！ 实践——读写者锁读取锁——共享；写入锁——独占。即：读线程可以加多个，而写线程只能有一个，并且读者和写者不能同时工作。 这种情况下由于允许多个读者共享临界区效率会高效，我们来考虑实现的问题：只允许一个写者工作，那么一定需要一个互斥量或二值信号量来维护，我们称为写者锁；由于读者和写者不能同时工作，第一个读者必须尝试获取写者锁，而一旦读者数量大于1，则后续读者无须尝试获取写者锁而可直接进入，注意到这里存在全局读者数量变量，因此读者也需要一个锁以维护全局读者数量，最后一个退出的读者必须负责释放读者锁。 知晓原理，快去自己动手实现一个读写者锁把！ Linux下通过pthread_rwlock函数族实现。 其核心思想便是如此。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"计算机网络中的安全、常见攻击、以及HTTPS原理与抓包实践","slug":"计算机网络中的安全、常见攻击、以及HTTPS原理与抓包实践","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.998Z","comments":true,"path":"post/1636.html","link":"","permalink":"http://example.com/post/1636.html","excerpt":"","text":"计算机网络中的安全、常见攻击、以及HTTPS原理与抓包实践 注：本文是 计算机网络中的安全 与 HTTPS 的合并。 文章已收录我的仓库：Java学习笔记 计算机网络中的安全什么是安全？本文主要研究具体的算法思想而不关注具体的协议实现，在接下来的文章中我门再把目光投向 SSL&#x2F;TLS。 在具体分析之前，我们首先来思考一下计算机网络中会面临那些安全问题，只有理清楚了这些问题，我们才能知道为什么需要这些安全技术，并且和面试官谈的时候条理也能更清楚。 报文机密性 - 我们的谈话会被窃听吗？当然会，你肯定不希望你的谈话会被别人监听，所以你需要一些加密手段让别人听不懂你的谈话。 网络中也是一样，如果不对报文加密，则任何一台中间计算机都可以窃听你的报文，如果报文中包含了你的银行密码这可就完蛋了。 报文完整性 - 我收到的报文被篡改过吗？这里的完整性并不是数据丢失问题，数据丢失在应用层之下就应该通过校验码检测出来了，本文的完整性是指：报文有没有被篡改？ 你肯定不希望你的报文在网络中被别人篡改，所以必须要有些验证方法去验证报文完整性。 端点鉴别 - Alice，真的是你在给我发消息吗？你要怎么确定对方真的是 Alice，而不是 Bob 伪造的，正如在现实生活中，你要怎么确定和你裸聊的是一个女性而不是一个五旬老汉？ 带着上述三大问题，让我们一起来看看计算机科学家们提出了什么样的解决方案。 报文机密性我们要保证报文是加密的，并且只有通信双方能够解密。 对称密匙密码体制这种体制中，通信双方协商好相同的密匙和算法，发送方利用密匙加密报文，而接收方利用密匙解密报文，因为其他人不知道密匙，所以其他人无法对报文解密。 加密方法有许多种，例如最简单的凯撒密码，它将所有字母后移 k 位，例如 abc 可能被替换为 bcd，此时 k &#x3D; 1 就是密匙。 在对称密匙体制中，主要采用块密码和流密码进行加密，流密码多用于WLAN中，我们主要看看块密码。 块密码块密码的主要原理是将明文分为固定大小的块，对每一种块都维护一个映射表以加密数据。 例如，假设块大小为 3，考虑下列映射表： 例如源数据为：000, 001, 101 将会被加密成 110, 111, 010。解密逆过程即可。 那么这里的映射表就是通信双方的密匙，上述表有 8 中输入，而每种输入又可能对应 8 种输出，所以想要破解密匙需要尝试 8 的阶乘种可能，阶乘函数上升是非常快的，当块大小变得比较大时，破解块密码在理论上说是不可能的。 但是，出现了新的问题，如果我们让块大小增大，假设为 64bit，那么交互的双方都必须维护一张长达 2^64 大小的映射表(表项为输入输出)，更可怕的情况是如果映射有所修改，那么这将是一个非常大的工作量。 取而代之是采用函数来模拟输入输出表，例如对所有二进制输入流进行亦或运算得到加密输出流。当然实际的函数不可能如此简单，它依赖于具体的实现。 获取我们还可以将每个加密块打乱，以实现让更小的函数映射模拟更大的块输入输出表。 例如我们用函数来模拟 64bit 输入输出表，我们将每个 64bit 作为一个块，但我们没有维护 64bit 的输入输出表，而是将这 64bit 分为 8 个 8bit 块，对每个 8bit 块维护一个特定的函数(图中的T1、T2….)，而后对这 8个加密的 8bit 块进行 64bit 函数置乱，使得每个 8bit 块被打乱，经过一定次数循环后，此时的 64bit 块就已经被完全打乱了，就好像我们采用了 64bit 输入输出表一样。 在上图中，密匙是 9 个函数，即 8 个映射函数和 1 个置乱函数(假定循环次数已知)。这些函数都可以由一个唯一的二进制密匙生成，现在通信双方只需要维护一个二进制串即可，无须维护一个巨大的映射表。 典型的块密码协议如 DES 与 AES 都是采用函数而非预先设定的表，它们定义了一些列算法以生成这些小型函数映射与置乱函数排列，不过前提是需要一个密匙来生成。DES(就像我们例子中的) 的密匙比特串长度为 56，块大小为 64bit，在现代计算机运行速度下，256中可能破解已非难事，因此 DES 已经被淘汰成为历史了，取而代之的是 AES，AES 的密匙长度最小为 128 位，理论上是不可能破解的。 — 如何利用密匙生成 “特定小型表函数映射” 和 “特定排列函数”？ — 我也不知道。 如何提前协商密匙如何提前协商密匙在对称密匙体制中是最为重要的一个问题，这个过程必须足够安全才行。 不过解决办法总是有的，就像我们马上要讲的，可以利用非对称密匙密码体制来协商一个相同的密匙。 非对称密匙密码体制(公开密匙密码)在非对称密匙密码体制中，假定每个网络用户都拥有私匙和公匙，私匙是个人私有的，公匙是公开在网络上的，我们定义利用私匙处理数据算法为 S，而利用公匙处理数据算法为 P。 那么，非对称密匙体制要求有如下公式成立：$$S(P(data)) &#x3D; data \\P(S(data)) &#x3D; data$$其中 data 是网络上传输的二进制比特流，现在假设 A 要像 B 发送消息 data，那么 A 直接直接用 B 的公匙(公开的)对 data 加密得到 $P_B(data)$，那么 B 可以直接利用其私匙对数据解密 $S_B(P_B(data)) &#x3D; data$，这样 B 就能够还原原文，而其他人不知道 B 的私匙，所以无法破解密文。 你可能会想，天啊，怎么可能会有这种算法！如果你真有这种想法，说明你低估了数论的魅力。 RSA算法RSA 已经成为了公开密匙密码的代言人，RSA 算法结论如下：$$(m^e \\ mod \\ n)^d \\ mod \\ n &#x3D; (m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; m \\ e, d 是经过特殊运算生成的$$通过这个神奇的结果，我们选定 e 和 d 为公匙和私匙，假定 m 为 报文 message，那么有：$$P(m) &#x3D; m^e \\ mod \\ n \\S(m) &#x3D; m^d \\ mod \\ n \\S(P(m)) &#x3D; P(m)^d \\ mod \\ n &#x3D; (m^e \\ mod \\ n)^d \\ mod \\ n &#x3D; m \\P(S(m)) &#x3D; S(m)^e \\ mod \\ n &#x3D; (m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; m$$利用这种的公匙算法和私匙算法就可以完成非对称密匙密码体制加密的任务。 RSA 的安全性依赖于目前没有一个已知的算法可以快速对一个大数进行因数分解。如果相对RSA有更深的了解可以翻到文末看看对 RSA 算法的证明，不过不清楚也没事，那毕竟是数学上的事。 RSA的缺陷是，当 e 和 d 较大时，指数运算与取模运算都是比较慢的操作，并不适合用来频繁通信，因此在未来的很长一段时间内对称密匙与非对称密匙共存都是共同的主角，在 HTTPS 中我们将看到 SSL 利用非对称密匙体制来协商一系列密匙，而在协商完毕后使用对称密匙进行通信。 不可信的公匙 Alice 要如何知道自己所知道的公匙真的是 Bob 的呢？攻击者完全宣称自己的公匙和私匙是 B 的！使用数字签名？不好意思，数字签名本身也是依赖公匙私匙体制来实现的。 我们需要一个可以信得过的机构告诉我们公匙是否合法，这种机构就是 CA（认证中心)，机构会为每个注册的实体签发一份数字证书，这个数字证书包括注册人的公匙和他的标识信息，CA 会用自己的私匙加密整数以防止服务商伪造整数(数字签名)。 在 Bob 发送公匙给 Alice 的时候会顺便发送 CA 签发的证书，Alice 比对证书来验证 Bob 的合法性。现在攻击者无法冒充 Bob 了，因为攻击者没有证书，即使攻击者也有证书，证书上也会有他的名字，Alice 可以很快知道这个 Bob 是冒充的。 报文完整性为维护报文完整性，我们需要对报文进行多对一映射(散列)，例如将 1000 比特的报文映射为 128 比特的摘要(也称报文鉴别码，MAC)，该摘要的每一个比特都与源报文相关，因此发送报文时将摘要一起发送，而接受报文时，根据报文重新计算一遍摘要，比对原先的摘要，如果不同则说明报文可能被篡改。 摘要长度须是固定的，这样接收方才能正确的取出摘要。 攻击者仅篡改报文或者仅篡改摘要都是不可行的，但如果攻击者知晓了散列函数，更改报文并同时替换摘要，此时接收方收到报文并计算摘要，并不会发现有任何问题，然而报文已经被篡改了！ 所以，为维护报文完整性，我们仍然需要一个密匙，发送方在计算散列时将密匙(字符串)附加在报文上计算摘要(发送的时候不会发送密匙)，而在接收方同时也附加密匙计算摘要，这样便解决了上述问题，因为攻击者无法不知道通信的密匙！ 注意，整个报文和摘要也需要保证报文机密性。现在需要对整个报文+摘要进行加密。 常用的密码散列函数 MD5 和 SHA-1、SHA-2、SHA-3散列函数必须要足够安全，至少要保证理论上不可能有多个不同的报文可以映射到相同的摘要，MD5声称它可以做到这一点，不过随着密码学的发展，在 2004 年后 MD5 变得不安全了，取而代之的是 SHA-1，SHA-1是 MD5 的加强版，思想上与 MD5 类似。不幸的是，2012年后，SHA-1也被指责说是不安全的，在 2015 年，破解 SHA-1甚至只需要不到一个小时，现在 SHA-1 已经被 SHA-2、SHA-3 所取代。 不过 MD5 的思想依赖未改变，后续的算法都是基于 MD5 算法思想加强的，MD5 的算法能够将任意长的报文映射为 128 bit 的摘要，过程如下： 将任意长的报文采用二进制模运算模 264 计算其余数(64位)，追加报文尾部。 在报文与余数之间填充 1~512 bit，使得填充后总长度是 512 的整数倍。填充的首位是1，后面都是0。 把追加后的报文分成一个个 512bit 数据块，每个 512 字节分为 4 个 128bit数据块，与 4 个 32bit 幻数分别进入主循环，每个幻数与每个 128bit 数据块进行交互运算，最终输出 4 个幻数，这四个幻数与这 512 字节存在某种联系，然后继续与下一个 512bit 进行循环，最终 4个幻数组合起来为 128bit 鉴别码。 更多细节可自行了解。 端点鉴别数字签名接收方 B 如何知道报文是否是 A 发送的呢？有了非对称密码加密，这点很容易做到。 A 可以用自己的私匙对 m 再次进行加密得到 C1，而 B 收到报文C1 后，B 尝试用 A 的公匙进行解密，如果得到的报文是 m，则可以确认 A 的身份，因为只有用 A 的密匙加密才能用 A 的公匙解密，所以可以确定对方持有 A 的密匙。 至于这个报文 m 到底该是什么，取决于具体的实现。它可以是确定好的一段数据，也可以是通信时的普通报文，不过大多数情况下，通常会对报文摘要(鉴别码)进行签名，因为对普通报文签名开销太大了，报文可能非常长！ 如果对摘要签名，接收方用发送方的公匙解密即可得到摘要，它可以根据报文重新计算摘要以比对正确性，如果比对不成功，可能会有两种可能，要么是签名错误、要么是报文完整性丢失，无论哪种情况 B 肯定都不会信任该报文了。 计算机网络安全总结 常见的攻击攻击在大类上分为主动攻击和被动攻击，主动攻击即主动发起攻击，可能涉及到报文篡改等；被动攻击则是指只是秘密的窃听你的报文，不会更改你的报文。被动攻击通常难以防范，只能采取更复杂的加密算法进行抑制，我们今天谈的主要是主动攻击。 在讨论攻击前，我们先假设我们上述讨论的所有措施全部使用，在此基础上看看还能有什么些攻击。 协议有关的攻击SYN泛洪攻击SYN 泛洪我在 TCP 总结中已经讲过了，具体就不在说了，可参考我的博客：万字长文总结TCP 重排序攻击这仍是针对 TCP 协议的攻击，即使 TCP 数据报已经被加密，但 TCP 首部仍然是明文的，攻击者可以劫持 TCP 报文，重排序(乱排序) TCP 首部中的序号字段，使得接收方接收到的字节流是乱序的，且接收方无法判断出异常，信以为真。 针对这种攻击的防御就是在 TCP 加密的数据报中继续定义序号，接收方验证加密的数据报中序号以判断顺序。 ARP欺骗ARP 协议是解析 MAC 地址的一种协议，当本地网关在自己的缓存表中没有找到 IP 对应的 MAC 地址，就会在局域网中广播消息，寻找对应 IP 的主机，而所有主机会监听 MAC 报文，如果是在寻找自己则即使回答自己的 MAC 地址。 在 Linux 上可利用 arpspoof命令来进行 ARP 地址欺骗(快去试试吧，我成功的攻击了我的好兄弟)，从而达到让局域网内用户断网的攻击，有兴趣的朋友门可以自己去试一试，篇幅有限就不在这里说了。 ARP欺骗（英语：ARP spoofing），又称ARP毒化（ARP poisoning，网络上多译为ARP病毒）或ARP攻击，是针对以太网地址解析协议（ARP）的一种攻击技术，通过欺骗局域网内访问者PC的网关MAC地址，使访问者PC错以为攻击者更改后的MAC地址是网关的MAC，导致网络不通。此种攻击可让攻击者获取局域网上的数据包甚至可篡改数据包，且可让网络上特定计算机或所有计算机无法正常连线。最早探讨ARP欺骗的文章是由Yuri Volobuev所写的《ARP与ICMP转向游戏》（ARP and ICMP redirection games）。 冒充网关 如果存在不法分子冒充网关(局域网内的，局域网外的无法通过网关)发送 ARP Request 报文，则局域网上的主机可能会错把黑客当作自己的网关，这些主机可能会更新自己的 MAC 缓存表，将黑客认为是自己的网关，则之后所有的信息都发给自己的网关。 事实上，如果我们的数据都进行了加密和报文完整性鉴别的话，那么黑客即使充当了网关也只能干巴巴的看着我们的加密数据，篡改也没有用，但是，黑客却可以让局域网内所有主机都无法访问外网，造成断网现象(或者是故意让网络变慢)，而且，黑客可以进行重放攻击。 不过，不是什么数据都会进行加密的，一旦你露出马脚，黑客就会立马攻击你，例如我们很快就会说到的 DNS 欺骗 充当中间人 —— 双重欺骗黑客充当中间人窃听主机与网关的通信，例如下图： 此时主机 PC1 以为 PC2 是网关，而网关以为 PC2 是 PC1，于是接下来所有的信息都将会发送给 PC2，这种欺骗方式是冒充网关的加强版，黑客现在不仅冒充网关，还冒充主机。 防范方法 配置 MAC 地址为静态地址，不允许改变。这种方法对网关通常不太可取，不过主机可以将他知道的网关地址配置成静态的。 网上设备可借由DHCP保留网络上各计算机的MAC地址，在伪造的ARP数据包发出时即可侦测到。通俗点说，主机在注册IP时同时注册了自己的MAC地址，使得路由完全掌握所有 IP 对应的 MAC地址，因此能够检测假冒ARP包。此方式已在一些厂牌的网上设备产品所支持。 网关更新速度更加频繁些，避免“一次跌倒，则放弃挣扎”。 嗅探网络 ARP 包，如果有不正当(对网关而言，除自己发的Request之外不应该有其他人发送 Request)或ARP包过多时，则及时告知网络管理员。 ARP欺骗亦有正当用途。其一是在一个需要登录的网上中，让未登录的计算机将其浏览网页强制转向到登录页面，以便登录后才可使用网上。另外有些设有备援机制的网上设备或服务器，亦需要利用ARP欺骗以在设备出现故障时将讯务导到备用的设备上。 [1] DNS欺骗DNS 欺骗就是攻击者冒充域名服务器的一种欺骗行为。 原理：如果可以冒充域名服务器，然后把查询的 IP 地址设为攻击者的 IP 地址，这样的话，用户上网就只能看到攻击者的主页，而不是用户想要取得的网站的主页了，这就是 DNS 欺骗的基本原理。DNS 欺骗其实并不是真的 “黑掉” 了对方的网站，而是冒名顶替、招摇撞骗罢了。 例如你正在请求某个银行的网址，你的 DNS 请求被黑客劫持了，黑客将返回了个假冒的 IP 给你，而这个假冒 IP 返回的页面和真实的一模一样，你信以为真，于是你的所有信息都暴露了。 黑客要如何劫持你的 dns 请求呢？通常有两种思路，一种是直接黑进你的 DNS Server，冒充DNS服务器，不过这点难度比较大；第二种就是常见的中间人劫持了，例如 ARP 欺骗。 此外，某些病毒可能会修改你的 host 文件(DNS 缓存文件)。 防范： 直接使用 ip 而不使用域名。 定期检查 host 文件。 防范 ARP 欺骗。 要求DNS服务器使用数字签名。 检测 DNS 应答，通常假冒的应答要比真实的应答简单的多。 采用 HTTPS 而不是 HTTP，碰到不合法证书提示立马警觉。 协议无关的攻击重放攻击重放攻击的基本原理就是把以前窃听到的数据原封不动地重新发送给接收方。很多时候，网络上传输的数据是加密过的，此时窃听者无法得到数据的准确意义。但如果他知道这些数据的作用，就可以在不知道数据内容的情况下通过再次发送这些数据达到愚弄接收端的目的。例如，有的系统会将鉴别信息进行简单加密后进行传输，这时攻击者虽然无法窃听密码，但他们却可以首先截取加密后的口令然后将其重放，从而利用这种方式进行有效的攻击。 例如下图： 你可能觉得重放攻击有什么大不了的，黑客又不知道具体的内容，如果这样想你就错了，假如你正给银行发送请求转账给别人，但此时你的所有请求都被黑客嗅探并且保存了下来，在某一时刻，黑客重放这些请求，于是你就发现你的钱全没了。 防范方法： 加随机数。该方法优点是认证双方不需要时间同步，双方记住使用过的随机数，如发现报文中有以前使用过的随机数，就认为是重放攻击。缺点是需要额外保存使用过的随机数，若记录的时间段较长，则保存和查询的开销较大。 加时间戳。该方法优点是不用额外保存其他信息。缺点是认证双方需要准确的时间同步，同步越好，受攻击的可能性就越小。但当系统很庞大，跨越的区域较广时，要做到精确的时间同步并不是很容易。 **加版本号(或序号、流水号)**。就是双方在报文中添加一个逐步递增的整数(例如 TCP)，只要接收到一个不连续的流水号报文(太大或太小)，就认定有重放威胁。该方法优点是不需要时间同步，保存的信息量比随机数方式小。缺点是一旦攻击者对报文解密成功，就可以获得流水号，从而每次将流水号递增欺骗认证端。 一次性口令。例如，和 cookie、token 机制有点像，但又不完全一样，该口令只在一次服务内有效，当服务完成后口令即为过期失效。 中间人攻击 如上图所示，这里我们假设 A-B 双方没有采用某种方式验证私匙和公匙的合法性，那么此时问题就大了，服务器错把C的公匙当作A的公匙，从而服务器发给 A 的数据完全暴露在 C 的眼皮底下。 这个例子再次告诉我们验证公匙的必要性，同时 CA 的可信程度也显得极为重要。 HTTPS什么是 HTTPSHTTPS （全称：Hyper Text Transfer Protocol over SecureSocket Layer），是以安全为目标的 HTTP 通道，在HTTP的基础上通过传输加密和身份认证保证了传输过程的安全性。 HTTPS 中，使用传输层安全性(TLS)或安全套接字层(SSL)对通信协议进行加密，即 HTTP + SSL(TLS) &#x3D; HTTPS。 阅读之前，希望你已经掌握了计算机网络方面的安全知识。 TLS 是 SSL3.0 的改进版本，它们之间的主要差别是加密的算法不同，从思想上看，它们的语义是相同的。由于 TLS 是基于 SSL 发展过来的，在下文中我们仅采用 SSL 以指代 SSL&#x2F;TLS。 SSL 握手SSL 握手阶段是整个 SSL 协议最复杂也是最核心的阶段，SSL 在握手阶段中协商算法与密匙，就像我们在计算机网络中的安全所说的，握手阶段采用的是非对称密码体制，而一旦算法与密匙协商完成，通信则使用对称密码体制。 在这一步中，SSL 利用非对称密码加密体制以协商供通信使用的对称密码体制加密的算法和密匙 和 用于报文完整性加密(MAC)的算法和密匙，此外为了防止重放攻击，SSL 采用生成随机数的方式去应对，具体的握手步骤如下： 客户明文发送它支持的密码算法的列表，连同一个客户的随机不重数。 从客户发来的列表中，服务器选择一种公匙算法(例如RSA)、一种对称算法(例如AES、DES) 和一种MAC算法(例如SHA-3)。服务器把它的算法选择和证书以及一个服务器的不重数发送(明文)给客户端，服务器还会签名还报文，此时算法协商完毕。 服务器可以要求客户端发送它的证书。 服务器生成一个前主密匙（Pre-Master Secret，PMS，预主密匙），发送给客户端。 客户端验证该证书，提取服务器公匙，生成一个前主密匙（Pre-Master Secret，PMS，预主密匙），用服务器的公匙加密 PMS，然后发送给服务器。 如果服务器要求客户端发送证书，这一步还必须发送证书。 使用 SSL 标准定义密匙导出函数，客户端与服务器同时利用双方的不重数从各自收到的 PMS 中导出相同的主密匙（Master Secret，MS）。从 MS 中导出双方需要的对称密匙以及MAC密匙，到此密匙协商完毕。 客户端利用 MAC 密匙发送所有握手报文的一个 MAC（报文摘要）。 服务器利用 MAC 密匙发送所有握手报文的一个 MAC（报文摘要）。 注意，根据上述步骤，这里有 4 个密匙，EA、MA、EB 和 MB，分别是发送方和接收方的会话密匙和 MAC 密匙，双方共享四个密匙，例如 A 利用 EA、MA 发送加密消息给 B，B 利用 EA、MA 解密；而 B 利用 EB 和 MB 发送加密消息给 A，A 利用 EB 和 MB 解密。 双方发送利用各自的密匙发送消息，使得整个会话安全更为健壮，即使有一方的密文被破解，另一方的密文仍然无法破解。 在下文中，我们可能会抽象的将这 4 个密匙当作两个密匙，E 和 M。 分析： 不重数是有必要的，利用不重数可以防止重放攻击，如果黑客原封不动的重放报文，那么服务器将会拒绝此次连接，因为不重数重复。你可能会有疑问：黑客不可以更改不重数吗？这是不可以的，因为最后会有一次汇总 MAC 签名。 数字签名也是有必要的，这是为了防止黑客劫持该证书报文，而伪装成服务器与客户端通信(黑客会更改不重数)。 最后的报文摘要也是必要的，这是为了防止黑客篡改报文，例如黑客劫持步骤 1 中的报文，删掉其中比较强的算法，迫使服务器与客户端选择较弱的算法通信。 密匙交换 ECDH算法 我们假定双方只需要两个密匙，一个密匙用于对称密码加密，定义为 E，一个密匙用于 MAC 加密，定义为 M，而不是前面说的 4 个。 前主密匙怎么生成的？主密匙又是怎么生成的？如何重主密匙中导出双方需要的密匙？ 我们先回答第三个问题：切分主密匙即可，换句话说，主密匙就是就是 E 和 M 的合并字符串，E 与 M 的长度在协商算法时就已经确认了，例如 E &#x3D; 101，M &#x3D; 011，则主密匙可能是 101011，切分时按照长度切割即可。 现在我们来讨论如何生成 PMS 以及如何从 PMS 中解析出 MS，ECDH 算法已经成为了当下主流的实现，因此我们主要介绍一下 ECDH 算法。 我们定义：$$S_A \\ 是客户端生成的一个私匙 \\S_B \\ 是服务器生成的一个私匙 \\P \\ 是一个大质数, \\ G \\ 是一个整数, \\ P、G是公开的$$假设 PMSA是客户端生成发送给服务器的前主密匙，PMSB是服务器生成发送给客户端的前主密匙，那么其计算公式为：$$PMS_A &#x3D; G^{S_A} mod \\ P \\PMS_B &#x3D; G^{S_B} mod \\ P \\$$那么经过交换后，客户端握有 PMSB，而服务器拥有 PMSA，现在它们分别对收到的 PSM 进行如下运算：$$客户端：(PMS_B)^{S_A} \\ mod \\ P &#x3D; (G^{S_B} mod \\ P)^ \\ mod \\ P &#x3D; K_1 \\服务器：(PMS_A)^{S_B} \\ mod \\ P &#x3D; (G^{S_A} mod \\ P)^ \\ mod \\ P &#x3D; K_2$$在数论中，我们有一个结论：$$(m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; (m^e \\ mod \\ n)^d \\ mod \\ n$$因此可以得：$$K_1 &#x3D; K_2 &#x3D; K$$即，双方根据收到的 PSM 经过运算后会得到一致的数据，这个 K 就是我们要的主密匙 MS，从主密匙中就可以切分出我们具体需要的密匙了！P、G 是 SSL 标准规定的，这样我们就彻底揭开了密匙交换过程的面纱。 在 SSL 握手的第 4 步中，注意到服务器发送给客户端 PSMB 是没有加密的，这意味着服务器的 SB 是暴露在外的，然而即使黑客得知了 SB 也无能为例，因为在生成 MS 的计算中，是同时需要 SA、SB 的，而 SA 是加密的，因为客户发送的 PSMA 会用服务器的公匙加密，只有服务器自己能够解密，然后得出 SA，黑客无法获取 SA ，故我们可以保证整个密匙交换过程是安全的！ 数据传输运输层仍然是使用 TCP 传输，这就可能会遭受 重排序攻击，因此 SSL 设计了 SSL 记录以防止该攻击（同时也用于关闭连接），SSL 记录位于应用层与传输层之间，应用层的数据需要被处理成 SSL 记录才会交给 TCP 层。 类型。该字段指示这是 SSL 握手报文，还是通信报文，或是 SSL 连接关闭报文。 版本。指示 SSL 报文协议，例如 TLS。 长度。指示 SSL 记录的长度，以便 SSL 处理程序从 TCP 字节流中提取出 SSL 记录（解决粘包问题）。 数据。要发送的应用程序的数据。 MAC。对整个 SSL 记录的摘要，注意，这个摘要还包含了序号。 SSL 采用序号解决重排序攻击，SSL 记录除 数据 和 MAC 外都是明文发送的（但它们都可以通过 MAC 验证，所以无须担心这些明文被修改），序号没有一个显示的字段指示，而是被保存在 MAC 中，这样更安全。双方遵守 SSL 标准以获取&#x2F;添加序号，例如可以选择 MAC 中的前 4 字节作为序号。发送方每次发送数据都会递增 SSL 序号，初始时它为 0，序号被加密在 MAC 中，通过这种方式以防止重排序攻击。 中止连接通过 SSL 记录中的类型以发出中止连接，无须担心黑客更改类型或仿造发出中止报文，因为加密的 MAC 对它进行了鉴别。服务器应答后客户端即可发出 TCP FIN。 SSL 握手抓包实践随便搜一个 HTTPS 的网站，例如：curl https://www.baidu.com，得到数据包如下： 10.252.251.95 是我自己的 IP，14.215.177.38 是服务器 IP Cilent Hello 包 Server Hello 包 Certificate 包 Server Key Exchange Server Hello Done 包这个没啥说的，就是结束 Server Hello。 Cilent Key Exchange, Change Cipher Spec, Encrypted HandShack Message 包 看名字也能猜出个大概，客户密匙交换、更改密码规范以及对整个客户端握手的MAC报文摘要，更改密码规范我们没说，这是 TLS 引入的新规范，即要求通信双方每隔一段时间后就更换新的密匙，以加强安全，本文会略过对该规范的讲解。 Server Encrypted HandShack Message剩下的就是服务器生成的握手报文摘要了，整个握手环节到此结束。 请比对一下我们之前说的步骤，看看是否吻合，结果应该是一致的，只是某些报文合并成一个报文了或者一些报文拆分成多个报文。 总结通过理论分析和实践抓包，相信理解 HTTPS 应该没有任何困难了，我们已经彻底揭开 HTTPS 神秘的面纱。 附 RSA 算法证明我们的算法结论是：$$(m^e \\ mod \\ n)^d \\ mod \\ n &#x3D; (m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; m \\tag {A}$$现在我们来指出如何选出 e、d，首先我们选择两个大素数 p、q，则取 n、z 满足：$$\\ n &#x3D; p \\times q，z &#x3D; (p - 1)(q - 1)，n &gt; m \\tag1$$现在我们选择一个数 e，满足：$$e &lt; n \\ &amp;&amp; \\ e 与 n互质$$给定 e，我们可以选择 d，使得：$$(e \\times d) \\ mod \\ z &#x3D; 1 \\tag2$$这样我们就选出了 e、d 的值，欲证明结果，需要引入数论里的一个结论，即当 n、z 满足我们上面 (1) 式，有：$$x^y \\ mod \\ n &#x3D; x^{(y \\ mod \\ z)} \\ mod \\ n \\tag3$$ 该结论由 Kaufman 提出 现在，令 x &#x3D; m，y &#x3D; ed，带入 (3) 式有：$$m^{ed} \\ mod \\ n &#x3D; m^{(ed \\ mod \\ z)} \\ mod \\ n \\tag4$$结合 (2)、(4) 可知：$$m^{ed} \\ mod \\ n &#x3D; m \\ mod \\ n &#x3D; m\\tag5$$我们都知道简单数学中有一条取模运算的分配律：$$(a \\times b) \\ mod \\ n &#x3D; [(a \\ mod \\ n) \\times (b \\ mod \\ n)] \\ mod \\ n \\tag6$$根据 (6) 式可推：$$(a^d) \\ mod \\ n &#x3D; (a \\ mod \\ n)^d \\ mod \\ n \\tag7$$结合 (5) (7) 而式有：$$m^{ed} \\ mod \\ n &#x3D; (m^e)^d \\ mod \\ n &#x3D; (m^e \\ mod \\ n)^d \\ mod \\ n &#x3D; m \\m^{ed} \\ mod \\ n &#x3D; (m^d)^e \\ mod \\ n &#x3D; (m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; m$$从而 (A) 式得证。 勘误，RSA 的算法应该并不是 1 式，1 式是数论中的一个结论，RSA 算法的核心应该是 e、d 的生成。$$(m^e \\ mod \\ n)^d \\ mod \\ n &#x3D; m^{ed} \\ mod \\ n&#x3D; (m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; m$$这是恒成立的。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"计算机网络中的安全","slug":"计算机网络中的安全","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.992Z","comments":true,"path":"post/65ff.html","link":"","permalink":"http://example.com/post/65ff.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记 计算机网络中的安全前言本文主要研究具体的算法思想而不关注具体的协议实现，在接下来的文章中我门再把目光投向 SSL&#x2F;TLS。 在具体分析之前，我们首先来思考一下计算机网络中会面临那些安全问题，只有理清楚了这些问题，我们才能知道为什么需要这些安全技术，并且和面试官谈的时候条理也能更清楚。 报文机密性 - 我们的谈话会被窃听吗？当然会，你肯定不希望你的谈话会被别人监听，所以你需要一些加密手段让别人听不懂你的谈话。 网络中也是一样，如果不对报文加密，则任何一台中间计算机都可以窃听你的报文，如果报文中包含了你的银行密码这可就完蛋了。 报文完整性 - 我收到的报文被篡改过吗？这里的完整性并不是数据丢失问题，数据丢失在应用层之下就应该通过校验码检测出来了，本文的完整性是指：报文有没有被篡改？ 你肯定不希望你的报文在网络中被别人篡改，所以必须要有些验证方法去验证报文完整性。 端点鉴别 - Alice，真的是你在给我发消息吗？你要怎么确定对方真的是 Alice，而不是 Bob 伪造的，正如在现实生活中，你要怎么确定和你裸聊的是一个女性而不是一个五旬老汉？ 带着上述三大问题，让我们一起来看看计算机科学家们提出了什么样的解决方案。 报文机密性我们要保证报文是加密的，并且只有通信双方能够解密。 对称密匙密码体制这种体制中，通信双方协商好相同的密匙和算法，发送方利用密匙加密报文，而接收方利用密匙解密报文，因为其他人不知道密匙，所以其他人无法对报文解密。 加密方法有许多种，例如最简单的凯撒密码，它将所有字母后移 k 位，例如 abc 可能被替换为 bcd，此时 k &#x3D; 1 就是密匙。 在对称密匙体制中，主要采用块密码和流密码进行加密，流密码多用于WLAN中，我们主要看看块密码。 块密码块密码的主要原理是将明文分为固定大小的块，对每一种块都维护一个映射表以加密数据。 例如，假设块大小为 3，考虑下列映射表： 例如源数据为：000, 001, 101 将会被加密成 110, 111, 010。解密逆过程即可。 那么这里的映射表就是通信双方的密匙，上述表有 8 中输入，而每种输入又可能对应 8 种输出，所以想要破解密匙需要尝试 8 的阶乘种可能，阶乘函数上升是非常快的，当块大小变得比较大时，破解块密码在理论上说是不可能的。 但是，出现了新的问题，如果我们让块大小增大，假设为 64bit，那么交互的双方都必须维护一张长达 2^64 大小的映射表(表项为输入输出)，更可怕的情况是如果映射有所修改，那么这将是一个非常大的工作量。 取而代之是采用函数来模拟输入输出表，例如对所有二进制输入流进行亦或运算得到加密输出流。当然实际的函数不可能如此简单，它依赖于具体的实现。 获取我们还可以将每个加密块打乱，以实现让更小的函数映射模拟更大的块输入输出表。 例如我们用函数来模拟 64bit 输入输出表，我们将每个 64bit 作为一个块，但我们没有维护 64bit 的输入输出表，而是将这 64bit 分为 8 个 8bit 块，对每个 8bit 块维护一个特定的函数(图中的T1、T2….)，而后对这 8个加密的 8bit 块进行 64bit 函数置乱，使得每个 8bit 块被打乱，经过一定次数循环后，此时的 64bit 块就已经被完全打乱了，就好像我们采用了 64bit 输入输出表一样。 在上图中，密匙是 9 个函数，即 8 个映射函数和 1 个置乱函数(假定循环次数已知)。这些函数都可以由一个唯一的二进制密匙生成，现在通信双方只需要维护一个二进制串即可，无须维护一个巨大的映射表。 典型的块密码协议如 DES 与 AES 都是采用函数而非预先设定的表，它们定义了一些列算法以生成这些小型函数映射与置乱函数排列，不过前提是需要一个密匙来生成。DES(就像我们例子中的) 的密匙比特串长度为 56，块大小为 64bit，在现代计算机运行速度下，256中可能破解已非难事，因此 DES 已经被淘汰成为历史了，取而代之的是 AES，AES 的密匙长度最小为 128 位，理论上是不可能破解的。 — 如何利用密匙生成 “特定小型表函数映射” 和 “特定排列函数”？ — 我也不知道。 如何提前协商密匙如何提前协商密匙在对称密匙体制中是最为重要的一个问题，这个过程必须足够安全才行。 不过解决办法总是有的，就像我们马上要讲的，可以利用非对称密匙密码体制来协商一个相同的密匙。 非对称密匙密码体制(公开密匙密码)在非堆成密匙密码体制中，假定每个网络用户都拥有私匙和公匙，私匙是个人私有的，公匙是公开在网络上的，我们定义利用私匙处理数据算法为 S，而利用公匙处理数据算法为 P。 那么，非对称密匙体制要求有如下公式成立：$$S(P(data)) &#x3D; data \\P(S(data)) &#x3D; data$$其中 data 是网络上传输的二进制比特流，现在假设 A 要像 B 发送消息 data，那么 A 直接直接用 B 的公匙(公开的)对 data 加密得到 $P_B(data)$，那么 B 可以直接利用其私匙对数据解密 $S_B(P_B(data)) &#x3D; data$，这样 B 就能够还原原文，而其他人不知道 B 的私匙，所以无法破解密文。 你可能会想，天啊，怎么可能会有这种算法！如果你真有这种想法，说明你低估了数论的魅力。 RSA算法RSA 已经成为了公开密匙密码的代言人，RSA 算法结论如下：$$(m^e \\ mod \\ n)^d \\ mod \\ n &#x3D; (m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; m \\ e, d 是经过特殊运算生成的$$通过这个神奇的结果，我们选定 e 和 d 为公匙和私匙，假定 m 为 报文 message，那么有：$$P(m) &#x3D; m^e \\ mod \\ n \\S(m) &#x3D; m^d \\ mod \\ n \\S(P(m)) &#x3D; P(m)^d \\ mod \\ n &#x3D; (m^e \\ mod \\ n)^d \\ mod \\ n &#x3D; m \\P(S(m)) &#x3D; S(m)^e \\ mod \\ n &#x3D; (m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; m$$利用这种的公匙算法和私匙算法就可以完成非对称密匙密码体制加密的任务。 RSA 的安全性依赖于目前没有一个已知的算法可以快速对一个大数进行因数分解。如果相对RSA有更深的了解可以翻到文末看看对 RSA 算法的证明，不过不清楚也没事，那毕竟是数学上的事。 RSA的缺陷是，当 e 和 d 较大时，指数运算与取模运算都是比较慢的操作，并不适合用来频繁通信，因此在未来的很长一段时间内对称密匙与非对称密匙共存都是共同的主角，在 HTTPS 中我们将看到 SSL 利用非对称密匙体制来协商一系列密匙，而在协商完毕后使用对称密匙进行通信。 不可信的公匙 Alice 要如何知道自己所知道的公匙真的是 Bob 的呢？攻击者完全宣称自己的公匙和私匙是 B 的！使用数字签名？不好意思，数字签名本身也是依赖公匙私匙体制来实现的。 我们需要一个可以信得过的机构告诉我们公匙是否合法，这种机构就是 CA（认证中心)，机构会为每个注册的实体签发一份数字证书，这个数字证书包括注册人的公匙和他的标识信息，CA 会用自己的私匙加密整数以防止服务商伪造整数(数字签名)。 在 Bob 发送公匙给 Alice 的时候会顺便发送 CA 签发的证书，Alice 比对证书来验证 Bob 的合法性。现在攻击者无法冒充 Bob 了，因为攻击者没有证书，即使攻击者也有证书，证书上也会有他的名字，Alice 可以很快知道这个 Bob 是冒充的。 报文完整性为维护报文完整性，我们需要对报文进行多对一映射(散列)，例如将 1000 比特的报文映射为 128 比特的摘要(也称报文鉴别码，MAC)，该摘要的每一个比特都与源报文相关，因此发送报文时将摘要一起发送，而接受报文时，根据报文重新计算一遍摘要，比对原先的摘要，如果不同则说明报文可能被篡改。 摘要长度须是固定的，这样接收方才能正确的取出摘要。 攻击者仅篡改报文或者仅篡改摘要都是不可行的，但如果攻击者知晓了散列函数，更改报文并同时替换摘要，此时接收方收到报文并计算摘要，并不会发现有任何问题，然而报文已经被篡改了！ 所以，为维护报文完整性，我们仍然需要一个密匙，发送方在计算散列时将密匙(字符串)附加在报文上计算摘要(发送的时候不会发送密匙)，而在接收方同时也附加密匙计算摘要，这样便解决了上述问题，因为攻击者无法不知道通信的密匙！ 注意，整个报文和摘要也需要保证报文机密性。现在需要对整个报文+摘要进行加密。 常用的密码散列函数 MD5 和 SHA-1、SHA-2、SHA-3散列函数必须要足够安全，至少要保证理论上不可能有多个不同的报文可以映射到相同的摘要，MD5声称它可以做到这一点，不过随着密码学的发展，在 2004 年后 MD5 变得不安全了，取而代之的是 SHA-1，SHA-1是 MD5 的加强版，思想上与 MD5 类似。不幸的是，2012年后，SHA-1也被指责说是不安全的，在 2015 年，破解 SHA-1甚至只需要不到一个小时，现在 SHA-1 已经被 SHA-2、SHA-3 所取代。 不过 MD5 的思想依赖未改变，后续的算法都是基于 MD5 算法思想加强的，MD5 的算法能够将任意长的报文映射为 128 bit 的摘要，过程如下： 将任意长的报文采用二进制模运算模 264 计算其余数(64位)，追加报文尾部。 在报文与余数之间填充 1~512 bit，使得填充后总长度是 512 的整数倍。填充的首位是1，后面都是0。 把追加后的报文分成一个个 512bit 数据块，每个 512 字节分为 4 个 128bit数据块，与 4 个 32bit 幻数分别进入主循环，每个幻数与每个 128bit 数据块进行交互运算，最终输出 4 个幻数，这四个幻数与这 512 字节存在某种联系，然后继续与下一个 512bit 进行循环，最终 4个幻数组合起来为 128bit 鉴别码。 更多细节可自行了解。 端点鉴别数字签名接收方 B 如何知道报文是否是 A 发送的呢？有了非对称密码加密，这点很容易做到。 A 可以用自己的私匙对 m 再次进行加密得到 C1，而 B 收到报文C1 后，B 尝试用 A 的公匙进行解密，如果得到的报文是 m，则可以确认 A 的身份，因为只有用 A 的密匙加密才能用 A 的公匙解密，所以可以确定对方持有 A 的密匙。 至于这个报文 m 到底该是什么，取决于具体的实现。它可以是确定好的一段数据，也可以是通信时的普通报文，不过大多数情况下，通常会对报文摘要(鉴别码)进行签名，因为对普通报文签名开销太大了，报文可能非常长！ 如果对摘要签名，接收方用发送方的公匙解密即可得到摘要，它可以根据报文重新计算摘要以比对正确性，如果比对不成功，可能会有两种可能，要么是签名错误、要么是报文完整性丢失，无论哪种情况 B 肯定都不会信任该报文了。 常见的攻击攻击在大类上分为主动攻击和被动攻击，主动攻击即主动发起攻击，可能涉及到报文篡改等；被动攻击则是指只是秘密的窃听你的报文，不会更改你的报文。被动攻击通常难以防范，只能采取更复杂的加密算法进行抑制，我们今天谈的主要是主动攻击。 在讨论攻击前，我们先假设我们上述讨论的所有措施全部使用，在此基础上看看还能有什么些攻击。 协议有关的攻击SYN泛洪攻击SYN 泛洪我在 TCP 总结中已经讲过了，具体就不在说了，可参考我的博客：万字长文总结TCP 重排序攻击这仍是针对 TCP 协议的攻击，即使 TCP 数据报已经被加密，但 TCP 首部仍然是明文的，攻击者可以劫持 TCP 报文，重排序(乱排序) TCP 首部中的序号字段，使得接收方接收到的字节流是乱序的，且接收方无法判断出异常，信以为真。 针对这种攻击的防御就是在 TCP 加密的数据报中继续定义序号，接收方验证加密的数据报中序号以判断顺序。 ARP欺骗ARP 协议是解析 MAC 地址的一种协议，当本地网关在自己的缓存表中没有找到 IP 对应的 MAC 地址，就会在局域网中广播消息，寻找对应 IP 的主机，而所有主机会监听 MAC 报文，如果是在寻找自己则即使回答自己的 MAC 地址。 在 Linux 上可利用 arpspoof命令来进行 ARP 地址欺骗(快去试试吧，我成功的攻击了我的好兄弟)，从而达到让局域网内用户断网的攻击，有兴趣的朋友门可以自己去试一试，篇幅有限就不在这里说了。 ARP欺骗（英语：ARP spoofing），又称ARP毒化（ARP poisoning，网络上多译为ARP病毒）或ARP攻击，是针对以太网地址解析协议（ARP）的一种攻击技术，通过欺骗局域网内访问者PC的网关MAC地址，使访问者PC错以为攻击者更改后的MAC地址是网关的MAC，导致网络不通。此种攻击可让攻击者获取局域网上的数据包甚至可篡改数据包，且可让网络上特定计算机或所有计算机无法正常连线。最早探讨ARP欺骗的文章是由Yuri Volobuev所写的《ARP与ICMP转向游戏》（ARP and ICMP redirection games）。 冒充网关 如果存在不法分子冒充网关(局域网内的，局域网外的无法通过网关)发送 ARP Request 报文，则局域网上的主机可能会错把黑客当作自己的网关，这些主机可能会更新自己的 MAC 缓存表，将黑客认为是自己的网关，则之后所有的信息都发给自己的网关。 事实上，如果我们的数据都进行了加密和报文完整性鉴别的话，那么黑客即使充当了网关也只能干巴巴的看着我们的加密数据，篡改也没有用，但是，黑客却可以让局域网内所有主机都无法访问外网，造成断网现象(或者是故意让网络变慢)，而且，黑客可以进行重放攻击。 不过，不是什么数据都会进行加密的，一旦你露出马脚，黑客就会立马攻击你，例如我们很快就会说到的 DNS 欺骗 充当中间人 —— 双重欺骗黑客充当中间人窃听主机与网关的通信，例如下图： 此时主机 PC1 以为 PC2 是网关，而网关以为 PC2 是 PC1，于是接下来所有的信息都将会发送给 PC2，这种欺骗方式是冒充网关的加强版，黑客现在不仅冒充网关，还冒充主机。 防范方法 配置 MAC 地址为静态地址，不允许改变。这种方法对网关通常不太可取，不过主机可以将他知道的网关地址配置成静态的。 网上设备可借由DHCP保留网络上各计算机的MAC地址，在伪造的ARP数据包发出时即可侦测到。通俗点说，主机在注册IP时同时注册了自己的MAC地址，使得路由完全掌握所有 IP 对应的 MAC地址，因此能够检测假冒ARP包。此方式已在一些厂牌的网上设备产品所支持。 网关更新速度更加频繁些，避免“一次跌倒，则放弃挣扎”。 嗅探网络 ARP 包，如果有不正当(对网关而言，除自己发的Request之外不应该有其他人发送 Request)或ARP包过多时，则及时告知网络管理员。 ARP欺骗亦有正当用途。其一是在一个需要登录的网上中，让未登录的计算机将其浏览网页强制转向到登录页面，以便登录后才可使用网上。另外有些设有备援机制的网上设备或服务器，亦需要利用ARP欺骗以在设备出现故障时将讯务导到备用的设备上。 [1] DNS欺骗DNS 欺骗就是攻击者冒充域名服务器的一种欺骗行为。 原理：如果可以冒充域名服务器，然后把查询的 IP 地址设为攻击者的 IP 地址，这样的话，用户上网就只能看到攻击者的主页，而不是用户想要取得的网站的主页了，这就是 DNS 欺骗的基本原理。DNS 欺骗其实并不是真的 “黑掉” 了对方的网站，而是冒名顶替、招摇撞骗罢了。 例如你正在请求某个银行的网址，你的 DNS 请求被黑客劫持了，黑客将返回了个假冒的 IP 给你，而这个假冒 IP 返回的页面和真实的一模一样，你信以为真，于是你的所有信息都暴露了。 黑客要如何劫持你的 dns 请求呢？通常有两种思路，一种是直接黑进你的 DNS Server，冒充DNS服务器，不过这点难度比较大；第二种就是常见的中间人劫持了，例如 ARP 欺骗。 此外，某些病毒可能会修改你的 host 文件(DNS 缓存文件)。 防范： 直接使用 ip 而不使用域名。 定期检查 host 文件。 防范 ARP 欺骗。 要求DNS服务器使用数字签名。 检测 DNS 应答，通常假冒的应答要比真实的应答简单的多。 采用 HTTPS 而不是 HTTP，碰到不合法证书提示立马警觉。 协议无关的攻击重放攻击重放攻击的基本原理就是把以前窃听到的数据原封不动地重新发送给接收方。很多时候，网络上传输的数据是加密过的，此时窃听者无法得到数据的准确意义。但如果他知道这些数据的作用，就可以在不知道数据内容的情况下通过再次发送这些数据达到愚弄接收端的目的。例如，有的系统会将鉴别信息进行简单加密后进行传输，这时攻击者虽然无法窃听密码，但他们却可以首先截取加密后的口令然后将其重放，从而利用这种方式进行有效的攻击。 例如下图： 你可能觉得重放攻击有什么大不了的，黑客又不知道具体的内容，如果这样想你就错了，假如你正给银行发送请求转账给别人，但此时你的所有请求都被黑客嗅探并且保存了下来，在某一时刻，黑客重放这些请求，于是你就发现你的钱全没了。 防范方法： 加随机数。该方法优点是认证双方不需要时间同步，双方记住使用过的随机数，如发现报文中有以前使用过的随机数，就认为是重放攻击。缺点是需要额外保存使用过的随机数，若记录的时间段较长，则保存和查询的开销较大。 加时间戳。该方法优点是不用额外保存其他信息。缺点是认证双方需要准确的时间同步，同步越好，受攻击的可能性就越小。但当系统很庞大，跨越的区域较广时，要做到精确的时间同步并不是很容易。 **加版本号(或序号、流水号)**。就是双方在报文中添加一个逐步递增的整数(例如 TCP)，只要接收到一个不连续的流水号报文(太大或太小)，就认定有重放威胁。该方法优点是不需要时间同步，保存的信息量比随机数方式小。缺点是一旦攻击者对报文解密成功，就可以获得流水号，从而每次将流水号递增欺骗认证端。 一次性口令。例如，和 cookie、token 机制有点像，但又不完全一样，该口令只在一次服务内有效，当服务完成后口令即为过期失效。 中间人攻击 如上图所示，这里我们假设 A-B 双方没有采用某种方式验证私匙和公匙的合法性，那么此时问题就大了，服务器错把C的公匙当作A的公匙，从而服务器发给 A 的数据完全暴露在 C 的眼皮底下。 这个例子再次告诉我们验证公匙的必要性，同时 CA 的可信程度也显得极为重要。 总结 附 RSA 算法证明我们的算法结论是：$$(m^e \\ mod \\ n)^d \\ mod \\ n &#x3D; (m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; m \\tag {A}$$现在我们来指出如何选出 e、d，首先我们选择两个大素数 p、q，则取 n、z 满足：$$\\ n &#x3D; p \\times q，z &#x3D; (p - 1)(q - 1)，n &gt; m \\tag1$$现在我们选择一个数 e，满足：$$e &lt; n \\ &amp;&amp; \\ e 与 n互质$$给定 e，我们可以选择 d，使得：$$(e \\times d) \\ mod \\ z &#x3D; 1 \\tag2$$这样我们就选出了 e、d 的值，欲证明结果，需要引入数论里的一个结论，即当 n、z 满足我们上面 (1) 式，有：$$x^y \\ mod \\ n &#x3D; x^{(y \\ mod \\ z)} \\ mod \\ n \\tag3$$ 该结论由 Kaufman 提出 现在，令 x &#x3D; m，y &#x3D; ed，带入 (3) 式有：$$m^{ed} \\ mod \\ n &#x3D; m^{(ed \\ mod \\ z)} \\ mod \\ n \\tag4$$结合 (2)、(4) 可知：$$m^{ed} \\ mod \\ n &#x3D; m \\ mod \\ n &#x3D; m\\tag5$$我们都知道简单数学中有一条取模运算的分配律：$$(a \\times b) \\ mod \\ n &#x3D; [(a \\ mod \\ n) \\times (b \\ mod \\ n)] \\ mod \\ n \\tag6$$根据 (6) 式可推：$$(a^d) \\ mod \\ n &#x3D; (a \\ mod \\ n)^d \\ mod \\ n \\tag7$$结合 (5) (7) 而式有：$$m^{ed} \\ mod \\ n &#x3D; (m^e)^d \\ mod \\ n &#x3D; (m^e \\ mod \\ n)^d \\ mod \\ n &#x3D; m \\m^{ed} \\ mod \\ n &#x3D; (m^d)^e \\ mod \\ n &#x3D; (m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; m$$从而 (A) 式得证。 勘误，RSA 的算法应该并不是 1 式，1 式是数论中的一个结论，RSA 算法的核心应该是 e、d 的生成。$$(m^e \\ mod \\ n)^d \\ mod \\ n &#x3D; m^{ed} \\ mod \\ n&#x3D; (m^d \\ mod \\ n)^e \\ mod \\ n &#x3D; m$$这是恒成立的。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"设计模式之代理模式(Proxy)","slug":"设计模式之代理模式(Proxy)","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.997Z","comments":true,"path":"post/ea8d.html","link":"","permalink":"http://example.com/post/ea8d.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 代理模式引言代理模式是非常常见的模式，在生活中的例子也非常多，例如你不好意思向你关系不太好朋友帮个忙，这时需要找一个和它关系好的应一个朋友帮忙转达，这个中间朋友就是代理对象。例如购买火车票不一定要去火车站买，可以通过12306网站或者去火车票代售点买。又如找女朋友、找保姆、找工作等都可以通过找中介完成。 代理模式的定义与特点代理模式的定义：由于某些原因需要给某对象提供一个代理以控制对该对象的访问。这时，访问对象不适合或者不能直接引用目标对象，代理对象作为访问对象和目标对象之间的中介。 考虑生活中一个常见的例子，客户想买房，房东有很多房，提供卖房服务，但房东不会带客户看房，于是客户通过中介买房。 你可能无法理解这里中介是代替客户买房还是代替房东卖房，其实这是很好理解的。我们程序编写代码是为客户服务的，中介是代替一名服务商处理业务，这种服务可能被定义为卖房，也可能被定义为帮助客户买房，但中介唯独不可能去实现买房的功能，在代码中，我们定义的是服务于客户的业务接口，而不是客户的需求接口，如果让客户和中介都去实现买房接口，那么这里的买房就是一种业务，服务于卖房的客户，这样房东就是客户端，买房的一方就是服务端。 但在生活中，买房的一方往往是客户端，卖房的才是服务端，因此这里中介和房东都要实现卖房的接口方法，换句话说，中介是代替房东卖房而不是代替客户买房。 客户将中介抽象看成房东，直接从中介手中买房(中介&#x3D;&#x3D;房东，提供卖房服务)。这里中介就是代理对象，客户是访问对象，房东是目标对象，实际由代理完全操控与目标对象的访问，访问对象客户仅与代理对象交流。 ， 代理模式的结构代理模式的结构比较简单，主要是通过定义一个继承抽象主题的代理来包含真实主题，从而实现对真实主题的访问，下面来分析其基本结构。 代理模式的主要角色如下。 抽象主题（Subject）类(业务接口类)：通过接口或抽象类声明真实主题和代理对象实现的业务方法，服务端需要实现该方法。 真实主题（Real Subject）类(业务实现类)：实现了抽象主题中的具体业务，是代理对象所代表的真实对象，是最终要引用的对象。 代理（Proxy）类：提供了与真实主题相同的接口，其内部含有对真实主题的引用，它可以访问、控制或扩展真实主题的功能。 其结构图如图 1 所示。 图1 代理模式的结构图 在代码中，一般代理会被理解为代码增强，实际上就是在原代码逻辑前后增加一些代码逻辑，而使调用者无感知。 模式实现根据代理的创建时期，代理模式分为静态代理和动态代理。 静态：由程序员创建代理类或特定工具自动生成源代码再对其编译，在程序运行前代理类的 .class 文件就已经存在了。 动态：在程序运行时，运用反射机制动态创建而成。 静态代理静态代理服务于单个接口，我们来考虑实际工程中的一个例子，现在已经有业务代码实现一个增删功能，原有的业务代码由于仍有大量程序无法改变，现在新增需求，即以后每执行一个方法输出一个日志。 我们不改变原有代码而添加一个代理来实现： //业务接口 interface DateService &amp;#123; void add(); void del(); &amp;#125; class DateServiceImplA implements DateService &amp;#123; @Override public void add() &amp;#123; System.out.println(\"成功添加！\"); &amp;#125; @Override public void del() &amp;#123; System.out.println(\"成功删除！\"); &amp;#125; &amp;#125; class DateServiceProxy implements DateService &amp;#123; DateServiceImplA server = new DateServiceImplA(); @Override public void add() &amp;#123; server.add(); System.out.println(\"程序执行add方法，记录日志.\"); &amp;#125; @Override public void del() &amp;#123; server.del(); System.out.println(\"程序执行del方法，记录日志.\"); &amp;#125; &amp;#125; //客户端 public class Test &amp;#123; public static void main(String[] args) &amp;#123; DateService service = new DateServiceProxy(); service.add(); service.del(); &amp;#125; &amp;#125; 现在，我么成功的在不改变程序原有代码的情况下，扩展了一些功能！ 我们来思考一下这种情况，当原有的业务处理由于某种原因无法改变，而目前又需要扩展一些功能，此时可以通过代理模式实现： 如上图所示，我们原有的业务十分庞大，牵一发而动全身，难以修改，而现在需要扩展一些功能，这里就需要代理模式实现，在纵向代码之间，横向扩展一些功能，这也是所谓的面向切面编程。 如果你设计思想比较良好的话，你很快就能发现上面代码的不足：一个代理只能服务于一个特定的业务实现类，假设我们又另外一个类也实现了业务接口，即class DateServiceImplB implements DateService，发现想要扩展该类必须要为其也编写一个代理，扩展性极低。想要解决这个问题也是很简单的，我们面向接口编程而不是面向实现，我们给代理类持有接口而不是持有具体的类： class DateServiceProxy implements DateService &amp;#123; DateService server; public DateServiceProxy(DateService server) &amp;#123; this.server = server; &amp;#125; &amp;#125; 这样一个代理就可以同时代理多个实现了同一个业务接口的业务，但这种方式必须要求客户端传入一个具体的实现类，这样客户就必须要获得具体目标对象实例，目标对象就直接暴露在访问对象面前了，对于某些情况这是不可接受的，例如你想获得某资源，但需要一定的权限，这时由代理控制你对目标资源对象的访问，不能由你直接区去访问，这是代理就必须将目标资源对象牢牢的控制在自己手中，后面会讲到这其实就是保护代理。但在这里，这种方法是可以接受的，并且带给程序较高的灵活性。 动态代理我们为什么需要动态代理？要理解这一点，我们必须要知道静态代理有什么不好，要实现静态代理，我们必须要提前将代理类硬编码在程序中，这是固定死的，上面也提到过，有一些代理一个代理就必须要负责一个类，这种情况下代理类的数量可能是非常多的，但我们真的每个代理都会用上吗？例如，在普通的项目中，可能99%的时间都仅仅只是简单的查询，而不会设计到增删功能，此时是不需要我们的增删代理类的，但在静态代理中，我们仍然必须硬编码代理类，这就造成了不必要的资源浪费并且增加了代码量。 动态代理可以帮助我们仅仅在需要的时候再创建代理类，减少资源浪费，此外由于动态代理是一个模板的形式，也可以减少程序的代码量，例如在静态代码示例中，我们在每个方法中加入System.out.println(&quot;程序执行***方法，记录日志.&quot;);，当业务方法非常多时，我们也得为每个业务方法加上记录日志的语句，而动态代理中将方法统一管理，无论几个业务方法都只需要一条记录语句即可实现，具体请看代码。 动态代理采用反射的机制，在运行时创建一个接口类的实例。在JDK的实现中，我们需要借助Proxy类和InvocationHandler接口类。 在运行期动态创建一个interface实例的方法如下： 定义一个类去实现InvocationHandler接口，这个接口下有一个invoke(Object proxy, Method method, Object[] args) 方法，它负责调用对应接口的接口方法； 调用代理类的方法时，处理程序会利用反射，将代理类、代理类的方法、要调用代理类的参数传入这个函数，并运行这个函数，这个函数是实际运行的，我们在这里编写代理的核心代码。 通过Proxy.newProxyInstance()创建某个interface实例，它需要3个参数： 使用的ClassLoader，通常就是接口类的ClassLoader； 需要实现的接口数组，至少需要传入一个接口进去； 一个处理程序的接口。 这个方法返回一个代理类$Proxy0，它有三个参数，第一个通常是类本身的ClassLoader，第二个是该类要实现的接口，例如这里我们要实现增删接口，第三个是一个处理程序接口，即调用这个类的方法时，这个类的方法会被委托给该处理程序，该处理程序做一些处理，这里对应了上面这个方法，通常设置为this。 将返回的Object强制转型为接口。 来看一下具体实现： import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; //业务接口 interface DateService &amp;#123; void add(); void del(); &amp;#125; class DateServiceImplA implements DateService &amp;#123; @Override public void add() &amp;#123; System.out.println(\"成功添加！\"); &amp;#125; @Override public void del() &amp;#123; System.out.println(\"成功删除！\"); &amp;#125; &amp;#125; class ProxyInvocationHandler implements InvocationHandler &amp;#123; private DateService service; public ProxyInvocationHandler(DateService service) &amp;#123; this.service = service; &amp;#125; public Object getDateServiceProxy() &amp;#123; return Proxy.newProxyInstance(this.getClass().getClassLoader(), service.getClass().getInterfaces(), this); &amp;#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123; var result = method.invoke(service, args); // 让service调用方法，方法返回值 System.out.println(proxy.getClass().getName() + \"代理类执行\" + method.getName() + \"方法，返回\" + result + \"，记录日志！\"); return result; &amp;#125; &amp;#125; //客户端 public class Test &amp;#123; public static void main(String[] args) &amp;#123; DateService serviceA = new DateServiceImplA(); DateService serviceProxy = (DateService) new ProxyInvocationHandler(serviceA).getDateServiceProxy(); serviceProxy.add(); serviceProxy.del(); &amp;#125; &amp;#125; /* 成功添加！ $Proxy0代理类执行add方法，返回null，记录日志！ 成功删除！ $Proxy0代理类执行del方法，返回null，记录日志！ */ 我们代理类是通过Proxy.newProxyInstance(this.getClass().getClassLoader(),service.getClass().getInterfaces(), this);方法得到的，这个方法中，第二个参数我们传入了类service的接口部分，即DateService，在底层通过该接口的字节码帮我们创建一个新类$Proxy0，该类具有接口的全部方法。第三个参数是一个处理程序接口，此处传入this即表明将方法交给ProxyInvocationHandler 的接口即InvocationHandler的invoke方法执行。 $Proxy并不具备真正处理的能力，当我们调用$$Proxy0.add()时，会陷入invoke处理程序，这是我们编写核心代码的地方，在这里var result = method.invoke(service, args);调用目标对象的方法，我们可以编写代理的核心代码。 我们还可以编写一个更加万能的接口，让其能扩展不同的业务接口，在静态代理中，如果要扩展两个接口我们最少要编写两个代理类，尽管这两个代理类的代码是一样的，通过一个向上转型，动态代理可以更好的实现这一功能，能够极大的较少代码量。 import java.lang.reflect.InvocationHandler; import java.lang.reflect.Method; import java.lang.reflect.Proxy; //业务接口 interface DateService &amp;#123; void add(); void del(); &amp;#125; class DateServiceImplA implements DateService &amp;#123; @Override public void add() &amp;#123; System.out.println(\"成功添加！\"); &amp;#125; @Override public void del() &amp;#123; System.out.println(\"成功删除！\"); &amp;#125; &amp;#125; interface OperateService &amp;#123; void plus(); void subtract(); &amp;#125; class OperateServiceImplA implements OperateService &amp;#123; @Override public void plus() &amp;#123; System.out.println(\"+ 操作\"); &amp;#125; @Override public void subtract() &amp;#123; System.out.println(\"- 操作\"); &amp;#125; &amp;#125; //w class ProxyInvocationHandler implements InvocationHandler &amp;#123; private Object service; public ProxyInvocationHandler(Object service) &amp;#123; this.service = service; &amp;#125; public Object getDateServiceProxy() &amp;#123; return Proxy.newProxyInstance(this.getClass().getClassLoader(), service.getClass().getInterfaces(), this); &amp;#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &amp;#123; var result = method.invoke(service, args); // 方法返回值 System.out.println(proxy.getClass().getName() + \"代理类执行\" + method.getName() + \"方法，返回\" + result + \"，记录日志！\"); return result; &amp;#125; &amp;#125; //客户端 public class Test &amp;#123; public static void main(String[] args) &amp;#123; DateService dateServiceA = new DateServiceImplA(); DateService dateServiceProxy = (DateService) new ProxyInvocationHandler(dateServiceA).getDateServiceProxy(); dateServiceProxy.add(); dateServiceProxy.del(); OperateService operateServiceA = new OperateServiceImplA(); OperateService operateServiceProxy = (OperateService) new ProxyInvocationHandler(operateServiceA).getDateServiceProxy(); operateServiceProxy.plus(); operateServiceProxy.subtract(); &amp;#125; &amp;#125; /* 成功添加！ $Proxy0代理类执行add方法，返回null，记录日志！ 成功删除！ $Proxy0代理类执行del方法，返回null，记录日志！ + 操作 $Proxy1代理类执行plus方法，返回null，记录日志！ - 操作 $Proxy1代理类执行subtract方法，返回null，记录日志！ */ 总结代理模式通常有如下几种用途： 远程代理，这种方式通常是为了隐藏目标对象存在于不同地址空间的事实，方便客户端访问。例如，用户申请某些网盘空间时，会在用户的文件系统中建立一个虚拟的硬盘，用户访问虚拟硬盘时实际访问的是网盘空间。 虚拟代理，这种方式通常用于要创建的目标对象开销很大时。例如，下载一幅很大的图像需要很长时间，因某种计算比较复杂而短时间无法完成，这时可以先用小比例的虚拟代理替换真实的对象，消除用户对服务器慢的感觉。 保护代理，当对目标对象访问需要某种权限时，保护代理提供对目标对象的受控保护，例如，它可以拒绝服务权限不够的客户。 智能指引，主要用于调用目标对象时，代理附加一些额外的处理功能。例如，增加计算真实对象的引用次数的功能，这样当该对象没有被引用时，就可以自动释放它(C++智能指针)；例如上面的房产中介代理就是一种智能指引代理，代理附加了一些额外的功能，例如带看房等。 代理模式的主要优点有： 代理模式在客户端与目标对象之间起到一个中介作用和保护目标对象的作用； 代理对象可以扩展目标对象的功能； 代理模式能将客户端与目标对象分离，在一定程度上降低了系统的耦合度，增加了程序的可扩展性; 其主要缺点是： 静态代理模式会造成系统设计中类的数量增加，但动态代理可以解决这个问题； 在客户端和目标对象之间增加一个代理对象，会造成请求处理速度变慢； 增加了系统的复杂度； 与装饰者模式我们实现的代理模式和装饰者模式十分相像，但他们的目的不同。在上面我们提到过，某些代理会严格将访问对象和受控对象分离开来，一个代理仅仅只负责一个类，这与装饰器模式是不同的，对于装饰器模式来说，目标对象就是访问对象所持有的。此外虚拟代理的实现与装饰者模式实现是不同的，虚拟代理一开始并不持有远程服务器的资源对象，而是对域名和文件名进行解析才得到该对象，这与我们上面的代码都是不同的，在我们的代码中我们要么传入一个实例，要么让代理持有一个实例，但在虚拟代理中，我么传入一个虚拟的文件资源，虚拟代理对远程服务器进行解析才会获得真实的对象实例，这一点也是不同的。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"设计模式之单例模式(Singleton)","slug":"设计模式之单例模式(Singleton)","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.998Z","comments":true,"path":"post/b4c2.html","link":"","permalink":"http://example.com/post/b4c2.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 设计动机正如其名，单例模式保证一个类只有一个实例，那么为什么需要设计单例模式？ 对一些类来说，只有一个实例是很重要的，例如一台电脑只应该由一个文件系统，生产厂商不应该为一台电脑配置两个文件系统；一个应用应该有一个专属的日志对象，而不应该一会儿写到这里一会儿写到那里；一个程序中往往只有一个线程池，由一个线程池管理线程，而不应该使用多个线程池，那样会使得线程乱套并且难以维护；在抽象工厂中，具体的工厂类也只应该存在一个…… 诸如此类的要求，我们都需要保证一个类只有一个实例，此时便可以使用单例模式。 设计我们必须要防止用户实例化多个对象，解决办法是让类自己保存它的唯一实例，并将构造函数对外隐藏，并暴露特定静态方法返回唯一实例，这样用户将无法自己实例化多个对象而只能通过类对外暴露的静态方法获取唯一实例。 代码示例假设需求如下：一个应用程序的全局状态中需要同一个日志对象。 一、懒汉模式懒汉模式并不直接初始化实例，而是等到实例被使用时才初始化它，避免不必要的资源浪费。 //日志文件类 class LogFile &amp;#123; //唯一实例 private static LogFile logFile = null; //构造方法对外隐藏 private LogFile()&amp;#123;&amp;#125;; //对外暴露的方法 public static LogFile getInstance() &amp;#123; //懒汉模式 if (logFile == null) &amp;#123; logFile = new LogFile(); &amp;#125; return logFile; &amp;#125; &amp;#125; public class Test &amp;#123; public static void main(String[] args) &amp;#123; var s1 = LogFile.getInstance(); var s2 = LogFile.getInstance(); System.out.println(s1 == s2); //输出true，产生的是同一个对象 &amp;#125; &amp;#125; 这里的代码在单线程中运行良好，logFile属于临界区资源，因此这样的写法是线程不安全的，一开始实例为null，线程A执行完if判断句后在执行logFile = new LogFile()前被调度到线程B，此时线程B看到的实例也为空，因为A还没有初始化，所以线程B初始化实例，当回到线程A时，线程A将继续执行构造logFile的语句，此时logFile已经被初始化两次了，它们A与B拿到的已经不是同一个实例了。 一个简单的解决办法是为它们上锁： public static LogFile getInstance() &amp;#123; synchronized (LogFile.class) &amp;#123; //懒汉模式 if (logFile == null) &amp;#123; logFile = new LogFile(); &amp;#125; &amp;#125; return logFile; &amp;#125; 但是这样上锁效率太低了，还不如采用饿汉式，因为即时当logFile不为空时，多个线程也必须排队获取实例，而事实上并不需要排队，当logFile不为空时，多个线程应当可以同时获取logFile实例，因为它们仅仅只是读取实例而并不会更改实例，共享读是线程安全的。 一个更好的解决办法是采用双重检查锁定： public static LogFile getInstance() &amp;#123; if (logFile == null) &amp;#123; synchronized (LogFile.class) &amp;#123; //懒汉模式 if (logFile == null) &amp;#123; logFile = new LogFile(); &amp;#125; &amp;#125; &amp;#125; return logFile; &amp;#125; 通过在外层加一重判断，我们解决了上述所说的问题，现在代码的效率已经够高了——仅仅在最开始的阶段才会涉及到加锁。 注意，上面的代码仍然是线程不安全的，如果要想线程安全，我们必须为logFile实例的声明加上volatile 关键字，即： private volatile static LogFile logFile; 要想理解这一点，我们必须要理解new一个对象的过程，大致的过程如下： 申请内存空间，对空间内字段采用默认初始化(此时对象为null)。 调用类的构造方法，进行初始化(此时对象为null)。 返回地址(执行完成后对象不为null)。 如果不加volatile关键字，Java虚拟机可能在保证可串行化的前提下发生指令重排，即虚拟机可能先执行第3步再执行第2步(比较罕见的)，初始化对象时虚拟机考虑的仅仅只是单线程的情况，此时的指令重排并不会影响到单线程的运行，因此为了加快速度，指令重排这种情况是可能出现的。 如果从多线程角度来看，如果发生了指令重排，线程A在new对象时执行第一部后先执行了第三步，此时对象已经不为null了，但是对象还没被构造好，虽然这个时候线程A还持有锁，但这对线程B毫无影响——线程B闯入发现对象不为null而直接拿走一个还未构造完全的对象实例——根本不会通过第一层判断而申请锁。 加上volatile关键字可以保证可见性并且禁止指令重排。 但从解决问题的角度来看，我们还有更好的解决办法——静态内部类： //日志文件类 class LogFile &amp;#123; //实例交给静态内部类保管 private static class LazyHolder &amp;#123; private static LogFile logFile = new LogFile(); &amp;#125; //构造方法对外隐藏 private LogFile()&amp;#123;&amp;#125;; //对外暴露的方法 public static LogFile getInstance() &amp;#123; return LazyHolder.logFile; &amp;#125; &amp;#125; public class Test &amp;#123; public static void main(String[] args) &amp;#123; var s1 = LogFile.getInstance(); var s2 = LogFile.getInstance(); System.out.println(s1 == s2); //输出true，产生的是同一个对象 &amp;#125; &amp;#125; 静态内部类的效果是最好的，静态内部类只有在其成员变量或方法被引用时才会加载，也就是说只有当我们第一次访问类的时候实例才会被初始化完成，我们将实例委托给静态内部类帮忙初始化，虚拟机对静态内部类的加载是线程安全的，我们避免自己采用上锁机制而委托给虚拟机，这样的效率是非常高的。 懒汉式可以避免无用垃圾对象的产生——只有在它们使用时才初始化它，但我们也必须为此多编写一些代码来保证它的安全性，如果某个类并不是很常用的话，使用懒汉式可以一定程度的节约资源。 二、饿汉式饿汉式模式在加载时便初始化单例，使得用户获取时实例已经被初始化。 //日志文件类 class LogFile &amp;#123; //唯一实例 private static LogFile logFile = new LogFile(); //构造方法对外隐藏 private LogFile()&amp;#123;&amp;#125;; //对外暴露的方法 public static LogFile getInstance() &amp;#123; return logFile; &amp;#125; &amp;#125; public class Test &amp;#123; public static void main(String[] args) &amp;#123; var s1 = LogFile.getInstance(); var s2 = LogFile.getInstance(); System.out.println(s1 == s2); //输出true，产生的是同一个对象 &amp;#125; &amp;#125; 饿汉式是线程安全的，因为logFile已经被初始完成，因此饿汉式比懒汉式效率更高，但与此同时，如果实例在全局都没用上的话，饿汉式模式将会产生垃圾从而消耗资源。 优缺点总结主要优点: 提供了对唯一实例的受控访问。 系统中内存只存在一个对象，节约系统的的资源。 单例模式可以允许可变的数目的实例。 主要缺点: 可扩展性比较差。 单例类，职责过重，在一定程度上违背了”单一职责原则”。 滥用单例将带来一些负面的问题，如为了节省资源将数据库连接池对象设计为单例类，可能会导致共享连接池对象的程序过多而出现的连接池溢出(大家都用一个池子，可能池子吃不消)，如果实例化对象长时间不用系统就会被认为垃圾对象被回收，这将导致对象状态丢失。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"设计模式之工厂模式(Factory)","slug":"设计模式之工厂模式(Factory)","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:16.998Z","comments":true,"path":"post/6982.html","link":"","permalink":"http://example.com/post/6982.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 模式类型工厂模式属于创建者模式，与对象的创建有关，其中工厂方法模式用于类，而抽象工厂模式用于对象。创建型类模式将对象的部分创建工作延迟到子类，由子类创建对象；而创建型对象模式将它延迟到另一个对象中。 模式设计意图工厂模式将复杂的对象创建工作隐藏起来，而仅仅暴露出一个接口供客户使用，具体的创建工作由工厂管理而对用户封装，将对象的创建和使用分离开来，降低耦合度，便于管理，能够很好的支持变化。 对于某些类而言，其对象的创建可能是需要一系列复杂的参数或大量准备代码，当这个任务由客户完成时，如果客户创建多个复杂对象，先不说这些代码可能难以编写，也会造成不必要的代码重复，交给工厂产生对象则不会造成代码重复，因为工厂中的代码写一次便可以复用无数次，能够减少代码量，并且用户无需关注这些难以编写的代码，增加可读性，例如Spring框架中的beanFactory便是如此。 此外，将对象的创建和使用分离开来，所有的创建工作由工厂管理，工厂可以管理类并适应相应业务变化，而无须对客户暴露，例如如果某个产品A升级为AA，我们可以直接在工厂中将return new A()改为return new AA()，客户仍然调用factory.createProductA()而无须变更代码，如果客户是通过new A()的形式创建对象，那么我们还需要找到所有的代码并把它们改成new AA()，这在一个庞大的工程中是一项巨大的任务。 当客户使用的对象可能发生变化时，例如一开始使用A产品而后来想使用B产品时，普通的方式我们可能不得不更改所有的new方法，如果使用简单工厂模式，可以仅仅更改配置文件而无须更改客户代码来完成这个目的，如果使用工厂方法模式或者抽象工厂模式，那么可以调整工厂的构造函数或者使用set注入来达到这个目的，大大减少因变化而造成的不适应性。 上述所说的一切都归功于将类的使用与创建解耦，这也就是整个工厂模式的核心思想与设计意图。无论何时，高内聚、低耦合永远都是编写需要考虑到的地方。 工厂模式具体分为简单工厂、工厂方法和抽象工厂模式，这些方法都符合上述设计意图，但同时又满足不同的需求、适应不同的场景。 简单工厂(Simple Factory)设计定义一个创建对象的接口，创建一个子类通过传入的参数决定创建哪一种实例。 适用场景 工厂类负责生产的对象较少。 一个类不确定它所必须创建的对象的类的时候，具备不确定性。 客户知道需要传入工厂的参数而并不关心具体的类创建逻辑。 代码实例假设我们具有如下需求：一家游戏厂商开发了A、B、C三种游戏，某个测试者被要求试玩相应游戏。 //定义游戏接口 interface Game &amp;#123; public void play(); &amp;#125; //A游戏 class GameA implements Game&amp;#123; public void play()&amp;#123;System.out.println(\"Playing GameA\");&amp;#125;; &amp;#125; //B游戏 class GameB implements Game&amp;#123; public void play()&amp;#123;System.out.println(\"Playing GameB\");&amp;#125;; &amp;#125; //C游戏 class GameC implements Game&amp;#123; public void play()&amp;#123;System.out.println(\"Playing GameC\");&amp;#125;; &amp;#125; class GameFactory &amp;#123; public Game createGame(char type) &amp;#123; switch (type) &amp;#123; case 'A': return new GameA(); case 'B': return new GameB(); case 'C': return new GameC(); &amp;#125; return null; &amp;#125; &amp;#125; //测试者(客户)类 class Tester &amp;#123; private char type; public Tester(char type) &amp;#123; this.type = type; &amp;#125; public void testGame() &amp;#123; GameFactory gameFactory = new GameFactory(); //通过简单工厂获取游戏实例 Game game = gameFactory.createGame(type); //试玩游戏 game.play(); &amp;#125; &amp;#125; //代码测试 public class Test &amp;#123; public static void main(String[] args) &amp;#123; //要求测试者试玩游戏A Tester tester = new Tester('A'); tester.testGame(); &amp;#125; &amp;#125; 在测试代码Test类中我们是这样写的: Tester tester = new Tester('A'); 事实上在工程中我们并不直接写类型，而是导入配置文件: Tester tester = new Tester(config.GAME_TYPE); 这样如果我们想要让测试者测试不同的游戏时，就可以修改config配置文件中的GAME_TYPE信息(还可以利用反射)，这就使得代码能够适应变化。 如果每个类的构造准备工作都是一致的初始化(上述代码没有任何准备工作而直接返回)，可以考虑采用哈希表存储参数与实例之间的关系，可以减少大量if-else语句。在这种情况下我们需要提前在哈希表中初始化并存储相关实例而没有考虑程序是否会用上，也许会造成不必要的资源浪费，但另一方面，我们每次获取实例都是返回HashMap中实例的克隆，这样比new操作效率更高——这其实就是享元设计模式。不过，大多数情况下我们仍需要对不同的实例进行不同的初始化操作，此时仍需要大量的判断语句。（如果类真的具有一致性而采用Map缓存，事实上这种设计模式就是策略模式，策略模式是编程中最基本的设计模式，我们大多都在有意无意的使用——定义算法接口并由子类实现不同算法，定义相关类以选择这些子类。） UML类图 总结简单工厂模式的结构非常简单，易于使用，当对象实例较少时可以考虑简单工厂模式。通过UML类图可以发现，简单工厂模式对客户封装了具体创建类的逻辑过程，所以我们可以在工厂中进行一些复杂的初始化或其他操作帮助客户减轻压力，用户仅仅需要知道传入的具体参数即可获得相应实例。简单工厂模式也可以应对适量的业务变化而不影响客户代码，符合工厂模式的设计意图。 简单工厂模式的缺点也是很明显的，正如它的名字，它仅仅适用于较为简单的场景，而对稍加复杂的情况会使得简单工厂无比庞大而难以维护，当增加或减少实例时，我们必须对工厂进行较为大量的修改，这违反了开闭原则。此外，当工厂出现BUG时，整个程序将会崩溃。 工厂方法(Factory Method)设计定义一个创建对象的接口，由子类决定实例化哪一个类，工厂方法将类的实例化推迟到子类实现。 适用场景 一个类不确定它所必须创建的对象的类的时候，具备不确定性。 你期望获得较高的扩展性。 当一个类希望由它的子类来指定它所创建的对象。 当类将创建对象的职责委托给多个帮忙子类的中的某一个，并且客户知道将要使用哪一个帮忙子类。 代码实例假设我们同样具有需求：一家游戏厂商开发了A、B、C三种游戏，测试者被要求试玩相应游戏。 //定义游戏接口 interface Game &amp;#123; public void play(); &amp;#125; //A游戏 class GameA implements Game&amp;#123; public void play()&amp;#123;System.out.println(\"Playing GameA\");&amp;#125;; &amp;#125; //B游戏 class GameB implements Game&amp;#123; public void play()&amp;#123;System.out.println(\"Playing GameB\");&amp;#125;; &amp;#125; //C游戏 class GameC implements Game&amp;#123; public void play()&amp;#123;System.out.println(\"Playing GameC\");&amp;#125;; &amp;#125; //定义工厂(父类) interface GameFactory &amp;#123; Game createGame(); &amp;#125; //帮忙子类，游戏A工厂 class GameAFactory implements GameFactory &amp;#123; @Override public Game createGame() &amp;#123; return new GameA(); &amp;#125; &amp;#125; //帮忙子类，游戏B工厂 class GameBFactory implements GameFactory &amp;#123; @Override public Game createGame() &amp;#123; return new GameB(); &amp;#125; &amp;#125; //帮忙子类，游戏C工厂 class GameCFactory implements GameFactory &amp;#123; @Override public Game createGame() &amp;#123; return new GameC(); &amp;#125; &amp;#125; //测试者(客户)类 class Tester &amp;#123; private GameFactory gameFactory; public Tester(GameFactory gameFactory) &amp;#123; this.gameFactory = gameFactory; &amp;#125; public void testGame() &amp;#123; //通过工厂获取游戏实例 Game game = gameFactory.createGame(); //试玩游戏 game.play(); &amp;#125; &amp;#125; //代码测试 public class Test &amp;#123; public static void main(String[] args) &amp;#123; //要求测试者1试玩游戏A GameFactory gameFactory = new GameAFactory(); Tester tester1 = new Tester(gameFactory); tester1.testGame(); //要求测试者2也试玩游戏A Tester tester2 = new Tester(gameFactory); tester2.testGame(); //... 测试者1000也试玩游戏A &amp;#125; &amp;#125; 我们可以通过更改构造函数或使用set方法来更改工厂，可以更改较少的代码就能让所有测试者都更改试玩游戏(最坏情况下仍然需要更改较多代码)，具有较好的灵活性。 UML类图 总结工厂方法模式其实就是简单工厂模式一种扩展，工厂方法模式具有高扩展性，如果后续想要增加类时，直接编写一个新的帮忙子类即可，可以很方便的生产或切换产品，而无需修改现有的代码，完美符合了开闭原则·。 工厂方法模式是工程中较为理想的一种设计模式，但它的缺点也是明显的，当客户新建一个产品时，就不得不创建一个产品工厂，增加了代码量，而且对于父类接口难以进行修改，因为一旦修改接口，就必须要对众多的帮忙子类进行修改。 ​ 抽象工厂(Abstract Factory)设计提供一个接口以创建一系列相关或互相依赖的对象，将类的实例化延迟到子类。 适用场景 代码需要与多个不同系列的相关产品交互， 但是由于无法提前获取相关信息， 或者出于对未来扩展性的考虑， 你不希望代码基于产品的具体类进行构建而仅希望显示创建它们的接口。 需要创建的对象是一系列相互关联或相互依赖的产品族。 当一系列中的产品被设计为一起使用时，在一个应用中仅使用同一个系列中的对象。 代码实例假设具有需求如下：一家品牌鞋垫可以生产大号尺寸的鞋子和对应鞋垫和小号尺寸的鞋子和对应鞋垫，现在有一个客户想要购买一双鞋子穿。 //定义鞋子接口 interface Shoe &amp;#123; void printShone(); &amp;#125; //定义鞋垫接口 interface Insole &amp;#123; void printInsole(); &amp;#125; //具体产品，大号鞋子 class LargeShoes implements Shoe &amp;#123; @Override public void printShone() &amp;#123; System.out.println(\"大号鞋子\"); &amp;#125; &amp;#125; //具体产品，大号鞋垫 class LargeInsole implements Insole &amp;#123; @Override public void printInsole() &amp;#123; System.out.println(\"大号鞋垫\"); &amp;#125; &amp;#125; //具体产品，小号鞋子 class SmallShoes implements Shoe &amp;#123; @Override public void printShone() &amp;#123; System.out.println(\"小号鞋子\"); &amp;#125; &amp;#125; //具体产品，小号鞋垫 class SmallInsole implements Insole &amp;#123; @Override public void printInsole() &amp;#123; System.out.println(\"小号鞋垫\"); &amp;#125; &amp;#125; //定义完整鞋子工厂接口，一个完整的鞋子由鞋子和鞋垫组成 interface CompleteShoeFactory &amp;#123; Shoe createShoe(); Insole createInsole(); &amp;#125; //大型鞋子工厂，生产配套的大号鞋子和鞋垫 class CompleteLargeShoeFactory implements CompleteShoeFactory &amp;#123; @Override public Shoe createShoe() &amp;#123; return new LargeShoes(); &amp;#125; @Override public Insole createInsole() &amp;#123; return new LargeInsole(); &amp;#125; &amp;#125; //小号鞋子工厂，生产配套的小号鞋子和鞋垫 class CompleteSmallShoeFactory implements CompleteShoeFactory &amp;#123; @Override public Shoe createShoe() &amp;#123; return new SmallShoes(); &amp;#125; @Override public Insole createInsole() &amp;#123; return new SmallInsole(); &amp;#125; &amp;#125; //客户类，购买鞋子 class Customer &amp;#123; private CompleteShoeFactory factory; public Customer(CompleteShoeFactory factory) &amp;#123; this.factory = factory; &amp;#125; //购买完整的鞋 public void buyCompleteShoe() &amp;#123; Shoe myShoe = factory.createShoe(); myShoe.printShone(); Insole myInsole = factory.createInsole(); myInsole.printInsole(); System.out.println(\"我已经买了配套产品，终于有鞋穿了！\"); &amp;#125; &amp;#125; //代码测试类 public class Test &amp;#123; public static void main(String[] args) &amp;#123; //购买大号鞋子 //这里通常使用单例模式生成工厂 CompleteShoeFactory factory = new CompleteLargeShoeFactory(); Customer customer = new Customer(factory); customer.buyCompleteShoe(); &amp;#125; &amp;#125; 理解抽象工厂需要创建的对象是一系列相互关联或相互依赖的产品族的好处，例如这里的大号鞋子配大号鞋垫，小号鞋子配小号鞋垫，这就是对应的产品族，消费者要么买大号产品，要么买小号产品，不可能买大号鞋配小号鞋垫，这就使得一个具体工厂类在一个应用中仅出现一次，因此具体工厂类通常使用单例设计模式创建，由于一个具体工厂类在一个应用中仅出现一次，那么变更产品系列将十分简单，我们仅需要修改一行代码——创建工厂时的代码，这具有极大的灵活性。 UML类图 总结抽象工厂模式用于创建的对象是一系列相互关联或相互依赖的产品族，易于交换产品系列，能够较好的应对变化。因为一个对象的产品被设计成一起工作，因此也利于维护产品的一致性，如果采用简单工厂模式，那么得创建四个工厂——大鞋子工厂、大鞋垫工厂、小鞋子工厂和鞋垫工厂，引入的类也增多，而且用户可能会不小心创建大鞋子和小鞋垫，使得结果不适配，采用抽象工厂模式则可以较好的解决这个问题。 抽象工厂模式的缺点在于当工厂接口的功能越来越多时，它会变得越来越笨重，因为所有的子类都必须要去实现这里接口，这就要保证不同系列的产品种类都是一致的，此外，后续想要增加新种类或者删减种类，都不得不对所有子类做出更改。 结语工厂模式包括简单工厂模式，工厂方法模式，还是抽象工厂模式，它们在形式和特点上是极为相似的，而且最终目的都是为了解耦。在使用时，我们不必去在意这个模式到底工厂方法模式还是抽象工厂模式，因为他们之间的演变常常是令人琢磨不透的。经常你会发现，明明使用的工厂方法模式，当新需求来临，稍加修改，加入了一个新方法后，由于类中的产品构成了不同等级结构中的产品族，它就变成抽象工厂模式了；而对于抽象工厂模式，当减少一个方法使的提供的产品不再构成产品族之后，它就演变成了工厂方法模式。 所以，在使用工厂模式时，只需要设计的六大原则的目的是否达到了。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"设计模式之建造者模式(Builder)","slug":"设计模式之建造者模式(Builder)","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:17.001Z","comments":true,"path":"post/3cc4.html","link":"","permalink":"http://example.com/post/3cc4.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 设计意图为了将复杂对象的构建与它的表示分离，使得对象可以通过不同的表示创建出来。 例如对一个迷宫可能有墙、房间和门，并且数量不计。迷宫可能仅由一堵墙构成，也可能由两堵墙构成，也可能由2个房间加一扇门构成…如果采用重载的方式生产迷宫，代码量是难以计数的、无比庞大的。 针对一个对象拥有大量的组件（迷宫可以拥有很多墙或房间或门），而构造这个对象对其组件的使用又是不确定的这一问题（使用墙、房间、门的数量是不确定的)，想要精细的控制构建过程，此时可以采用建造者模式解决问题。 建造者模式的意图是为了构造对象，因此它属于创建型模式。 适用场景 构造过程中，被构造的对象具有不同的表示。 一些基本部件不会变，而其组合经常变化的时候。 需要生成的对象内部属性本身相互依赖。 设计指派一个建造者交给总指挥，由总指挥设计如何建造，由建造者实际建造，最终建造者将产品交给总指挥，用户从总指挥手中完成交付。 这样的流程是非常人性化的，例如我们实际的房子装修也是如此，我们请一些工人们，再请一个工人头目设计建造思路，指导这些工人该如何装修，我们接下来只与工人头目打交道，由工人头目将装修好的房子交付给我们。 代码示例考虑上述的迷宫问题： //定义迷宫类 class Maze &amp;#123; public void setRoom(int x, int y, int roomId) &amp;#123; System.out.println(\"在[\" + x + \",\" + y + \"]处建立一座编号为\" + roomId + \"的房间\"); //保存相关信息 &amp;#125; public void setDoor(int Id1, int Id2) &amp;#123; System.out.println(\"在组件编号为\" + Id1 + \"和组件编号为\" + Id2 + \"之间建立一扇门\"); //保存相关信息 &amp;#125; public void setBarrier(int x, int y, int barrierId) &amp;#123; System.out.println(\"在[\" + x + \",\" + y + \"]处建立一座编号为\" + barrierId + \"的障碍物\"); //保存相关信息 &amp;#125; &amp;#125; //定义迷宫建造者接口 interface MazeBuilder &amp;#123; void buildRoom(int x, int y, int roomId);//建造房间 void buildDoor(int Id1, int Id2);//建造门 void buildBarrier(int x, int y, int barrierId);//建造障碍物 Maze getMaze();//获取最终结果 &amp;#125; //迷宫建造团队A，每个建造团队的建造方式是不一样的 class MazeBuilderA implements MazeBuilder &amp;#123; //建造团队将逐步完善这个迷宫，并交付给客户 private Maze maze = new Maze(); @Override public void buildRoom(int x, int y, int roomId) &amp;#123; maze.setRoom(x, y, roomId); &amp;#125; @Override public void buildDoor(int Id1, int Id2) &amp;#123; maze.setDoor(Id1, Id2); &amp;#125; @Override public void buildBarrier(int x, int y, int barrierId) &amp;#123; maze.setBarrier(x, y, barrierId); &amp;#125; @Override public Maze getMaze() &amp;#123; return maze; &amp;#125; &amp;#125; //迷宫指挥者类 class MazeDirecotr &amp;#123; MazeBuilder mazeBuilder; public MazeDirecotr(MazeBuilder mazeBuilder) &amp;#123; this.mazeBuilder = mazeBuilder; &amp;#125; //将工作交给指挥，用户只需要等待建筑完成取走实例 public Maze getMaze() &amp;#123; //具体的设计思想在这里产生 //在这里我们可以一步一步按照我们的想法构造出复杂的模型 //例如这里我想要建造两个房间和中间的一扇门 mazeBuilder.buildRoom(0, 0, 0); mazeBuilder.buildRoom(0, 1, 1); mazeBuilder.buildDoor(0, 1); //实际的工作是由工人们建造的 //总指挥从工人们手中获取最终产品，由总指挥完成与用户的交接 return mazeBuilder.getMaze(); &amp;#125; &amp;#125; //测试类 public class Test &amp;#123; public static void main(String[] args) &amp;#123; //请工人 MazeBuilder mazeBuilder = new MazeBuilderA(); //请指挥，并将工人交给其指挥 MazeDirecotr mazeDirecotr = new MazeDirecotr(mazeBuilder); //最终与总指挥完成产品交付 Maze maze = mazeDirecotr.getMaze(); &amp;#125; &amp;#125; //输出 /* 在[0,0]处建立一座编号为0的房间 在[0,1]处建立一座编号为1的房间 在组件编号为0和组件编号为1之间建立一扇门 */ 通过建造者模式，我们不再需要重载大量函数。通过设计导演类而一步一步的生成我们期望的对象，可以更加精细的控制创建的过程。实际开发中，导演类由用户自己编写定义，一个优化的技巧是采用链式编程，我们可以定义建造者接口如下： //定义迷宫建造者接口 interface MazeBuilder &amp;#123; MazeBuilder buildRoom(int x, int y, int roomId);//建造房间 MazeBuilder buildDoor(int Id1, int Id2);//建造门 MazeBuilder buildBarrier(int x, int y, int barrierId);//建造障碍物 Maze getMaze();//获取最终结果 &amp;#125; 那么我们就可以在导演类中这样编写代码： mazeBuilder.buildRoom(0, 0, 0).buildRoom(0,1,1).buildDoor(0, 1); 优缺点总结优点： 1、建造者独立，采用接口方式，易扩展。 2、便于控制细节风险。 3、将设计与使用解耦，利于扩展与维护。 缺点： 1、产品必须有共同点，范围有限制。 2、如内部变化复杂，会有很多的建造类。 注意事项：与工厂模式的区别是：建造者模式更加关注与零件装配的顺序。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"设计模式之观察者模式(Observer)","slug":"设计模式之观察者模式(Observer)","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:17.001Z","comments":true,"path":"post/515f.html","link":"","permalink":"http://example.com/post/515f.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 设计意图定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。 在实际设计开发中，我们通常会降低类与类之间的耦合度，这样可能会产生一个副作用：由于类与类被分割，我们难以维护类之间的一致性。 举一个常见的例子，我们对用户显示数学饼状图是需要数据支撑的，例如下面这张东京奥运会金牌榜: 在开发中，这张图表分为两个部分，一个是视图部分，也就是以饼状图呈现出的样子，一个是数据部分，即各国的金牌数量，由于我们将数据与视图抽离，因此一旦数据部分更新，视图部分得不到最新的数据，难以维持一致性，这个时候我们需要一个时刻关注数据变化的观察者，一旦观察者感知到数据变化则立即更新视图，我们可以让视图本身作为一个观察者，但这样设计是不好的，视图类应当做好设计视图的事而无需插手其他工作，更好的办法是单独分离出一个观察者类以维护两个类之间的一致性，这就是观察者模式的设计意图。 在实际例子中，这种模式应用非常广泛，例如一旦小说更新将会自动订阅，一旦会员过期将会自动续费，MVC三层模式中的控制器就会观察视图并实时更新模型部分……观察者模式是应用最广泛的模式之一。 设计实现观察者模式时要注意具体目标对象和具体观察者对象之间不能直接调用，否则将使两者之间紧密耦合起来，这违反了面向对象的设计原则。 观察者模式的主要角色如下。 抽象主题（Subject）角色：也叫抽象目标类或目标接口类，它提供了一个用于保存观察者对象的聚集类和增加、删除观察者对象的方法，以及通知所有观察者的抽象方法。 具体主题（Concrete Subject）（被观察目标）角色：也叫具体目标类，它是被观察的目标，它实现抽象目标中的通知方法，当具体主题的内部状态发生改变时，通知所有注册过的观察者对象。 观察者接口（Observer）角色：它是一个抽象类或接口，它包含了一个更新自己的抽象方法，当接到具体主题的更改通知时被调用。 具体观察者（Concrete Observer）角色：实现抽象观察者中定义的抽象方法，以便在得到目标的更改通知时更新自身的状态。 设计接口(抽象)是常规的设计思想：定义一个接口由子类实现。这样做利于后续扩展，但如果确定只有一个被观察对象，则没有必要设计接口(抽象)类。 常见的设计是：观察者到被观察目标中注册登记，告诉它有一个观察者正在观察他，如有变化请通知，随后观察目标发生变化，则通知所有注册登录过的观察者并告诉自己的身份(观察者可能观察多个目标，某些时候它必须知道具体是那个目标发生了变化)，随后观察者更新相应数据。 代码示例我们考虑上述数据与视图之间的例子，这里假设我们的视图接收谷歌数据源与百度数据源： import java.util.ArrayList; import java.util.Date; import java.util.List; //视图类 class View &amp;#123; //通过复杂转换将数据可视化，这里简单的打印 public void show(Object data) &amp;#123; System.out.println(data); &amp;#125; &amp;#125; //定义抽象类 数据源类 abstract class DataSource &amp;#123; //相关的源数据 protected String data = \"\"; //存储已经注册过的观察者 protected List&lt;Observer> observers = new ArrayList&lt;>(); //获取该数据 public String getData() &amp;#123; return data; &amp;#125; //观察者到这里注册，被观察者保存观察者信息 public void addObserver(Observer observer) &amp;#123; observers.add(observer); &amp;#125; //移除更改观察者就不写了 //接口方法，更新数据，由目标类通知观察者 abstract protected void updateData(String newData); //接口方法，通知观察者，由子类采用不同的方法实现 abstract public void notifyObserver(); &amp;#125; //数据源类的具体实现之一，百度数据源类 class BaiduDataSource extends DataSource &amp;#123; @Override protected void updateData(String newData) &amp;#123; //如果数据发生变化，则更新数据并通知观察者 if (!newData.equals(data)) &amp;#123; //这一步是必须的，在通知观察者前一定要完成变化 //这就好比你明天才出发可你却告诉你的好朋友今天走，你的好朋友来接你没看到你，友情破碎 //必须要保持状态的一致性 data = newData; notifyObserver(); &amp;#125; &amp;#125; @Override public void notifyObserver() &amp;#123; //广播消息，并告知观察者自己是谁 for (var observer : observers) &amp;#123; observer.update(this, data); &amp;#125; &amp;#125; &amp;#125; //数据源类的具体实现之一，谷歌数据源类 class GoogleDataSource extends DataSource &amp;#123; @Override protected void updateData(String newData) &amp;#123; //如果数据发生变化，则更新数据并通知观察者 if (!newData.equals(data)) &amp;#123; //必须要保持状态的一致性 data = newData; notifyObserver(); &amp;#125; &amp;#125; @Override public void notifyObserver() &amp;#123; //广播消息，并告知观察者自己是谁 for (var observer : observers) &amp;#123; observer.update(this, data); &amp;#125; &amp;#125; &amp;#125; //观察者接口 interface Observer &amp;#123; /** * 更新操作 * @param ds 观察的具体数据源 * @param data 更新的数据 */ void update(DataSource ds, String data); &amp;#125; //观察者A class ObserverA implements Observer &amp;#123; //由view示例委托观察数据源 private View view; public ObserverA(View view) &amp;#123; this.view = view; &amp;#125; @Override public void update(DataSource ds, String data) &amp;#123; System.out.println(\"观察到\" + ds.getClass().getSimpleName() + \"发生变化，更新视图\"); //更新视图View view.show(data); &amp;#125; &amp;#125; //测试类 public class Test &amp;#123; public static void main(String[] args) &amp;#123; //定义视图类 View view = new View(); view.show(\"初始状态\"); System.out.println(); //定义与view相关数据源 DataSource bds = new BaiduDataSource();//百度数据源 DataSource gds = new GoogleDataSource();//谷歌数据源 //为view添加观察数据源的观察者 Observer observer = new ObserverA(view); //观察者需要到到数据源类中注册 bds.addObserver(observer); gds.addObserver(observer); //手动更新数据 bds.updateData(\"这是百度新数据--\" + new Date()); System.out.println(); gds.updateData(\"这是谷歌新数据--\" + new Date()); &amp;#125; &amp;#125; //输出 /* 初始状态 观察到BaiduDataSource发生变化，更新视图 这是百度新数据--Fri Jul 30 10:43:55 CST 2021 观察到GoogleDataSource发生变化，更新视图 这是谷歌新数据--Fri Jul 30 10:43:55 CST 2021 */ 讨论与优化我们围绕上面的代码示例来讨论。 在发送给通知给观察者前，维护自身状态一致性是很重要的，在上面的代码中我们必须要先更新数据在发送通知，就像例子说的，你明明要等到明天才出发，可你却通知你的好朋友马上就走走，这样总会引起一些不好的结果。 上述代码只设置了一个观察者，实际中可能有多个观察者，可是观察者之间却又互相不知道彼此的存在，这就可能会造成重复更新的甚至更严重的问题，我们必须要好好设置观察者，以保证它们在功能上不具有重复性。事实上，当观察者越来越多时，代码会变得更加难以扩展维护。 上述代码中我们让观察者保存了View的实例，实际的更新还是由该实例自己来完成，这是符合观察者模式的定义的。但实际上，常常会由观察者自身来更新相关数据。 观察者可能观察多个目标，因此当目标通知观察者时应该告知观察者它自己是谁，以便观察者做出相应操作，实现的办法就是目标将自身传入观察者方法的参数中。这样是符合常理的——观察者正在观察5岁、6岁、7岁的人比赛跑步，一旦出现达到终点则观察者颁发奖状，不同年龄的人评奖原则也是不同的，所以观察者必须知道到底是谁完成比赛。 上述代码中一旦有变化则通知所有的观察者——尽管有些观察者对这些消息并不感兴趣，当观察者较多时，效率是很低的，我们应该只通知那些对该变化感兴趣的观察者们，我们可以定义一个Aspect类表示该变化的特点，可以采用哈希表保存观察者： Map&lt;Aspect, List&lt;Observer>> map = new HashMap&lt;>(); 观察者注册时，必须表面自己对那些方面的变化感兴趣： public void addObserver(Aspect aspect, Observer observer) &amp;#123; map.put(aspect, observer); &amp;#125; 其他在 Java 中，通过 java.util.Observable 类和 java.util.Observer 接口定义了观察者模式，只要实现它们的子类就可以编写观察者模式实例。我们来分析主要的类与它们的功能： 1. Observable类Observable 类是抽象目标类，它有一个 Vector 向量，用于保存所有要通知的观察者对象，下面来介绍它最重要的 3 个方法。 void addObserver(Observer o) 方法：用于将新的观察者对象添加到向量中。 void notifyObservers(Object arg) 方法：调用向量中的所有观察者对象的 update() 方法，通知它们数据发生改变。通常越晚加入向量的观察者越先得到通知。 void setChange() 方法：用来设置一个 boolean 类型的内部标志位，注明目标对象发生了变化。当它为真时，notifyObservers() 才会通知观察者。 2. Observer 接口Observer 接口是抽象观察者，它监视目标对象的变化，当目标对象发生变化时，观察者得到通知，并调用 void update(Observable o,Object arg) 方法，进行相应的工作。 事实上这一套类已经太老了，效率比较低，不建议使用。 总结观察者模式是一种对象行为型模式，其主要优点如下。 降低了目标与观察者之间的耦合关系，两者之间是抽象耦合关系。符合依赖倒置原则。 目标与观察者之间建立了一套触发机制。 它的主要缺点如下。 目标与观察者之间的依赖关系并没有完全解除，而且有可能出现循环引用。 当观察者对象很多时，通知的发布会花费很多时间，影响程序的效率，并且可能会导致意外的更新。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"设计模式之适配器模式(Adapter)","slug":"设计模式之适配器模式(Adapter)","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:17.004Z","comments":true,"path":"post/f0e7.html","link":"","permalink":"http://example.com/post/f0e7.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 设计意图适配器模式（Adapter Pattern）是作为两个不兼容的接口之间的桥梁。这种类型的设计模式属于结构型模式，它结合了两个独立接口的功能。 在某些时候，客户期望获得某种功能接口但现有的接口无法满足客户的需求，例如美国的正常供电电压为110V，一个中国人带了一款中国制造电器去美国，这个电器必须要在220V电压下才能充电使用。这种情况下，客户(中国人)的期望接口是有一个220V的电压为电器充电，但实际的接口是仅有一个110V的电压供电器充电，这种情况下就需要采用一根电压转换器(适配器)使得110V的电压能够转换为220V的电压，供客户使用。 将一个类的接口转换成客户希望的另外一个接口，这就是适配器需要做的事情，适配器模式使得原本由于接口不兼容而不能一起工作的那些类可以一起工作。 适用条件 系统需要使用现有的类，而此类的接口不符合系统的需要(核心需求)。 想要建立一个可以重复使用的适配器类，用于与一些彼此之间没有太大关联的一些类，包括一些可能在将来引进的类一起工作，这些源类不一定有一致的接口，但通过适配器使得它们都具有一致的接口。 通过接口转换，将一个类插入另一个类系中。（比如老虎和飞禽，现在多了一个飞虎，在不增加实体的需求下，增加一个适配器，在里面包容一个虎对象，实现飞的接口。） 设计通常有两种方式实现适配器模式，一种是类适配器，类适配器目前已不太使用，另一种实现方式是对象适配器，通常情况下采用对象适配器会使得代码更易扩展与维护。 不管采用何种方式，其基本的实现思想都是：对现有接口的实现类进行扩展，使其实现客户期望的目标接口。 类适配器通过继承现有接口类并实现目标接口，这样的话会使得现有接口类完全对适配器暴露，使得适配器具有现有接口类的全部功能，破坏了封装性。此外从逻辑上来说，这也是不符合常理的，适配器要做的是扩展现有接口类的功能而不是替代，类适配器只有在特定条件下会被使用。 对象适配器持有现有接口类一个实例，并扩展其功能，实现目标接口。这是推荐的方式，优先采用组合而不是继承，会使得代码更利于维护。此外，这也是非常符合常理的——“给我一根线，让我来给他加长到5m，我并不需要知道这跟线是什么组成的，因为我的工作就是让线加长到5m”——我们扩展了相应功能而并不关心其具体实现。 类适配器结构图： 对象适配器结构图： Target：客户期望获得的功能接口(220V电压供电)。 Cilent：客户，期望访问Target接口(客户期望能有220V电压)。 Adaptee：现有接口，这个接口需要被适配(现有110V电压供电，需要被适配至220V)。 Adapter：适配器类，适配现有接口使其符合客户需求接口(适配110V电压，使其变为220V电压)。 在适配器模式中，Cilent调用Adapter以获得相应功能，Adapter扩展Adaptee以实现对应功能。 代码示例类适配器：//客户期望的接口——220V的电压充电 interface Target &amp;#123; void chargeBy220V(); &amp;#125; //现有接口——只能通过110V电压充电 interface Adaptee &amp;#123; void chargeBy110V(); &amp;#125; //现有接口的具体实现类，美国供电器——通过110V电压供电 class americanCharger implements Adaptee &amp;#123; @Override public void chargeBy110V() &amp;#123; System.out.println(\"美国供电器，只为你服务，正在通过110V电压为您充电\"); &amp;#125; &amp;#125; //类适配器，通过继承现有接口来完成对现有接口的扩展 class Adapter extends americanCharger implements Target &amp;#123; @Override public void chargeBy220V() &amp;#123; super.chargeBy110V();//现有功能 System.out.println(\"再加110V，达到220V，冲鸭！\");//对现有功能扩展 &amp;#125; &amp;#125; //测试类 public class Test &amp;#123; public static void main(String[] args) throws FileNotFoundException &amp;#123; //类适配器使得代码逻辑混乱 //这种情况下仿佛Adapter是一种110V的美国供电器可以直接使用不需要其他信息 //具体可以和对象适配器对比以下 new Adapter().chargeBy220V(); &amp;#125; &amp;#125; //输出 /* 美国供电器，只为你服务，正在通过110V电压为您充电 再加110V，达到220V，冲鸭！ */ 对象适配器：//客户期望的接口——220V的电压充电 interface Target &amp;#123; void chargeBy220V(); &amp;#125; //现有接口——只能通过110V电压充电 interface Adaptee &amp;#123; void chargeBy110V(); &amp;#125; //现有接口的具体实现类，美国供电器——通过110V电压供电 class americanCharger implements Adaptee &amp;#123; @Override public void chargeBy110V() &amp;#123; System.out.println(\"美国供电器，只为你服务，正在通过110V电压为您充电\"); &amp;#125; &amp;#125; //类适配器，通过继承现有接口来完成对现有接口的扩展，使得能够110V供电 class Adapter implements Target &amp;#123; Adaptee adaptee;//持有现有接口具体实现对象的引用 public Adapter(Adaptee adaptee) &amp;#123; this.adaptee = adaptee; &amp;#125; @Override public void chargeBy220V() &amp;#123; adaptee.chargeBy110V();//该对象的现有功能 System.out.println(\"再加110V，达到220V，冲鸭！\");//对现有功能扩展 &amp;#125; &amp;#125; //测试类 public class Test &amp;#123; public static void main(String[] args) throws FileNotFoundException &amp;#123; //现在我们有一个美国110V供电站，但我们无法使用 Adaptee adaptee = new americanCharger(); //我们将这个供电器交给适配器，适配器转换为220V供电器 Adapter adapter = new Adapter(adaptee); //接下来我们通过适配器充电就好了 adapter.chargeBy220V(); &amp;#125; &amp;#125; //输出同上 对象适配器采用组合的方式实现对现有接口的扩展以达到客户期望的接口。 让我们来看JavaIO流中的一个实例： FileInputStream fis = new FileInputStream(\"qe\"); InputStreamReader isrAdapter = new InputStreamReader(fis); BufferedReader bf = new BufferedReader(isrAdapter); BufferedReader(此处为客户)需要读取文件字符流进行工作，读取文件字符流就是客户的需求部分，但是根据现有的接口，想要读取文件就只能读取字节流，FileInputStream就是现有接口的一个具体实现类，为了满足客户的需求，我们要对现有的接口进行适配，InputStreamReader就是一个适配器，它持有一个现有接口类的实例，通过这个实例读取文件字节流并将其扩展为字符流以满足客户的需求，这是标准的对象适配器模式。如果仔细研究源码，发现JavaIO库将适配器定义为抽象的，并由具体的适配器继承该抽象适配器，如这里的InputStreamReader就是具体的适配器之一。 如果实现适配有多种方式的话，我们可以将适配器类Adapter声明为抽象类，并由子类扩展它: //客户期望的接口——220V的电压充电 interface Target &amp;#123; void chargeBy220V(); &amp;#125; //现有接口——只能通过110V电压充电 interface Adaptee &amp;#123; void chargeBy110V(); &amp;#125; //现有接口的具体实现类，美国供电器——通过110V电压供电 class americanCharger implements Adaptee &amp;#123; @Override public void chargeBy110V() &amp;#123; System.out.println(\"美国供电器，只为你服务，正在通过110V电压为您充电\"); &amp;#125; &amp;#125; //抽象类适配器，通过继承现有接口来完成对现有接口的扩展 abstract class Adapter implements Target &amp;#123; Adaptee adaptee;//持有现有接口具体实现对象的引用 public Adapter(Adaptee adaptee) &amp;#123; this.adaptee = adaptee; &amp;#125; &amp;#125; //中国自制 class ChinaMakeAdapter extends Adapter &amp;#123; public ChinaMakeAdapter(Adaptee adaptee) &amp;#123; super(adaptee); &amp;#125; @Override public void chargeBy220V() &amp;#123; adaptee.chargeBy110V();//该对象的现有功能 System.out.println(\"再加110V，达到220V，认准中国制造，冲鸭！\");//对现有功能扩展 &amp;#125; &amp;#125; //测试类 public class Test &amp;#123; public static void main(String[] args) throws FileNotFoundException &amp;#123; //现在我们有一个美国110V供电站，但我们无法使用 Adaptee adaptee = new americanCharger(); //我们将这个供电站交给中国制造的适配器 Adapter adapter = new ChinaMakeAdapter(adaptee); //接下来我们通过适配器充电就好了 adapter.chargeBy220V(); &amp;#125; &amp;#125; //输出同上 此外可以适配器还通过实现两个接口以达到双向适配的目的，即从接口A可以适配到接口B，从接口B也可以适配到接口A，这种情况并不常见。 //接口A——220V的电压供电 interface A &amp;#123; void chargeBy220V(); &amp;#125; //接口A的具体实现类，中国供电器——通过220V电压供电 class ChinaCharger implements A &amp;#123; @Override public void chargeBy220V() &amp;#123; System.out.println(\"220V电压中国充电，值得信赖\"); &amp;#125; &amp;#125; //接口B——110V电压供电 interface B &amp;#123; void chargeBy110V(); &amp;#125; //接口B的具体实现类，美国供电器——通过110V电压供电 class AmericanCharger implements B &amp;#123; @Override public void chargeBy110V() &amp;#123; System.out.println(\"美国充电器，只为你服务，正在通过110V电压为您充电\"); &amp;#125; &amp;#125; //双向适配器 class Adapter implements A, B &amp;#123; A a; //220V充电 B b; //110V充电 public Adapter(A a) &amp;#123; this.a = a; &amp;#125; public Adapter(B b) &amp;#123; this.b = b; &amp;#125; @Override public void chargeBy220V() &amp;#123; b.chargeBy110V(); //当前接口 System.out.println(\"加码，加到220V！！\");//适配目标接口 &amp;#125; @Override public void chargeBy110V() &amp;#123; a.chargeBy220V();//当前接口 System.out.println(\"缓冲电压，现在是110V了\"); &amp;#125; &amp;#125; //测试类 public class Test &amp;#123; public static void main(String[] args) throws FileNotFoundException &amp;#123; //我们去美国，酒店里有一个美国110V充电站，我们需要220V的电压 B b = new AmericanCharger(); //我们将这个充电站交给适配器以获取220V电压充电 Adapter adapter1 = new Adapter(b); //接下来我们通过适配器充电就好了 adapter1.chargeBy220V(); System.out.println(); //美国人来中国，酒店里有一个中国220V充电站，但他需要110V的电压 A a = new ChinaCharger(); //将这个充电站交给适配器以获取110V电压充电 Adapter adapter2 = new Adapter(a); //接下来我们通过适配器充电就好了 adapter2.chargeBy110V(); &amp;#125; &amp;#125; //输出 /* 美国充电器，只为你服务，正在通过110V电压为您充电 加码，加到220V！！ 220V电压中国充电，值得信赖 缓冲电压，现在是110V了 Process finished with exit code 0 */ 通过实现两个接口的方式，达到不同接口的双向适配，在某些情况下还是很实用的，例如TypeC—USB接口转换器，既能从typeC转USB也能从USB转typeC。 适配器模式总结优点： 可以让任何两个没有关联的类一起运行。 提高了类的复用，可以一致化多个不同接口。 将现有接口实现类隐藏，增加了类的透明度。 灵活性高，可自由适配。 缺点： 过多地使用适配器，会让系统非常零乱，不易整体进行把握。比如，明明看到调用的是 A 接口，其实内部被适配成了 B 接口的实现，一个系统如果太多出现这种情况，无异于一场灾难。因此如果不是很有必要，可以不使用适配器，而是直接对系统进行重构。 某些适配工作可能非常困难，例如让房子飞起来。 当我们有动机地修改一个正常运行的系统的接口，这时应该考虑使用适配器模式。 注意事项：适配器不是在详细设计时添加的，而是解决正在服役的项目的问题，即现有接口可能无法改变(去美国不可能把人家110V电压供给改成220V电压供给)。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"读 Spring 源码总结","slug":"读 Spring 源码总结","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:17.004Z","comments":true,"path":"post/c10f.html","link":"","permalink":"http://example.com/post/c10f.html","excerpt":"","text":"Spring 源码初探 本文基于 jdk 11 文章已收录我的仓库：Java学习笔记 核心类interface BeanFactory该接口是访问 Spring bean 容器的根接口，是 bean 容器的基本客户端视图； 其他接口如ListableBeanFactory和ConfigurableBeanFactory可用于扩展一些其他功能。 简单来说，该类就是“容器”接口类，用以存放 bean，其内定义了一系列 getBean 方法，是一个存粹的 “bean 生产地”。 class DefaultListableBeanFactory 如果说 BeanFactory 是一个简单存粹的 “bean 生产地”，那么 DefaultListableBeanFactory 就是一个庞大而复杂的 “bean 生产机器”，DefaultListableBeanFactory 不仅实现了 BeanFactory 接口，还实现了其他与 bean 相关的接口，例如别名相关、BeanDefinition等，这个类是 spring 默认使用的 bean 工厂，但它已经不像 BeanFactory 那么存粹了。 如无特殊说明，下文说所 bean 工厂或 BeanFactory 均是指 DefaultListableBeanFactory。 interface ApplicationContext 该类是 IOC 的中央接口，该接口类继承了 BeanFactory 并且实现了更多的接口，即具备更完善的功能，例如： 用于访问应用程序组件的 Bean 工厂方法，继承自 ListableBeanFactory，默认使用 DefaultListableBeanFactory 工厂 。 以通用方式加载文件资源的能力，继承自org.springframework.core.io.ResourceLoader接口。 能够将事件发布到注册的侦听器，继承自ApplicationEventPublisher接口。 解析消息的能力，支持国际化，继承自MessageSource接口。 从父上下文继承，例如，单个父上下文可以被整个 Web 应用程序使用，而每个 servlet 都有自己的子上下文，该子上下文独立于任何其他 servlet 的子上下文，例如 Spring 容器是 SpringMVC 的父容器，SpringMVC 容器可以访问 Spring 中所有 Bean。 interface BeanDefinitionBeanDefinition 描述了一个 bean 实例，它具有 bean 的属性值、构造函数参数值以及其他信息(由具体实现中实现)，简单的将该类就是存放在 bean 的元数据（还未实例化），以便我们后续创建 bean 实例。 interface BeanDefinitionReader读取 BeanDefinition 信息，例如可以有 XML 形式读取（XmlBeanDefinitionReader）、配置文件读取（PropertiesBeanDefinitionReader）、注解读取（AnnotatedBeanDefinitionReader ）或由配置类读取（ConfigurationClassBeanDefinitionReader）。 在 BeanDefinitionLoader 类中的 load 方法有具体的判断 private int load(Object source) &#123; Assert.notNull(source, &quot;Source must not be null&quot;); if (source instanceof Class&lt;?&gt;) &#123; // 这是一个 Class&lt;&gt;？ return load((Class&lt;?&gt;) source); &#125; if (source instanceof Resource) &#123; // 这是一个资源？ return load((Resource) source); &#125; if (source instanceof Package) &#123; // 这是一个包？ return load((Package) source); &#125; if (source instanceof CharSequence) &#123; // 一个字符串？例如 XML 文件名 return load((CharSequence) source); &#125; throw new IllegalArgumentException(&quot;Invalid source type &quot; + source.getClass()); &#125; interface Aware一个标记超级接口，指示 bean 有资格通过回调样式的方法由特定框架对象的 Spring 容器通知。 简单的来讲，aware 就是 bean 的额外的一些属性，例如你想知道某个 bean 的 name(id)，则你可以实现让这个 bean BeanNameAware 接口，该接口只有一个 setBeanName 方法，spring 在初始化 bean 的时候会判断该 bean 是否实现了某个具体的 Aware 接口（例如，通过 instanceof），如果是的话则调用 set 方法注入属性。 @Component(\"我是 beanName\") public class Bean implements BeanNameAware &amp;#123; public String name; @Override public void setBeanName(String name) &amp;#123; this.name = name; &amp;#125; &amp;#125; Test 代码： @Autowired Bean bean; @Test void contextLoads() &amp;#123; System.out.println(bean); &amp;#125; // 输出：Bean&amp;#123;name='我是 beanName'&amp;#125; interface BeanFactoryPostProcessor当所有的 BeanDefinitionReader 加载完 BeanDefinition 到 BeanFactory 后，Spring 执行每一个注册的 BeanFactoryPostProcessor 的**postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory)方法，该方法被认为是一个增强器**，允许对 BeanDefinition 信息做额外的修改或注册 BeanDefinition。 例如由 @Component、@Bean 等标记的 bean 就是在这一阶段被增强器扫描并注册 BeanDefinition 加载到 BeanFactory 中。 详细请参考 SpringBoot 源码总结 例如，我们可以自己实现一个简易的注解myBean，使得被该注解标记的类都能成为 Spring Bean： @Target(ElementType.TYPE) @Retention(RetentionPolicy.RUNTIME) public @interface myBean &amp;#123; String beanName() default \"\"; &amp;#125; 添加注解： @myBean(beanName = \"abc\") public class Bean &amp;#123; &amp;#125; 注册 BeanFactoryPostProcessor，扫描所有被 @myBean 标记的类，并注册 BeanDefinition： @Component public class MyBeanFactoryPostProcessor implements BeanFactoryPostProcessor &amp;#123; @Override public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException &amp;#123; Enumeration&lt;URL> resources = null; String basePackage = \"com.happysnaker\"; try &amp;#123; resources = Thread.currentThread().getContextClassLoader().getResources(basePackage.replaceAll(\"\\\\.\", \"/\")); &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; while (resources.hasMoreElements()) &amp;#123; URL resource = resources.nextElement(); String protocol = resource.getProtocol(); if (\"file\".equals(protocol)) &amp;#123; String filePath = null; try &amp;#123; filePath = URLDecoder.decode(resource.getFile(), \"UTF-8\"); &amp;#125; catch (UnsupportedEncodingException e) &amp;#123; e.printStackTrace(); &amp;#125; try &amp;#123; // 扫描 com.happysnaker 包下的所有类 List&lt;Class> classes = getAllClass(new File(filePath), basePackage); for (Class aClass : classes) &amp;#123; doWork(beanFactory, aClass); &amp;#125; &amp;#125; catch (IOException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; &amp;#125; private void doWork(ConfigurableListableBeanFactory beanFactory, Class c) &amp;#123; // 如果是被 @myBean 标记的话 if (c.isAnnotationPresent(myBean.class)) &amp;#123; myBean annotation = (myBean) c.getAnnotation(myBean.class); BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(c); try &amp;#123; BeanDefinitionRegistry registry = (BeanDefinitionRegistry) beanFactory; // 注册 BeanDefinition registry.registerBeanDefinition(annotation.beanName(), builder.getBeanDefinition()); &amp;#125; catch (Exception e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; private List&lt;Class> getAllClass(File file, String path) throws IOException &amp;#123; List&lt;Class> ans = new ArrayList&lt;>(); if (file.isDirectory()) &amp;#123; File[] files = file.listFiles(); for (File file1 : files) &amp;#123; List&lt;Class> classList = getAllClass(file1, path + \".\" + file1.getName()); if (classList != null) &amp;#123; ans.addAll(classList); &amp;#125; &amp;#125; &amp;#125; else &amp;#123; if (file.getName().indexOf(\".class\") != -1) &amp;#123; path = path.substring(0, path.indexOf(\".class\")); try &amp;#123; Class c = Class.forName(path); ans.add(c); &amp;#125; catch (ClassNotFoundException e) &amp;#123; e.printStackTrace(); &amp;#125; &amp;#125; &amp;#125; return ans; &amp;#125; &amp;#125; 测试： @Qualifier(\"abc\") @Autowired Bean bean; @Test void contextLoads() &amp;#123; System.out.println(bean); &amp;#125; // 输出：com.happysnaker.bean.Bean@12fcc71f interface BeanDefinitionRegistryPostProcessor该方法与 BeanFactoryPostProcessor 类一个意思，其本身就实现了 BeanFactoryPostProcessor，这个类下有一个方法 postProcessBeanDefinitionRegistry，实现了这个方法的类会与 postProcessBeanFactory 方法在同一个函数内执行。 事实上由于 BeanDefinitionRegistryPostProcessor 继承了 BeanFactoryPostProcessor，我们会认为 BeanDefinitionRegistryPostProcessor 就是一个 BeanFactoryPostProcessor，下文中以及后续文章将不会再出现 BeanDefinitionRegistryPostProcessor 这个名词。 interface BeanPostProcessor该接口中有两个方法： Object postProcessBeforeInitialization(Object bean, String beanName); Object postProcessAfterInitialization(Object bean, String beanName); 与 BeanFactoryPostProcessor 不同的是，BeanFactoryPostProcessor 在 bean 实例化之前被调用，而 BeanPostProcessor 在 bean 实例化之后、初始化前后调用，注入 @Value、@AutoWired、AOP 均依赖该类实现。 生命周期Spring 生命周期通常被认为包括 实例化 和 初始化两个步骤，实例化通常是通过反射 newInstance 构建对象，而初始化包括设置对象属性、注入 val（例如 AutoWired）等，执行 init-method 方法，设置代理类等操作，你可以简单的认为实例化只是简单的创建类，而初始化是包装类。 刷新生命周期与实例化打开断点调试，进入 AbstractApplicationContext 抽象类的 refresh() 方法，该方法是 Spring 启动的核心步骤，由 12 个方法构成： prepareRefresh()容器刷新前的准备，设置上下文状态为激活状态，开始启动计时，获取属性，验证必要的属性等。 obtainFreshBeanFactory()跟踪源码发现，最终调用了 AbstractRefreshableApplicationContext 类的 refreshBeanFactory 方法，该方法销毁原有 beanFactory，获取新的 beanFactory，通过断点调试确定 beanFactory 是 DefaultListableBeanFactory，同时还会 loadBeanDefinitions，跟踪该方法发现调用了 XmlBeanDefinitionReader 类解析 XML 文件，生成 BeanDefinition。 prepareBeanFactory(beanFactory)配置上下文的 ClassLoader，设置 SpEL 表达式解析器，添加忽略注入的接口，添加存在的 bean 以及 BeanFactoryPostProcessors 等。 postProcessBeanFactory(beanFactory);允许子类继承 AbstractApplicationContext 并扩展该方法。 invokeBeanFactoryPostProcessors(beanFactory)实例化并调用所有注册的 beanFactory 后置处理器，跟踪源码发现调用了 PostProcessorRegistrationDelegate 类的 invokeBeanFactoryPostProcessors 方法，该方法获取所有实现了 BeanFactoryPostProcessor 接口的 bean，然后调用增强器方法，首先会调用被 @PriorityOrdered 标记的方法 ，再调用被 @Ordered 标记的方法，最后调用普通方法。 我们前面已经提到了这一步将会解析一些注解标注的 bean，事实上 ConfigurationClassPostProcessor 增强器的增强方法中会调用这样一种方法：enhanceConfigurationClasses(beanFactory);，该方法会将所有用@Configuration 注解修饰的类用 cglib 技术代理加强，这样做的目的是为了解决单例问题，例如一个Configuration 配置类下面可能会调用两次 @Bean 方法，这违反了单例原则，因此通过增强代理来避免这种情况发送。 registerBeanPostProcessors(beanFactory)实例化和注册 beanFactory 中扩展了BeanPostProcessor的 bean，但并不执行，而是等到初始化时执行。 initMessageSource()初始化国际化工具类 MessageSource。 initApplicationEventMulticaster()初始化事件广播器。 onRefresh()模板方法，在容器刷新的时候可以自定义逻辑，不同的Spring容器做不同的事情，在 SpringBoot 中，容器为 AnnotationConfigServletWebServerApplicationContext（继承自 ServletWebServerApplicationContext），这个容器刷新上下文时创建并启动了 tomcat 。 registerListeners()注册监听器，监听 early application events。 finishBeanFactoryInitialization(beanFactory)实例化和初始化所有剩余的（非懒加载）单例类，比如 invokeBeanFactoryPostProcessors 方法中根据各种注解解析出来的类，在这个时候都会被实例化和初始化。 跟踪源码，发现最终调用： // Instantiate all remaining (non-lazy-init) singletons. beanFactory.preInstantiateSingletons(); 继续跟踪源码，preInstantiateSingletons 方法中进入如下语句块： // 早期对象 if (isEagerInit) &amp;#123; getBean(beanName); &amp;#125; 点进去，来到 doGetBean 方法，最终进入到： if (mbd.isSingleton()) &amp;#123; sharedInstance = getSingleton(beanName, () -> &amp;#123; try &amp;#123; return createBean(beanName, mbd, args); &amp;#125; &amp;#125;); &amp;#125; 点进 createBean 方法，一步步跟踪来到 AbstractAutowireCapableBeanFactory 类的 doCreateBean 方法，然后进入到 instantiateBean 方法，然后进入到 instantiate 方法，该方法中执行： constructorToUse = clazz.getDeclaredConstructor(); 然后构造器传入到 BeanUtils.instantiateClass 方法，该方法中直接实例化对象： return ctor.newInstance(argsWithDefaultValues); 当然，上述只是无参构造器的流程，如果需要 @Autowired，Spring 会执行 determineConstructorsFromBeanPostProcessors(beanClass, beanName); 方法会拿到构造函数列表，这些构造函数所需的参数都在 Bean 工厂中，随后会 ctors = mbd.getPreferredConstructors(); 决出最好的构造函数，默认是全长的构造函数，然后进行实例化。 实例被初始化，总算解开了我一直以来的疑惑。 finishRefresh()refresh做完之后需要做的一些事情。例如，清除上下文资源缓存（如扫描中的ASM元数据），发布ContextRefreshedEvent 事件告知对应的 ApplicationListener 进行响应的操作。 初始化循环依赖问题即 A 依赖与 B，同时 B 依赖于 A： @Component public class B &amp;#123; @Autowired A a; public B(A a) &amp;#123; this.a = a; &amp;#125; &amp;#125; @Component public class A &amp;#123; @Autowired B b; public A(B b) &amp;#123; this.b = b; &amp;#125; &amp;#125; 那么想初始化 A，就要填充 B，而 B 未被创建，就会去递归的创建 B，然后初始化 B，想要初始化 B，就要填充 A，而 A 未被创建，就会去递归的创建 A，那么…… 其实解决的办法也很简单，如果 A、B 提供了 set 方法的话： A a = new A(); B b = new B(); b.setA(a); a.setB(b); 这种思想叫提前暴露对象，例如 b 注入了一个不完整的 a，Spring 也是基于这种思想解决循环依赖的。 循环依赖源码跟踪Spring 是基于三级缓存解决循环依赖。 一级缓存 Map&lt;String, Object&gt;，key 是 beanName，val 是已创建完成的单例 bean 对象。 二级缓存 Map&lt;String, Object&gt;，key 是 beanName，val 是未创建完成的单例 bean 对象，即已实例化但未初始化的对象，例如，上面示例代码中的 a。 二级缓存 Map&lt;String, ObjectFactory&gt;，key 是 beanName，val 是一个函数式接口，其中调用 getObject 方法获取对象。 我们模拟 A、B 循环以来问题。 这里先初始化 A 对象。 初始化的逻辑也在 finishBeanFactoryInitialization(beanFactory) 中，我们按照上面步骤同样来到 doGetBean 方法，此时我们注意代码： // Eagerly check singleton cache for manually registered singletons. Object sharedInstance = getSingleton(beanName); **spirng 会尝试从缓存中获取对象，getSingleton 会一级一级的去判断是否有缓存(先判断一级)**，当然这里 A 对象肯定不在缓存，因此会先实例化 A 对象。 // singletonObject 一级； earlySingletonObjects 二级；singletonFactories 三级； protected Object getSingleton(String beanName, boolean allowEarlyReference) &amp;#123; Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null &amp;&amp; isSingletonCurrentlyInCreation(beanName)) &amp;#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null &amp;&amp; allowEarlyReference) &amp;#123; synchronized (this.singletonObjects) &amp;#123; singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null) &amp;#123; singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null) &amp;#123; ObjectFactory&lt;?> singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) &amp;#123; singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; &amp;#125; return singletonObject; &amp;#125; 注意还发现如果三级缓存取出对象，会添加至二级缓存，同时移除三级缓存。 让我们套用 finishBeanFactoryInitialization(beanFactory) 讲解，当我们拿到了反射创建的 a 实例之后，回到 doCreateBean 中继续执行： addSingletonFactory(beanName, () -> getEarlyBeanReference(beanName, mbd, bean)); 注意看 addSingletonFactory 方法，该方法将 a 的对象工厂(函数式接口)添加到三级缓存中，也就是说调用三级缓存工厂的 getObject 方法实际上会调用 getEarlyBeanReference 方法： protected Object getEarlyBeanReference(String beanName, RootBeanDefinition mbd, Object bean) &amp;#123; Object exposedObject = bean; // 是否有 beanPostProcessors 增强处理器，如果有，则使用增强处理器返回的对象 if (!mbd.isSynthetic() &amp;&amp; hasInstantiationAwareBeanPostProcessors()) &amp;#123; for (BeanPostProcessor bp : getBeanPostProcessors()) &amp;#123; if (bp instanceof SmartInstantiationAwareBeanPostProcessor) &amp;#123; SmartInstantiationAwareBeanPostProcessor ibp = (SmartInstantiationAwareBeanPostProcessor) bp; exposedObject = ibp.getEarlyBeanReference(exposedObject, beanName); &amp;#125; &amp;#125; &amp;#125; return exposedObject; &amp;#125; getEarlyBeanReference 方法事实上就是返回了 bean 对象，如果需要加强，就返回加强后的结果，即返回最终版本的 bean，如果有代理的话，这里会返回代理作为 bean。 回到 doCreateBean: Object exposedObject = bean; try &amp;#123; populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); &amp;#125; populateBean 是填充属性的方法，A 对象需要填充 B 对象。进入之后跟踪代码，最终调用了 applyPropertyValues(beanName, mbd, bw, pvs) 方法，然后调用 BeanDefinitionValueResolver 类的 resolveValueIfNecessary 方法，进而进入了 resolveReference 方法： bean = parent.getBean(String.valueOf(doEvaluate(ref.getBeanName()))); 这就是递归的步骤了，这里回到了最开始 getBean - doGetBean - createBean - doCreateBean…….这里递归的去实例化并初始化 B 对象。 注意，@Autowired 逻辑也是在填充属性这里被解析的。 最终 B 对象同样需要填充 A 对象，于是又递归的去调用 getBean 生产 A 对象，然后….. 我们说了 spirng 会尝试从缓存中获取对象，此时三级缓存中已经有 A 对象了，因此会直接取出 A 对象，取出 A 对象之后就不会走我们之前的分支了，此时会直接返回 A 对象！ 于是乎 B 对象成功填充 A，于是返回 B，于是 A 对象成功填充 B！ 填充完成后，spring 会删除二级缓存和三级缓存，并填充至一级缓存，对象成功创建。 缓存的一些问题为啥要三级，一个缓存不行吗？ 一个缓存是不可以的，因为都是以 beanName 作为 key，如果只有一个缓存将分不清哪个是完全构造完成的实例，哪个是半完成的实例。 当然，如果给 key 多一点信息标识也是可行的。 那为啥要三级，直接两级不好吗？ 阅读源码发现三级缓存中会构造 bean 的最终版本，也就是说可能会返回 bean 的代理而不是 bean 本身。 那为啥要三级，直接两级存代理不好吗？ 在填充属性阶段不应该过早的直接执行增强器，否则将违背 Spring 的标准，故除非迫不得已才会提前创建最终版本的 bean。 其他细节继续我们的源码征程，当填充属性完成后，将执行 initializeBean 方法： try &amp;#123; populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); &amp;#125; 这个方法将执行前置增强器、初始化方法和后置增强器： Object wrappedBean = bean; if (mbd == null || !mbd.isSynthetic()) &amp;#123; wrappedBean = applyBeanPostProcessorsBeforeInitialization(wrappedBean, beanName); &amp;#125; try &amp;#123; invokeInitMethods(beanName, wrappedBean, mbd); &amp;#125; catch (Throwable ex) &amp;#123; &amp;#125; if (mbd == null || !mbd.isSynthetic()) &amp;#123; wrappedBean = applyBeanPostProcessorsAfterInitialization(wrappedBean, beanName); &amp;#125; 注入 AOP，@AutoWired 都是使用增强器完成的。 这符合我们流程图的步骤。 再接下来 bean 就被注册到 bean 工厂中，可以正常使用了。 AOP 源码AOP 是增强器 AbstractAutoProxyCreator 实现的。 AOP 采用后置增强器： @Override public Object postProcessAfterInitialization(@Nullable Object bean, String beanName) &amp;#123; if (bean != null) &amp;#123; Object cacheKey = getCacheKey(bean.getClass(), beanName); if (this.earlyProxyReferences.remove(cacheKey) != bean) &amp;#123; return wrapIfNecessary(bean, beanName, cacheKey); &amp;#125; &amp;#125; return bean; &amp;#125; 进入 wrapIfNecessary 方法，然后进入 createProxy 方法： protected Object createProxy(Class&lt;?> beanClass, @Nullable String beanName, @Nullable Object[] specificInterceptors, TargetSource targetSource) &amp;#123; // s return proxyFactory.getProxy(getProxyClassLoader()); &amp;#125; 跟进源码： public Object getProxy(@Nullable ClassLoader classLoader) &amp;#123; return createAopProxy().getProxy(classLoader); &amp;#125; 持续跟进 createAopProxy 源码，最终发现这个方法返回了 DefaultAopProxyFactory 类，跟进 DefaultAopProxyFactory.getProxy 方法： public AopProxy createAopProxy(AdvisedSupport config) throws AopConfigException &amp;#123; if (config.isOptimize() || config.isProxyTargetClass() || hasNoUserSuppliedProxyInterfaces(config)) &amp;#123; Class&lt;?> targetClass = config.getTargetClass(); if (targetClass == null) &amp;#123; throw new Exception(); &amp;#125; if (targetClass.isInterface() || Proxy.isProxyClass(targetClass)) &amp;#123; return new JdkDynamicAopProxy(config); &amp;#125; return new ObjenesisCglibAopProxy(config); &amp;#125; else &amp;#123; return new JdkDynamicAopProxy(config); &amp;#125; &amp;#125; config 封装了一系列代理信息，例如代理类和被代理类（正式点说就是切点、连接点啥的），targetClass 即时被代理类（代理目标类），createAopProxy 方法判断代理目标类是否是接口或者是否已经是 JDK Proxy，是的话就采用 JdkDynamicAopProxy，即 JDK 动态代理，否则使用 Cglib 动态代理。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"读 SpringBoot 源码总结","slug":"读 SpringBoot 源码总结","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:17.004Z","comments":true,"path":"post/f150.html","link":"","permalink":"http://example.com/post/f150.html","excerpt":"","text":"SpringBoot 源码总结SpringApplication.run(Application.class, args) 这一行方法到底干了什么？ 本文前置知识：[读 Spring 源码总结](.&#x2F;读 Spring 源码总结.md) 与 [SPI 机制](.&#x2F;SPI 机制以及 jdbc 打破双亲委派.md)，基于 jdk11 注册初始化器和监听器 关键词：加载并设置初始化器和监听器、记录主配置类、META-INF&#x2F;spring.factories、getSpringFactoriesInstances、loadFactoryNames、loadSpringFactories。 点进 run 方法，事实上调用了: public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; return new SpringApplication(primarySources).run(args); &#125; 此处 primarySources是我们的主类，跟进查看new SpringApplication()的逻辑： public SpringApplication(ResourceLoader resourceLoader, Class&lt;?>... primarySources) &amp;#123; this.resourceLoader = resourceLoader; this.primarySources = new LinkedHashSet&lt;>(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); setInitializers((Collection) getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners((Collection) getSpringFactoriesInstances(ApplicationListener.class)); this.mainApplicationClass = deduceMainApplicationClass(); &amp;#125; 这个初始化代码干了啥呢？首先添加了主要资源，然后设置了初始化器和监听器，最后跟踪栈堆信息推导出主配置类 mainApplicationClass，getSpringFactoriesInstances 方法很重要，看看具体的逻辑： private &lt;T> Collection&lt;T> getSpringFactoriesInstances(Class&lt;T> type, Class&lt;?>[] parameterTypes, Object... args) &amp;#123; ClassLoader classLoader = getClassLoader(); Set&lt;String> names = new LinkedHashSet&lt;>(SpringFactoriesLoader.loadFactoryNames(type, classLoader)); List&lt;T> instances = createSpringFactoriesInstances(type, parameterTypes, classLoader, args, names); AnnotationAwareOrderComparator.sort(instances); return instances; &amp;#125; getSpringFactoriesInstances 方法通过 loadFactoryNames 获取了一系列的 names，然后反射创造实例返回，继续跟进 SpringFactoriesLoader.loadFactoryNames 方法，发现主要核心是 loadSpringFactories 方法： public static List&lt;String> loadFactoryNames(Class&lt;?> factoryType, @Nullable ClassLoader classLoader) &amp;#123; String factoryTypeName = factoryType.getName(); return loadSpringFactories(classLoader).getOrDefault(factoryTypeName, Collections.emptyList()); &amp;#125; private static Map&lt;String, List&lt;String>> loadSpringFactories(@Nullable ClassLoader classLoader) &amp;#123; MultiValueMap&lt;String, String> result = cache.get(classLoader); if (result != null) return result; Enumeration&lt;URL> urls = classLoader.getResources(FACTORIES_RESOURCE_LOCATION); result = new LinkedMultiValueMap&lt;>(); while (urls.hasMoreElements()) &amp;#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?> entry : properties.entrySet()) &amp;#123; String factoryTypeName = ((String) entry.getKey()).trim(); for (String factoryImplementationName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &amp;#123; result.add(factoryTypeName, factoryImplementationName.trim()); &amp;#125; &amp;#125; &amp;#125; cache.put(classLoader, result); return result; &amp;#125; 其中 String FACTORIES_RESOURCE_LOCATION = &quot;META-INF/spring.factories&quot;，loadSpringFactories 函数查找了 classPath 下 META-INF&#x2F;spring.factories 文件，并把所有的资源以键值对的形式放进缓存中，loadFactoryNames 返回对应键的所有元素（全限定名）。 现在来回顾下这两行代码是干啥的： setInitializers(getSpringFactoriesInstances(ApplicationContextInitializer.class)); setListeners(getSpringFactoriesInstances(ApplicationListener.class)); getSpringFactoriesInstances(ApplicationContextInitializer.class) 加载了所有 META-INF&#x2F;spring.factories 文件下的所有名称为 ApplicationContextInitializer 的元素，例如： 也就是说这些类会在这一步被加载进去，至于这些类都是干嘛的，读者可点进对应的类查看对应的注解。 再次说明 loadFactoryNames、loadSpringFactories 这两个方法很重要！ loadSpringFactories 加载 MEAT-INFO&#x2F;factories 下的所有键值对，每个值都是一个类的全限定名，loadFactoryNames 根据 loadSpringFactories 加载的 Map 选取对应的值返回！ 设置系统环境变量 关键词：设置系统环境变量、StandardEnvironment 类 进入 public ConfigurableApplicationContext run(String… args) 方法，其中有一行代码是： ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); 这一行代码将帮我们设置环境变量，在 prepareEnvironment 方法内调用了 getOrCreateEnvironment() 方法，跟进方法发现是一个 switch 判断，具体返回环境属性类什么取决于具体的情况，例如 Web 应用将返回 StandardServletEnvironment()。 private ConfigurableEnvironment getOrCreateEnvironment() &amp;#123; if (this.environment != null) &amp;#123; return this.environment; &amp;#125; switch (this.webApplicationType) &amp;#123; case SERVLET: return new StandardServletEnvironment(); case REACTIVE: return new StandardReactiveWebEnvironment(); default: return new StandardEnvironment(); &amp;#125; &amp;#125; 但不管怎么样都是继承了 StandardEnvironment 类，而 StandardEnvironment 类又继承了 AbstractEnvironment 类，因此无论如何都会触发 AbstractEnvironment 类的初始化： public AbstractEnvironment() &amp;#123; customizePropertySources(this.propertySources); &amp;#125; 而初始化又调用了子类 StandardEnvironment 的方法， protected void customizePropertySources(MutablePropertySources propertySources) &amp;#123; propertySources.addLast( new PropertiesPropertySource(SYSTEM_PROPERTIES_PROPERTY_SOURCE_NAME, getSystemProperties())); propertySources.addLast( new SystemEnvironmentPropertySource(SYSTEM_ENVIRONMENT_PROPERTY_SOURCE_NAME, getSystemEnvironment())); &amp;#125; getSystemProperties() 和 getSystemEnvironment() 其实就是返回了 System.getProperties() 和 System.getenv()，这就是我们的系统环境变量。 注册注解处理增强器并注册 beanFactory 反射、createApplicationContext、DefaultListableBeanFactory、注册默认的增强器、ConfigurationClassPostProcessor。 还是在 public ConfigurableApplicationContext run(String… args) 方法中，有一行代码 context = createApplicationContext(); 创建了 ConfigurableApplicationContext 上下文，点进这个方法： protected ConfigurableApplicationContext createApplicationContext() &amp;#123; Class&lt;?> contextClass = this.applicationContextClass; if (contextClass == null) &amp;#123; switch (this.webApplicationType) &amp;#123; case SERVLET: contextClass = Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS); break; case REACTIVE: contextClass = Class.forName(DEFAULT_REACTIVE_WEB_CONTEXT_CLASS); break; default: contextClass = Class.forName(DEFAULT_CONTEXT_CLASS); &amp;#125; &amp;#125; return (ConfigurableApplicationContext) BeanUtils.instantiateClass(contextClass); &amp;#125; 不要看这个方法很简单，但细节是魔鬼，我这里是进入了第一个 case 语句（Web 环境），也就是调用了 Class.forName(DEFAULT_SERVLET_WEB_CONTEXT_CLASS) 语句，DEFAULT_SERVLET_WEB_CONTEXT_CLASS 是： \"org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext\" 这个上下文内置了 Tomcat，在 onRefresh 时会初始化 tomcat。 也就是说我应该在 BeanUtils.instantiateClass 方法中实例化这个上下文容器，点进这个上下文容器的构造器： public AnnotationConfigServletWebServerApplicationContext() &#123; this.reader = new AnnotatedBeanDefinitionReader(this); this.scanner = new ClassPathBeanDefinitionScanner(this); &#125; 首先不要看这个代码，要知道这肯定会向上调用父类构造器，跟踪发现持续调用了 ServletWebServerApplicationContext、GenericWebApplicationContext、GenericApplicationContext 类的构造器方法，在 GenericApplicationContext 类中： public GenericApplicationContext() &#123; this.beanFactory = new DefaultListableBeanFactory(); &#125; 此时，DefaultListableBeanFactory 被注册。 然后在回到 AnnotationConfigServletWebServerApplicationContext() 方法中，这里注册了两个解析器，点入 AnnotatedBeanDefinitionReader 类的构造器，持续调用父类的构造器，最终调用了一行代码： AnnotationConfigUtils.registerAnnotationConfigProcessors(this.registry); 点入这行代码，跳到了 AnnotationConfigUtils 类中执行，代码很长，但逻辑很简单，就是将几个硬编码的增强器加到容器上下文中，例如： SpringBoot 中最最最重要的增强器 ConfigurationClassPostProcessor 在这里诞生了。 ClassPathBeanDefinitionScanner 这一行代码类似，添加了一些过滤器到容器内。 加载源类到容器中 关键词：prepareContext 方法、加载主配置类到容器中（未实例化）。 继续回到 run 方法中，可以发现 SpringBoot 又从 factorys 文件注册了异常播报者，但这不是我们关心的，注意方法：prepareContext，在这个方法内有一个核心逻辑： Set&lt;Object> sources = getAllSources(); // allSources.addAll(this.primarySources); load(context, sources.toArray(new Object[0])); getAllSources 其实加载了一些源，默认情况下就是我们传入的 primarySources，即主类，在 load 方法内被添加到容器中（未实例化）。 回到 run 方法： 成功加载了源类到 beanFactory 中！ 注册 JVM 关闭钩子你一定很好奇为什么关闭虚拟机时 springboot 还会输出一些日志，这是因为它向 JVM 注册了关闭钩子！ private void refreshContext(ConfigurableApplicationContext context) &amp;#123; if (this.registerShutdownHook) &amp;#123; try &amp;#123; // 注册关闭狗子 context.registerShutdownHook(); &amp;#125; catch (AccessControlException ex) &amp;#123; // Not allowed in some environments. &amp;#125; &amp;#125; refresh((ApplicationContext) context); &amp;#125; 执行 ConfigurationClassPostProcessor 增强器 关键词：refresh 方法、ConfigurationClassPostProcessor 增强器、主配置类 — 候选者、ConfigurationClassParser.parse 方法。 现在终于进入 refresh 方法，这是 spring 的知识点，就不再说了，现在到执行增强器的时候了，spirngboot 会调用 ConfigurationClassPostProcessor 类的 postProcessBeanDefinitionRegistry 方法（这个方法与 postProcessBeanFactory 方法具有同样的语义），然后调用了 processConfigBeanDefinitions 方法，在这个方法内，我们调用了： ConfigurationClassParser parser = new ConfigurationClassParser( this.metadataReaderFactory, this.problemReporter, this.environment, this.resourceLoader, this.componentScanBeanNameGenerator, registry); do &amp;#123; parser.parse(candidates); &amp;#125; while (!candidates.isEmpty()); 现在开始执行 ConfigurationClassParser.parse 了，而 candidates 就是我们的主配置类，这与之前 springboot 费尽心思加载主配置类也对应上了。 跟进 parse 方法内，核心代码是： public void parse(Set&lt;BeanDefinitionHolder> configCandidates) &amp;#123; for (BeanDefinitionHolder holder : configCandidates) &amp;#123; BeanDefinition bd = holder.getBeanDefinition(); parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &amp;#125; this.deferredImportSelectorHandler.process(); &amp;#125; this.deferredImportSelectorHandler.process() 这个方法很重要，先记下来，等会再说。 再跟进重载的 parse 方法，主要调用了 processConfigurationClass 方法，这个方法内有一个很重要的逻辑： SourceClass sourceClass = asSourceClass(configClass, filter); do &amp;#123; sourceClass = doProcessConfigurationClass(configClass, sourceClass, filter); &amp;#125; while (sourceClass != null); doProcessConfigurationClass 是真正做事的方法了，并且，如果 doProcessConfigurationClass 方法返回不是 null，那么会循环调用！ doProcessConfigurationClass 解析 Configuration 类上的注解 关键词：解析主配置类上的注解、@Import、getImports 方法、找到 @EnableAutoConfiguration 注解中的 @Import(AutoConfigurationImportSelector.class)。 这里面会执行对 @ComponentScan 的扫描，我们的启动类上的注解@SpringBootApplication 注解，这个注解内就包含了 @ComponentScan 注解： @ComponentScan(excludeFilters = &amp;#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &amp;#125;) 也就是说这里 springboot 会扫描和主类在同一个包下的所有被@Controller，@Service，@Repository，@Component 标注的类，将它们注册到容器中，然后递归的对这些类执行 parse 方法重新解析。 现在假设容器已经递归的解析好了其他的类，重新开始解析我们的主类，有一行关键的代码是： processImports(configClass, sourceClass, getImports(sourceClass), filter, true); 重点是这个函数的参数：getImports(sourceClass) 方法，跟进方法内： private Set&lt;SourceClass> getImports(SourceClass sourceClass) throws IOException &amp;#123; Set&lt;SourceClass> imports = new LinkedHashSet&lt;>(); Set&lt;SourceClass> visited = new LinkedHashSet&lt;>(); collectImports(sourceClass, imports, visited); return imports; &amp;#125; private void collectImports(SourceClass sourceClass, Set&lt;SourceClass> imports, Set&lt;SourceClass> visited) &amp;#123; if (visited.add(sourceClass)) &amp;#123; for (SourceClass annotation : sourceClass.getAnnotations()) &amp;#123; String annName = annotation.getMetadata().getClassName(); if (!annName.equals(Import.class.getName())) &amp;#123; collectImports(annotation, imports, visited); &amp;#125; &amp;#125; imports.addAll(sourceClass.getAnnotationAttributes(Import.class.getName(), \"value\")); &amp;#125; &amp;#125; 主要逻辑在 collectImports 方法内，这个方法啥意思？看if (!annName.equals(Import.class.getName()))，其实这个方法就是搜集类上的注解，然后继续递归的跟踪这些注解，看看注解上有没有 @Import，有就加入集合，然后继续跟踪注解……递归调用，同时用 visited 防止死循环。 简言之，就是搜集类上或从其他类继承的所有 @Import 注解，将这些注解信息添加到集合内。我们的启动类上应该是有两个 @Import 的，他们在 @EnableAutoConfiguration 和 @AutoConfigurationPackage 中。 拿到资源后将执行 processImports 方法，这个方法会执行普通的 @Import 注解类，但不是我们的重点，这个我们马上会说。 自动装配 请先了解 @Import 基本知识 关键词：延迟导入、getAutoConfigurationEntry 方法、loadFactoryNames 、 loadSpringFactories、获取自动装配类、EnableAutoConfiguration.class、过滤自动装配类、META-INF&#x2F;spring-autoconfigure-metadata.properties。 @Import(AutoConfigurationImportSelector.class) 中的注解并不会在 processImports 中执行，这是因为 AutoConfigurationImportSelector 实现了 DeferredImportSelector 接口，标志自己被延迟导入。 回到 parse 方法： public void parse(Set&lt;BeanDefinitionHolder> configCandidates) &amp;#123; for (BeanDefinitionHolder holder : configCandidates) &amp;#123; BeanDefinition bd = holder.getBeanDefinition(); parse(((AnnotatedBeanDefinition) bd).getMetadata(), holder.getBeanName()); &amp;#125; this.deferredImportSelectorHandler.process(); &amp;#125; this.deferredImportSelectorHandler.process() 是处理延迟导入的关键方法，跟进 process() 方法，这个方法调用了： DeferredImportSelectorGroupingHandler handler = new DeferredImportSelectorGroupingHandler(); handler.processGroupImports(); 点进 handler.processGroupImports() 方法内有一行： grouping.getImports().forEach(......) 跟进 grouping.getImports() 内： public Iterable&lt;Group.Entry> getImports() &amp;#123; for (DeferredImportSelectorHolder deferredImport : this.deferredImports) &amp;#123; this.group.process(deferredImport.getConfigurationClass().getMetadata(), deferredImport.getImportSelector()); &amp;#125; return this.group.selectImports(); &amp;#125; 核心方法是 this.group.process，继续跟进： @Override public void process(AnnotationMetadata annotationMetadata, DeferredImportSelector deferredImportSelector) &amp;#123; AutoConfigurationEntry autoConfigurationEntry = ((AutoConfigurationImportSelector) deferredImportSelector).getAutoConfigurationEntry(annotationMetadata); this.autoConfigurationEntries.add(autoConfigurationEntry); for (String importClassName : autoConfigurationEntry.getConfigurations()) &amp;#123; this.entries.putIfAbsent(importClassName, annotationMetadata); &amp;#125; &amp;#125; 至关重要的一行代码：getAutoConfigurationEntry(annotationMetadata)，跟进这个方法： protected AutoConfigurationEntry getAutoConfigurationEntry(AnnotationMetadata annotationMetadata) &amp;#123; AnnotationAttributes attributes = getAttributes(annotationMetadata); // 获取候选类 List&lt;String> configurations = getCandidateConfigurations(annotationMetadata, attributes); // 过滤候选类 configurations = getConfigurationClassFilter().filter(configurations); return new AutoConfigurationEntry(configurations, exclusions); &amp;#125; 这个方法主要就两个逻辑：获取自动装配类和过滤自动装配类，一个一个看！ 获取自动装配类点进 getCandidateConfigurations 方法： protected List&lt;String> getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &amp;#123; List&lt;String> configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); return configurations; &amp;#125; 看来核心是 SpringFactoriesLoader.loadFactoryNames 方法了，跟进这个方法，发现竟然调用了 loadFactoryNames 和 loadSpringFactories 方法！这两个方法我们在第一步的时候就已经详细讲了！我们来看看具体的参数（key）：getSpringFactoriesLoaderFactoryClass()： protected Class&lt;?> getSpringFactoriesLoaderFactoryClass() &amp;#123; return EnableAutoConfiguration.class; &amp;#125; 是 EnableAutoConfiguration！也就是说这一步会拿到所有 key &#x3D; EnableAutoConfiguration 的值： 类多的数不胜数，所有全限定名都被加载返回，这就是自动装配核心！ \\ 是换行的意思，按照上面的分析，这里肯定走缓存了，因为最开始在注册监听器的时候已经加载过一次 Names 了。 过滤自动装配类 须熟悉 OnCondition 相关知识 跟进 getConfigurationClassFilter().filter(configurations) 的 filter 方法，configurations 是我们刚刚获得的自动装配类的全限定名： List&lt;String> filter(List&lt;String> configurations) &amp;#123; String[] candidates = StringUtils.toStringArray(configurations); for (AutoConfigurationImportFilter filter : this.filters) &amp;#123; boolean[] match = filter.match(candidates, this.autoConfigurationMetadata); for (int i = 0; i &lt; match.length; i++) &amp;#123; if (!match[i]) &amp;#123; candidates[i] = null; &amp;#125; &amp;#125; &amp;#125; List&lt;String> result = new ArrayList&lt;>(candidates.length); for (String candidate : candidates) &amp;#123; if (candidate != null) &amp;#123; result.add(candidate); &amp;#125; &amp;#125; &amp;#125; 这个方法遍历 this.filters 来执行 match 方法，只要有一个不符合就过滤掉，this.filters 是什么呢？ 看到 OnCondition 应该很熟悉了，这里面的方法比较绕，就不放源码了，大致的是在 AutoConfigurationMetadataLoader 类内，对 PATH &#x3D; “META-INF&#x2F;spring-autoconfigure-metadata.properties“ 下的文件进行了资源加载，然后根据对应的规则（onClass 还是 onBean），去判断对应的 key 是否符合条件： 手写自动装配组件定义一个类 Hello： public class Hello &amp;#123; public void hello() &amp;#123; System.out.println(\"Hello World!\"); &amp;#125; &amp;#125; 按照要求建立资源文件： 按照要求填写类的全限定名： org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.happysnaker.Hello 打 jar 包，然后重启另一个项目导入 jar 包，运行 test（爆红别怕）： @SpringBootTest class ApplicationTests &amp;#123; @Autowired Hello hello; @Test void contextLoads() &amp;#123; hello.hello(); &amp;#125; &amp;#125; 成功输出：Hello World! 再建个文件： 填入： com.happysnaker.Hello= com.happysnaker.Hello.ConditionalOnClass=com.happysnaker.H 重新打包，运行程序报错！说明被过滤了！ 新建一个类 H： public class H &amp;#123; &amp;#125; 重新打包运行，成功输出：Hello World! 总结按照目录的顺序下来就是启动的所有流程了，如果能围绕着其中的关键字思考应该没多大问题了。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"进程间通信方式","slug":"进程间通信方式","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:17.004Z","comments":true,"path":"post/c120.html","link":"","permalink":"http://example.com/post/c120.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记 进程间通信方式引言在操作系统中，一个进程可以理解为是关于计算机资源集合的一次运行活动，其就是一个正在执行的程序的实例。从概念上来说，一个进程拥有它自己的虚拟CPU和虚拟地址空间，任何一个进程对于彼此而言都是相互独立的，这也引入了一个问题 —— 如何让进程之间互相通信？ 由于进程之间是互相独立的，没有任何手段直接通信，因此我们需要借助操作系统来辅助它们。举个通俗的例子，假如A与B之间是独立的，不能彼此联系，如果它们想要通信的话可以借助第三方C，比如A将信息交给C，C再将信息转交给B —— 这就是进程间通信的主要思想 —— 共享资源。 这里要解决的一个重要的问题就是如何避免竞争，即避免多个进程同时访问临界区的资源。 共享内存共享内存是进程间通信中最简单的方式之一。共享内存允许两个或更多进程访问同一块内存。当一个进程改变了这块地址中的内容的时候，其它进程都会察觉到这个更改。 你可能会想到，我直接创建一个文件，然后进程不就都可以访问了？ 是的，但这个方法有几个缺陷： 访问文件需要陷入系统调用，由用户态切入内核态，然后执行内核指令。这样做效率是非常低的，并且是不受用户掌握的。 直接访问磁盘是非常慢的，比访问内存要慢上几百倍。从某种意义上说，这是共享磁盘不算共享内存。 Linux下采用共享内存的方式来使进程完成对共享资源的访问，它将磁盘文件复制到内存，并创建虚拟地址到该内存的映射，就好像该资源本来就在进程空间之中，此后我们就可以像操作本地变量一样去操作它们了，因此共享内存的速度是最快的。 如同上图一样，进程将共享内存映射到自己的虚拟地址空间中，进程访问共享进程就好像在访问自己的虚拟内存一样，速度是非常快的。 共享内存的模型应该是比较好理解的：在物理内存中创建一块共享内存，进程将该共享内存绑定到自己的虚拟内存之中。 这里要解决的一个问题是如何将同一块共享内存绑定到自己的虚拟内存中，要知道在不同进程中使用malloc函数是会顺序分配空闲内存，而不会分配同一块内存，那么要如何去解决这个问题呢？ Linux操作系统已经想办法帮我们解决了这个问题，在#include &lt;sys/ipc.h&gt;和#include &lt;sys/shm.h&gt;头文件下，有如下几个shm系列函数： shmget函数：由ftok()函数获取需要共享文件资源标识符(IPC键)，将该资源标识符作为参数获取共享内存区域的唯一标识ID。 ftok()函数用以标识系统IPC资源，例如这里的共享资源、下文的消息队列、管道……都属于IPC资源。 IPC: Inter-Process[ Communication](https://baike.baidu.com/item/ Communication&#x2F;20394231)，进程间通信），IPC是指两个进程的数据之间产生交互。 shmat函数：通过由shmget函数获取的标识符，建立由共享内存到进程独立空间的映射。 shmdt函数：释放映射。 通过上述几个函数，每个独立的进程只要有统一的共享内存标识符便可以建立起虚拟地址到物理地址的映射，每个虚拟地址将被翻译成指向共享区域的物理地址，这样就实现了对共享内存的访问。 共享内存标识符由内核维护，全局唯一，通过这个标识符进程可以向内核请求获得共享内存基址，并绑定到虚拟内存中。共享内存资源被存放在由内存虚拟出来的文件系统上，不会到磁盘上，因此访问是非常快的。 还有一种相像的实现是采用mmap函数，mmap通常是直接对磁盘的映射——因此不算是共享内存，存储量非常大，但访问慢；shmat与此相反，通常将资源保存在内存中创建映射，访问快，但存储量较小。 不过要注意一点，操作系统并不保证任何并发问题，例如两个进程同时更改同一块内存区域，正如你和你的朋友在线编辑同一个文档中的同一个标题，这会导致一些不好的结果，所以我们需要借助信号量或其他方式来完成同步。 信号量信号量是迪杰斯特拉最先提出的一种为解决同步不同执行线程问题的一种方法，进程与线程抽象来看大同小异，所以信号量同样可以用于同步进程间通信。 信号量的工作原理信号量 s 是具有非负整数值的全局变量，由两种特殊的原子操作来实现，这两种原子操作称为 P 和 V ： P(s)：如果 s 的值大于零，就给它减1，然后立即返回，进程继续执行。；如果它的值为零，就挂起该进程的执行，等待 s 重新变为非零值。 V(s)：V操作将 s 的值加1，如果有任何进程在等在 s 值变为非0，那么V操作会重启这些等待进程中的其中一个(随机地)，然后由该进程执行P操作将 s 重新置为0，而其他等待进程将会继续等待。 理解信号量信号量并不用来传送资源，而是用来保护共享资源，理解这一点是很重要的，信号量 s 的表示的含义为同时允许最大访问资源的进程数量，它是一个全局变量。 无论何时只有 s 个进程能够访问共享资源，这就是信号量做的事情，他控制进入共享区的最大进程数量，这取决于初始化s的值。此后，在进入共享区之前调用P操作，出共享区后调用V操作，这就是信号量的思想。 在Linux下并没有直接的P&amp;V函数，而是需要我们根据这几个基本的sem函数族进行封装： semget：初始化或获取一个信号量，这个函数需要接受ftok()的返回值以及初始s的值，它将全局计数变量s绑定在由ftok标识的共享资源上，并返回一个唯一标识的信号量组ID。 semop：这个函数接受上面函数返回的信号量组ID以及一些其他参数，根据参数的不同有一些不同的操作，他将对与该信号量组ID绑定的全局计数变量 s 进行一些操作，P&amp;V操作便是基于此实现。 semctl：这个函数接受上面函数返回的信号量组ID以及一些其他参数，主要进行控制信号量相关信息，如删除该信号量等。 管道正如其名，管道就如同生活中的一根管道，一端输送，而另一端接收，双方不需要知道对方，只需要知道管道就好了。 管道是一种最基本的进程间通信机制。 管道由pipe函数来创建： 调用pipe函数，会在内核中开辟出一块缓冲区用来进行进程间通信，这块缓冲区称为管道，它有一个读端和一个写端。管道被分为匿名管道和有名管道。 匿名管道匿名管道通过pipe函数创建，这个函数接收一个长度为2的Int数组，并返回1或0表示成功或者失败： int pipe(int fd[2]) 这个函数打开两个文件描述符，一个读端文件，一个写端，分别存入fd[0]和fd[1]中，然后可以作为参数调用write和read函数进行写入或读取，注意fd[0]只能读取文件，而fd[1]只能用于写入文件。 你可能有个疑问，这要怎么实现通信？其他进程又不知道这个管道，因为进程是独立的，其他进程看不到某一个进程进行了什么操作。 是的，‘其他’进程确实是不知道，但是它的子进程却可以！这里涉及到fork派生进程的相关知识，一个进程派生一个子进程，那么子进程将会复制（写时复制）父进程的内存空间信息，注意这里是复制而不是共享，这意味着父子进程仍然是独立的，但是在这一时刻，它们所有的信息又是相等的。因此子进程也知道该全局管道，并且也拥有两个文件描述符与管道挂钩，所以匿名管道只能在具有亲缘关系的进程间通信。 还要注意，匿名管道内部采用环形队列实现，只能由写端到读端，由于设计技术问题，管道被设计为半双工的，一方要写入则必须关闭读描述符，一方要读出则必须关闭写入描述符。因此我们说管道的消息只能单向传递。 注意管道是堵塞的，如何堵塞将依赖于读写进程是否关闭文件描述符。如果读管道，如果读到空时，假设此时写端口还没有被完全关闭，那么操作系统会假设还有数据要读，此时读进程将会被堵塞，直到有新数据或写端口被关闭；如果管道为空，且写端口也被关闭，此时操作系统会认为已经没有东西可读，会直接退出，并关闭管道。 对于写一个已经满了的管道同理而言，如果管道已满，如果此时读端未关闭，则写端会被堵塞直到管道有剩余空间；但是如果读端已经关闭了，那么写端的写将会是无意义的，为防止写端继续写，操作系统会发送信号中止写端。 管道内部由内核管理，在半双工的条件下，保证数据不会出现并发问题。 命名管道了解了匿名管道之后，有名管道便很好理解了。在匿名管道的介绍中，我们说其他进程不知道管道和文件描述符的存在，所以匿名管道只适用于具有亲缘关系的进程，而命名管道则很好的解决了这个问题 —— 现在管道有一个唯一的名称了，任何进程都可以访问这个管道。 注意，操作系统将管道看作一个抽象的文件，但管道并不是普通的文件，管道存在于内核空间中而不放置在磁盘(有名管道文件系统上有一个标识符，没有数据块)，访问速度更快，但存储量较小，管道是临时的，是随进程的，当进程销毁，所有端口自动关闭，此时管道也是不存在的，操作系统将所有IO抽象的看作文件，例如网络也是一种文件，这意味着我们可以采用任何文件方法操作管道，理解这种抽象是很重要的，命名管道就利用了这种抽象。 Linux下，采用mkfifo函数创建，可以传入要指定的‘文件名’，然后其他进程就可以调用open方法打开这个特殊的文件，并进行write和read操作(那肯定是字节流对吧)。 注意，命名管道适用于任何进程，除了这一点不同外，其余大多数都与匿名管道相同。 消息队列什么是消息队列？消息队列亦称报文队列，也叫做信箱，是Linux的一种通信机制，这种通信机制传递的数据会被拆分为一个一个独立的数据块，也叫做消息体，消息体中可以定义类型与数据，克服了无格式承载字节流的缺陷(现在收到void*后可以知道其原本的格式惹): struct msgbuf &amp;#123; long mtype; /* 消息的类型 */ char mtext[1]; /* 消息正文 */ &amp;#125;; 同管道类似，它有一个不足就是每个消息的最大长度是有上限的，整个消息队列也是长度限制的。 内核为每个IPC对象维护了一个数据结构struct ipc_perm，该数据结构中有指向链表头与链表尾部的指针，保证每一次插入取出都是O(1)的时间复杂度。 1. msgget 功能：创建或访问一个消息队列 原型： #include &lt;sys/types.h> #include &lt;sys/ipc.h> #include &lt;sys/msg.h> int msgget(key_t key, int msgflag); 参数：key：某个消息队列的名字，用ftok()产生，消息队列为PIC资源，该key标识了此消息队列，如果传入key存在，则返回对应消息队列ID，否则，创建并返回消息队列ID。msgflag：有两个选项IPC_CREAT和IPC_EXCL，单独使用IPC_CREAT，如果消息队列不存在则创建之，如果存在则打开返回；单独使用IPC_EXCL是没有意义的；两个同时使用，如果消息队列不存在则创建之，如果存在则出错返回。 返回值：成功返回一个非负整数，即消息队列的标识码，失败返回-1 2. msgctl功能：消息队列的控制函数 原型： #include &lt;sys/types.h> #include &lt;sys/ipc.h> #include &lt;sys/msg.h> int msgctl(int msqid, int cmd, struct msqid_ds *buf); 参数：msqid：由msgget函数返回的消息队列标识码cmd：有三个可选的值，在此我们使用IPC_RMID IPC_STAT 把msqid_ds结构中的数据设置为消息队列的当前关联值 IPC_SET 在进程有足够权限的前提下，把消息队列的当前关联值设置为msqid_ds数据结构中给出的值 IPC_RMID 删除消息队列 返回值：成功返回0，失败返回-1 3. msgsnd功能：把一条消息添加到消息队列中 原型： #include &lt;sys/types.h> #include &lt;sys/ipc.h> #include &lt;sys/msg.h> int msgsnd(int msqid, const void *msgp, size_t msgsz, int msgflg); 参数：msgid：由msgget函数返回的消息队列标识码msgp：指针指向准备发送的消息msgze：msgp指向的消息的长度（不包括消息类型的long int长整型）msgflg：默认为0 返回值：成功返回0，失败返回-1 4. msgrcv功能：是从一个消息队列接受消息 原型：ssize_t msgrcv(int msqid, void *msgp, size_t msgsz, long msgtyp, int msgflg); 参数：与msgsnd相同 返回值：成功返回实际放到接收缓冲区里去的字符个数，失败返回-1 特点 与管道不同，消息队列的生命周期随内核，不会随进程销毁而销毁，需要我们显示的调用接口删除或使用命令删除。 消息队列可以双向通信。 克服了管道只能承载无格式字节流的缺点。 信号关于信号一个进程可以发送信号给另一个进程，一个信号就是一条消息，可以用于通知一个进程组发送了某种类型的事件，该进程组中的进程可以采取处理程序处理事件。 Linux下unistd.h头文件下定义了如图中的常量，当你在shell命令行键入ctrl + c时，内核就会前台进程组的每一个进程发送SIGINT信号，中止进程。 我们可以看到上述只有30个信号，因此操作系统会为每一个进程维护一个int类型变量sig，利用其中30位代表是否有对应信号事件，每一个进程还有一个int类型变量block，与sig对应，其30位表示是否堵塞对应信号(不调用处理程序)。如果存在多个相同的信号同时到来，多余信号正常情况下会被存储在一个等待队列中等待。 我们要理解进程组是什么，每个进程属于一个进程组，可以有多个进程属于同一个组。每个进程拥有一个进程ID，称为pid，而每个进程组拥有一个进程组ID，称为pgid，默认情况下，一个进程与其子进程属于同一进程组。 软件方面(诸如检测键盘输入是硬件方面)可以利用kill函数发送信号，kill函数接受两个参数，进程ID和信号类型，它将该信号类型发送到对应进程，如果该pid为0，那么会发送到属于自身进程组的所有进程。 接收方可以采用signal函数给对应事件添加处理程序，一旦事件发生，如果未被堵塞，则调用该处理程序。 Linux下有一套完善的函数用以处理信号机制。 特点 信号是在软件层次上对中断机制的一种模拟，是一种异步通信方式。 信号可以直接进行用户空间进程和内核进程之间的交互，内核进程也可以利用它来通知用户空间进程发生了哪些系统事件。 如果该进程当前并未处于执行态，则该信号就由内核保存起来，直到该进程恢复执行再传递给它；如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消时才被传递给进程。 信号有明确生命周期，首先产生信号，然后内核存储信号直到可以发送它，最后内核一旦有空闲，会适当处理信号。 处理程序是可以被另一个处理程序中断的，因此这可能造成并发问题，所以在处理程序中的代码应该是线程安全的，通常通过设置block位图以堵塞所有信号。 套接字Socket套接字是用与网络中不同主机的通信方式，多用于客户端与服务器之间，在Linux下也有一系列C语言函数，诸如socket、connect、bind、listen与accept，对于原理的学习，更好的是对Java中的套接字socket源码进行剖析。 结语对于工作而言，我们可能一辈子都用不上这些操作，但作为对于操作系统的学习，认识到进程间是如何通信还是很有必要的。 面试的时候对于这些方法我们不需要掌握到很深的程度，但我们必须要讲的来有什么通信方式，这些方式都有什么特点，适用于什么条件，大致是如何操作的，能说出这些，基本足以让面试官对你十分满意了。","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]},{"title":"页面置换算法","slug":"页面置换算法","date":"2023-02-10T07:12:13.000Z","updated":"2023-02-10T07:12:17.007Z","comments":true,"path":"post/651a.html","link":"","permalink":"http://example.com/post/651a.html","excerpt":"","text":"文章已收录我的仓库：Java学习笔记与免费书籍分享 页面置换(淘汰)算法 本文基于《现代操作系统》总结 前言对于操作系统而言，虚拟空间是非常大的，我们往往无法直接将如此大的空间装入内存，而即使我们采用多级页表与段页式存储即使，也仅仅只是节省了页表的大小，如此将如何多的物理页装进内存仍然是一个问题，为此科学家们提出了一种动态的思想，当剩余空间不够装入新页面时，操作系统就选择适当的页将其刷新回磁盘(如果确实是脏页的话，如果不是脏页则仅仅只是覆盖)，以此空出空间装入新页，而这则需要运用到页面置换算法。 还有一个问题是：是否需要对每一个进程固定一个空间大小，换句话说，是采用局部分配策略还是全局分配策略。 采用局部分配的好处在于每一个进程空间都是互不影响的，即使一个进程频繁的发生页面置换也不会影响到其他进程，并且易于管理；但缺点是，如何分配一个进程的空间大小是难以确定的，有的进程可能频繁发生页面置换，而有的进程可能只会使用一点点空间，这是预先无法确定的，如果给一个进程分配的空间小了，那么该进程可能会发生内存“颠簸”(频繁的发生页面置换)。 若采用全局分配，一个进程理论上可以使用整个内存空间，内存大意味着发生置换的频率就小了，在绝大多数情况下，全局分配优于局部策略。但缺点也是很明显的，如果进程较多，一个进程频繁进行页面置换可能会置换其他进程的页，这可能会导致其他进程也造成缺页异常，需要引入新页，从而造成死循环。这是操作系统不愿意看到的事情，而且操作系统难以控制这种局面。 好消息是历经这么多年，现代操作系统已经很聪明了，现代操作系统大多采用局部分配的方法，这更易于操作系统控制。当操作系统开始分配页面时，会根据进程数量、进程资源大小等参数相对公平的分配固定的空间，例如总内存大小为 10kb，当已有一个资源为 5kb 的进程A正在运行，由于只有一个进程，进程A的空间大小为整个内存大小 10kb，现在操作系统打算为资源大小为 15kb 的进程B分配空间，操作系统根据进程大小与进程数量进行评估，由于进程B大小 : 进程A大小 &#x3D; 3 : 1，因此操作系统为B分配 3&#x2F;4 的内存空间大小 7.5kb，同时调整A的大小为 2.5kb(淘汰页面)。 而在运行时，操作系统仍然会聪明的进行动态调整，如果一个进程A频繁的发生颠簸，而进程B几乎不发生颠簸，操作系统会适当增加进程A空间的大小，而减少进程B空间的大小。如果所有的进程都发生颠簸，这是最坏的情况，此时操作系统会选择一些进程将它们暂时的调换到磁盘中以空处一些空间，直到有新的空间时再将他们换回来。 何时会发生页面置换？当发生缺页异常时(页表项中存在位为0)，需要引入该页，如果此时进程的内存空间不够，则需要淘汰一些页面。对于某些操作系统而言，可能会预先载入某些页以减少缺页异常的发生。 在了解这些之后，让我们来具体探讨一些页面淘汰算法。 最优置换算法(OPT)这个算法是不可能实现的，但面试需要说出这个算法。 最优置换算法的思想就是选取最晚使用的页面淘汰，这当然是最优的算法，但问题是计算机根本也不知道各个页面下一次将在什么时候被访问，因此该算法是无法实现的。 该算法通常作为基准，其他算法与该算法进行对比。 先进先出页面置换算法(First-In First-Out，FIFO)顾名思义，淘汰最先使用的页面，很容易想到队列这种数据结构，从尾入，从头出。 具体的实现是由操作系统维护一个所有当前在内存中的页面的链表，每一次最新进入的页面放在表尾，那么表头页面即使最久使用的。当发生缺页中断时，淘汰表头的页面并把新调入的页面加到表尾。 FIFO的实现跟简单，但效率不是很高。FIFO的算法思想很纯粹，即淘汰使用最久的页面，但是，保不准某些页面使用的久而且使用的频繁，这样淘汰最久使用的页面就不是一个好的办法了，因为下一次很可能又会载入该页面，因此很少有操作系统采用存粹的FIFO算法了。 第二次机会页面置换算法(Second Chance，SC)SC是对FIFO的一个优化，在FIFO中可能会错误的淘汰掉接下来可能会使用的页面，因此SC给予这些页面第二次机会。 SC仍然维护一个FIFO链表，但同时对每一个页会维护一个R位，为0则表示该页未使用，为1表示该页最近使用过，每次访问页都会设置该页R位为1。 当触发缺页异常，SC的算法规则是： 从表头移除页，如果该页R&#x3D;1，则表示该页最近被使用过，可能会接着被使用，给予其第二次机会，因此操作系统将该页重新装入表尾，但设置R&#x3D;0，然后继续从表头读页。 如果R&#x3D;0，则表示该页生存时间很久了，并且最近都没有使用，则可以像FIFO那样直接置换掉该页。 SC的思想是NRU思想，我们很快就会介绍NRU算法思想，实践表明SC算法是一个较为合理的算法，但缺点是SC经常要在链表中移动页面，这是非常耗时的。 最近未使用页面置换算法(Not Recently Used，NRU)NRU选择淘汰最近未使用的页面，NRU算法认为如果最近使用了一个页面，那么很有可能会继续使用，而对于没有使用的页面，可能很久都不会再使用了，因此淘汰掉该页面。 在大部分具有虚拟内存的计算机 中，在页面的页表项中，系统为每一页面设置了两个状态位。当页面被访问（读或写）时设置R位； 当页面（即修改页面）被写入时设置M位。R位是NRU实现的关键，R位为 1 表示该页最近被访问，为 0 则表示未被访问。 由于页面的访问是相当频繁的，因此设置R、M位最好是由硬件来完成，好在这项工作不算复杂，市面上已经有类似的实现了， 问题的关键是，这个最近的含义是什么？通常情况下，NRU采取操作系统的时钟中断(通常20ms一次)作为标志，即记录从上一次时钟中断到目前为止的访问信息，这意味着每一次时钟中断需要设置R为0，以表示“最近周期”的重新开始。时钟中断一般不设置M位，M位是脏位的标志，当确实要置换某页时，如果该页M位为1，表示页被修改，则必须要写回磁盘以维护一致性；如果M位为0，则页未被修改，可以直接覆盖(磁盘中的页与内存中的页一致)，无须写回。 当发生缺页中断时，操作系统检查所有的页面并根据它们当前的R位和M位的值，把它们分为4类： 编号0：没有被访问，没有被修改(最近未使用的干净页)。 编号1：没有被访问，已被修改(最近未使用的脏页)。 编号2：已被访问，没有被修改(最近使用的干净页)。 编号3：已被访问，已被修改(最近使用的脏页)。 NRU算法随机地从编号最小页面中挑选一个淘汰，选择的思想是优先选择干净页，这样可以节省一次写回磁盘的时间。 NRU主要优点是易于理解和能够有效地被实现，但它的性能不是很好，因为他必须要扫描所有表项才能找出要淘汰的页。 时钟算法时钟算法属于NRU软件实现的一种方法，算法思想源自于上述标准的NRU算法，上述NRU算法采用操作系统时钟中断周期作为标志，而时钟算法维护一个循环链表，以一个循环为标志。 时钟算法仍然维护一个R位标识是否被访问，1 标识被访问，0 标识未被访问，只不过这一次由软件实现，链表被放置在内存中(当然只会放置指向页或页表项的指针)。 具体的算法是： 访问一次页面，则设置该页R位为1 当发生缺页异常时，如果此时进程空间不够，需要淘汰页面，则： 检查当前页R位，如果是 0，表示该页最近未使用，则置换该页，检查页表项判断是否需要刷新回磁盘。 一种权衡是：如果该页是脏页，是否需要选择置换该页？答案是不确定的，选择置换该页则需要付出一次磁盘IO的代价；而不置换该页则需要继续查找，这也需要一定的时间，最坏的情况是所有页都是脏页，此时得等待操作系统发生时钟中断将脏页刷新回磁盘。 如果为 1，则置为 0，并前移指针。 最坏情况下，时钟算法需要遍历一个周期才能找到R&#x3D;0的页，这是非常糟糕的。 算法的思想是：如果当前指针指向的页为R &#x3D; 0，则可以确定至少一个循环内该页未被访问，这是由于既然该页R位为0，要么该页从来没有被访问；要么该页在上一个循环内被设置为0，而一个循环内未被访问(如果访问了就是1了)；无论怎样，都至少经历了一个循环，则可以近似的将其认为最近使用的页面。 时钟算法是NRU软件实现的一种较好的办法，实现简单，效率也还行，通常是一种不错的实现方法。 最近最少使用页面置换算法(Least Recently Used，LRU)LRU与NRU的区别在于：NRU是严格查找最近未使用的页面，当最近页面都使用过，NRU就会变得不知所措，此时NRU通常会随机选取一个页面，这是造成NRU效率低效的主要原因；而LRU充分考虑到了这一点，即使最近页面都使用过，LRU也能找到最少使用的那么页面，实施淘汰算法。从集合角度说，NRU包含于LRU，NRU通常作为LRU的近似实现。 因此LRU是最十分高效的算法，虽然LRU在理论上是可以实现的，但代价非常高。为了完全实现LRU，需要在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。每次访问一个页时，找到该页在链表中的位置(可以利用哈希)，然后将它移动到表头，淘汰时选取表尾的页淘汰即可。 算法思想是很简单的：每次被访问页面都被移动到头，那么尾部的节点就是最近最少被访问的页了。换句话说，对于任意一个节点而言，在它前面的节点一定是比它后被访问的，那么该节点在这段时间内访问的频率不如在它前面的节点，当然，这还要看对“最近”是如何定义的，对于这里的LRU而言，“最近”被定义为上一次访问尾节点的时间到现在。 但是，页面的访问是非常频繁的，诸如int a = 0; a++;这样的语句都需要访问对应的页，毫不夸张的说，几乎99%代码语句可能都需要访问页，而每次访问又需要移动页面指针，这代价太高了，因此这种存粹的软件模拟在操作系统层面上来说是不可取的。必须要借助硬件支持。 有一种很巧妙的方法实现LRU，即：每个页表项中存在一个时间字段，当访问该页时，设置该时间字段为当前时间，淘汰时，扫描全部页表项，找到最晚的时间戳淘汰它。 我们必须要利用硬件加速这个过程，因为软件更新时间戳效率太低了，这种算法是想要精确实现LRU的另一个选择。缺点是该算法与NRU类似，也必须扫描全部页表项，代价也是较高的(但可以接受)，并且还要考虑时间戳溢出问题。 最不常用页面置换算法(Not Frequently Used，NFU)该算法将每个页面与一个软件计数器相关联，计数器的初值为0。每次时钟中断时，由操作系统扫描内存中所有的 页面，将每个页面的R位（它的值是0或1）加到它的计数器上，然后重新设置R位为0。这个计数器大体上跟踪了各个页面被访问的频繁程度。发生缺页中断时，则置换计数器值最小的页面。 NFU与LRU的区别就在于NFU淡化了“最近”的含义，是一种近似LRU的实现，NFU从不忘记任何事，他记得所有历史以来所有事情。这就会产生一些问题，比如，在一个多次（扫描）编译器中，在前几次扫描中被频繁使用的页面在程序进入第N次扫描时，其计数器的值可能仍然很高(甚至可能会发生溢出)，尽管该页可能前面使用频繁而后面使用不频繁。 因此，我们得想办法让NFU忘掉一些事情。 老化算法改进后的算法叫做老化算法，只需对NFU做一个小小的修改就能使它很好地模拟LRU。其修改分为两部分： 首先，在R位被加进之前先将计数器右移一位(对所有的计数器执行)； 其次，将R位加到计数器最左端的位上。 改进的思想是：右移一位使得NFU能够忘掉最近没被用过的页面(右移相当于除以2，数减小)，而由于所有计数器被右移一位，衰减是非常快的(加在左边一下就衰减没了)，因此相加应该加在右边的位上(恰好右移一位空出)。 考虑经历了5个时钟周期，老化算法的运行如下所示： 当发生缺页时，置换计数器最小的值，例如在滴答4时，应该置换掉页面3，页面3在滴答2出现了一次，是所有页中最晚使用的页(页0,1,2,4在嘀嗒3,4使用，页5虽然在嘀嗒2使用，但页5已经是第二次被使用了)。 LRU和老化算法的区别是老化算法的计数器只有有限位数（本例中是 8位），这就限制了其对以往页面的记录。 工作集页面置换算法人们很早就发现大多数程序都不是均匀地访问它们的地址空间的，而访问往往是集中于一小部分页面。一次内存访问可能会取出一条指令，也可能会取数据，或者是存储数据。在任一时刻t，都存在一个集合，它包含所有最近k次内存访问所访问过的页面。这个集合w(k,t)就是工作集(k是人为确定的)。 工作集与 LRU 的区别是，工作集并不考虑频度的问题，它只在乎最近该页在不在工作集内，而不考虑该页使用频率如何，换句话说，被淘汰的页面不在工作集内，但并不能保证该页面是最近最少使用的。 工作集页面置换算法思想是当某一时刻 t 需要置换页面时，选取不在 w(k,t) 内页面淘汰它。为实时维护工作集，我们需要在内存中维护长度为 k 的链表，每次访问页面时都将页号从尾放入链表中，如果链表已满，则需要从头弹出一个元素，但问题是每次访问页都需要调整链表，代价也十分高昂。 通常采取近似的方法，例如基于时间戳的方法，比如：工作集是过去 T ms 中的内存访问所用到的页面的集合。我们并不需要每次访问都更新时间戳，可以近似的只在时钟中断时进行更新，代价是时钟中断时不得不遍历整个表项进行更新。 现在扫描整个表项，会出现4种情况： 时间戳不在工作集内，R&#x3D;0：这种情况下直接进行置换即可，循环继续，但不再置换页面。 时间戳不在工作集内，R&#x3D;1：该页最近被访问，在等待中断更新，此时更新该页时间戳为当前时间，设置 R &#x3D; 0。 时间戳在工作集内，R&#x3D;0：如果已经置换了页面，则忽略；否则，记录下该时间戳，如果所有都是这种情况，则选择时间戳最小的哪个淘汰。 时间戳在工作集内，R&#x3D;1：该页最近被访问，在等待中断更新，此时更新该页时间戳为当前时间， 设置 R &#x3D; 0。 总结 算法 总结 OPT 不可能实现，只是作为比较的基准。 FIFO 实现简单，但可能换出重要的页，工作效果不好 SC FIFO的优化，工作效果较好，但需要交换链表项，性能不是很高，但可以接受，是个不错的选择 NRU LRU的近似，但工作效果不是很好，需要遍历全部页，性能不高 时钟算法 NRU的思想，LRU的近似实现，工作效果较好，性能较高，是个不错的选择 LRU(链表) 工作效果好，但每次访问都需要复杂的指针移动，性能低，非最优选 LRU(时间戳) 可取的LRU实现，但需要硬件更新时间戳，每个页都需要维护一个时间戳，空间成本高，而且时钟是不可靠的！ NFU LRU的近似，工作效果不好，不可取 老化算法 NFU的优化，LRU的近似，工作效果好，但中断时需要遍历全部页表项，性能不高，但由于其工作效果优秀，是个不错的选择 工作集 工作效果一般，中断时需要遍历全部页表项，性能不高，非最优选","categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]}],"categories":[{"name":"暂无分类","slug":"暂无分类","permalink":"http://example.com/categories/%E6%9A%82%E6%97%A0%E5%88%86%E7%B1%BB/"}],"tags":[{"name":"暂无标签","slug":"暂无标签","permalink":"http://example.com/tags/%E6%9A%82%E6%97%A0%E6%A0%87%E7%AD%BE/"}]}